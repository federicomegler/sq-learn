

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>sklearn.inspection package &mdash; Qsklearn  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> Qsklearn
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="modules.html">qsklearn</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Qsklearn</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>sklearn.inspection package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/sklearn.inspection.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="sklearn-inspection-package">
<h1>sklearn.inspection package<a class="headerlink" href="#sklearn-inspection-package" title="Permalink to this headline">¶</a></h1>
<section id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="sklearn.inspection.tests.html">sklearn.inspection.tests package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="sklearn.inspection.tests.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.inspection.tests.html#sklearn-inspection-tests-test-partial-dependence-module">sklearn.inspection.tests.test_partial_dependence module</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.inspection.tests.html#sklearn-inspection-tests-test-permutation-importance-module">sklearn.inspection.tests.test_permutation_importance module</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.inspection.tests.html#module-sklearn.inspection.tests">Module contents</a></li>
</ul>
</li>
</ul>
</div>
</section>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</section>
<section id="module-sklearn.inspection.setup">
<span id="sklearn-inspection-setup-module"></span><h2>sklearn.inspection.setup module<a class="headerlink" href="#module-sklearn.inspection.setup" title="Permalink to this headline">¶</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="sklearn.inspection.setup.configuration">
<span class="sig-prename descclassname"><span class="pre">sklearn.inspection.setup.</span></span><span class="sig-name descname"><span class="pre">configuration</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parent_package</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.inspection.setup.configuration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</section>
<section id="module-sklearn.inspection">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-sklearn.inspection" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-sklearn.inspection" title="sklearn.inspection"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.inspection</span></code></a> module includes tools for model inspection.</p>
<dl class="py class">
<dt class="sig sig-object py" id="sklearn.inspection.PartialDependenceDisplay">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.inspection.</span></span><span class="sig-name descname"><span class="pre">PartialDependenceDisplay</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pd_results</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_names</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pdp_lim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deciles</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kind</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'average'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.inspection.PartialDependenceDisplay" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Partial Dependence Plot (PDP).</p>
<p>This can also display individual partial dependencies which are often
referred to as: Individual Condition Expectation (ICE).</p>
<p>It is recommended to use
<a class="reference internal" href="#sklearn.inspection.plot_partial_dependence" title="sklearn.inspection.plot_partial_dependence"><code class="xref py py-func docutils literal notranslate"><span class="pre">plot_partial_dependence()</span></code></a> to create a
<a class="reference internal" href="#sklearn.inspection.PartialDependenceDisplay" title="sklearn.inspection.PartialDependenceDisplay"><code class="xref py py-class docutils literal notranslate"><span class="pre">PartialDependenceDisplay</span></code></a>. All parameters are
stored as attributes.</p>
<p>Read more in
<span class="xref std std-ref">sphx_glr_auto_examples_miscellaneous_plot_partial_dependence_visualization_api.py</span>
and the <span class="xref std std-ref">User Guide</span>.</p>
<blockquote>
<div><div class="versionadded">
<p><span class="versionmodified added">New in version 0.22.</span></p>
</div>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pd_results</strong> (<em>list of Bunch</em>) – Results of <a class="reference internal" href="#sklearn.inspection.partial_dependence" title="sklearn.inspection.partial_dependence"><code class="xref py py-func docutils literal notranslate"><span class="pre">partial_dependence()</span></code></a> for
<code class="docutils literal notranslate"><span class="pre">features</span></code>.</p></li>
<li><p><strong>features</strong> (<em>list of</em><em> (</em><em>int</em><em>,</em><em>) or </em><em>list of</em><em> (</em><em>int</em><em>, </em><em>int</em><em>)</em>) – Indices of features for a given plot. A tuple of one integer will plot
a partial dependence curve of one feature. A tuple of two integers will
plot a two-way partial dependence curve as a contour plot.</p></li>
<li><p><strong>feature_names</strong> (<em>list of str</em>) – Feature names corresponding to the indices in <code class="docutils literal notranslate"><span class="pre">features</span></code>.</p></li>
<li><p><strong>target_idx</strong> (<em>int</em>) – <ul>
<li><p>In a multiclass setting, specifies the class for which the PDPs
should be computed. Note that for binary classification, the
positive class (index 1) is always used.</p></li>
<li><p>In a multioutput setting, specifies the task for which the PDPs
should be computed.</p></li>
</ul>
<p>Ignored in binary classification or classical regression settings.</p>
</p></li>
<li><p><strong>pdp_lim</strong> (<em>dict</em>) – Global min and max average predictions, such that all plots will have
the same scale and y limits. <cite>pdp_lim[1]</cite> is the global min and max for
single partial dependence curves. <cite>pdp_lim[2]</cite> is the global min and
max for two-way partial dependence curves.</p></li>
<li><p><strong>deciles</strong> (<em>dict</em>) – Deciles for feature indices in <code class="docutils literal notranslate"><span class="pre">features</span></code>.</p></li>
<li><p><strong>kind</strong> (<em>{'average'</em><em>, </em><em>'individual'</em><em>, </em><em>'both'}</em><em>, </em><em>default='average'</em>) – <dl class="simple">
<dt>Whether to plot the partial dependence averaged across all the samples</dt><dd><p>in the dataset or one line per sample or both.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">kind='average'</span></code> results in the traditional PD plot;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kind='individual'</span></code> results in the ICE plot.</p></li>
</ul>
</dd>
</dl>
<p>Note that the fast <code class="docutils literal notranslate"><span class="pre">method='recursion'</span></code> option is only available for
<code class="docutils literal notranslate"><span class="pre">kind='average'</span></code>. Plotting individual dependencies requires using the
slower <code class="docutils literal notranslate"><span class="pre">method='brute'</span></code> option.</p>
<blockquote>
<div><div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
</div></blockquote>
</p></li>
<li><p><strong>subsample</strong> (<em>float</em><em>, </em><em>int</em><em> or </em><em>None</em><em>, </em><em>default=1000</em>) – <p>Sampling for ICE curves when <cite>kind</cite> is ‘individual’ or ‘both’.
If float, should be between 0.0 and 1.0 and represent the proportion
of the dataset to be used to plot ICE curves. If int, represents the
maximum absolute number of samples to use.</p>
<p>Note that the full dataset is still used to calculate partial
dependence when <cite>kind=’both’</cite>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – <p>Controls the randomness of the selected samples when subsamples is not
<cite>None</cite>. See <span class="xref std std-term">Glossary</span> for details.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.inspection.PartialDependenceDisplay.bounding_ax_">
<span class="sig-name descname"><span class="pre">bounding_ax_</span></span><a class="headerlink" href="#sklearn.inspection.PartialDependenceDisplay.bounding_ax_" title="Permalink to this definition">¶</a></dt>
<dd><p>If <cite>ax</cite> is an axes or None, the <cite>bounding_ax_</cite> is the axes where the
grid of partial dependence plots are drawn. If <cite>ax</cite> is a list of axes
or a numpy array of axes, <cite>bounding_ax_</cite> is None.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>matplotlib Axes or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.inspection.PartialDependenceDisplay.axes_">
<span class="sig-name descname"><span class="pre">axes_</span></span><a class="headerlink" href="#sklearn.inspection.PartialDependenceDisplay.axes_" title="Permalink to this definition">¶</a></dt>
<dd><p>If <cite>ax</cite> is an axes or None, <cite>axes_[i, j]</cite> is the axes on the i-th row
and j-th column. If <cite>ax</cite> is a list of axes, <cite>axes_[i]</cite> is the i-th item
in <cite>ax</cite>. Elements that are None correspond to a nonexisting axes in
that position.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray of matplotlib Axes</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.inspection.PartialDependenceDisplay.lines_">
<span class="sig-name descname"><span class="pre">lines_</span></span><a class="headerlink" href="#sklearn.inspection.PartialDependenceDisplay.lines_" title="Permalink to this definition">¶</a></dt>
<dd><p>If <cite>ax</cite> is an axes or None, <cite>lines_[i, j]</cite> is the partial dependence
curve on the i-th row and j-th column. If <cite>ax</cite> is a list of axes,
<cite>lines_[i]</cite> is the partial dependence curve corresponding to the i-th
item in <cite>ax</cite>. Elements that are None correspond to a nonexisting axes
or an axes that does not include a line plot.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray of matplotlib Artists</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.inspection.PartialDependenceDisplay.deciles_vlines_">
<span class="sig-name descname"><span class="pre">deciles_vlines_</span></span><a class="headerlink" href="#sklearn.inspection.PartialDependenceDisplay.deciles_vlines_" title="Permalink to this definition">¶</a></dt>
<dd><p>If <cite>ax</cite> is an axes or None, <cite>vlines_[i, j]</cite> is the line collection
representing the x axis deciles of the i-th row and j-th column. If
<cite>ax</cite> is a list of axes, <cite>vlines_[i]</cite> corresponds to the i-th item in
<cite>ax</cite>. Elements that are None correspond to a nonexisting axes or an
axes that does not include a PDP plot.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.23.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray of matplotlib LineCollection</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.inspection.PartialDependenceDisplay.deciles_hlines_">
<span class="sig-name descname"><span class="pre">deciles_hlines_</span></span><a class="headerlink" href="#sklearn.inspection.PartialDependenceDisplay.deciles_hlines_" title="Permalink to this definition">¶</a></dt>
<dd><p>If <cite>ax</cite> is an axes or None, <cite>vlines_[i, j]</cite> is the line collection
representing the y axis deciles of the i-th row and j-th column. If
<cite>ax</cite> is a list of axes, <cite>vlines_[i]</cite> corresponds to the i-th item in
<cite>ax</cite>. Elements that are None correspond to a nonexisting axes or an
axes that does not include a 2-way plot.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.23.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray of matplotlib LineCollection</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.inspection.PartialDependenceDisplay.contours_">
<span class="sig-name descname"><span class="pre">contours_</span></span><a class="headerlink" href="#sklearn.inspection.PartialDependenceDisplay.contours_" title="Permalink to this definition">¶</a></dt>
<dd><p>If <cite>ax</cite> is an axes or None, <cite>contours_[i, j]</cite> is the partial dependence
plot on the i-th row and j-th column. If <cite>ax</cite> is a list of axes,
<cite>contours_[i]</cite> is the partial dependence plot corresponding to the i-th
item in <cite>ax</cite>. Elements that are None correspond to a nonexisting axes
or an axes that does not include a contour plot.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray of matplotlib Artists</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.inspection.PartialDependenceDisplay.figure_">
<span class="sig-name descname"><span class="pre">figure_</span></span><a class="headerlink" href="#sklearn.inspection.PartialDependenceDisplay.figure_" title="Permalink to this definition">¶</a></dt>
<dd><p>Figure containing partial dependence plots.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>matplotlib Figure</p>
</dd>
</dl>
</dd></dl>

<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.inspection.partial_dependence" title="sklearn.inspection.partial_dependence"><code class="xref py py-obj docutils literal notranslate"><span class="pre">partial_dependence</span></code></a></dt><dd><p>Compute Partial Dependence values.</p>
</dd>
<dt><a class="reference internal" href="#sklearn.inspection.plot_partial_dependence" title="sklearn.inspection.plot_partial_dependence"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_partial_dependence</span></code></a></dt><dd><p>Plot Partial Dependence.</p>
</dd>
</dl>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.inspection.PartialDependenceDisplay.plot">
<span class="sig-name descname"><span class="pre">plot</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_cols</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">line_kw</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">contour_kw</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.inspection.PartialDependenceDisplay.plot" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot partial dependence plots.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ax</strong> (<em>Matplotlib axes</em><em> or </em><em>array-like of Matplotlib axes</em><em>, </em><em>default=None</em>) – <ul>
<li><dl class="simple">
<dt>If a single axis is passed in, it is treated as a bounding axes</dt><dd><p>and a grid of partial dependence plots will be drawn within
these bounds. The <cite>n_cols</cite> parameter controls the number of
columns in the grid.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>If an array-like of axes are passed in, the partial dependence</dt><dd><p>plots will be drawn directly into these axes.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>If <cite>None</cite>, a figure and a bounding axes is created and treated</dt><dd><p>as the single axes case.</p>
</dd>
</dl>
</li>
</ul>
</p></li>
<li><p><strong>n_cols</strong> (<em>int</em><em>, </em><em>default=3</em>) – The maximum number of columns in the grid plot. Only active when
<cite>ax</cite> is a single axes or <cite>None</cite>.</p></li>
<li><p><strong>line_kw</strong> (<em>dict</em><em>, </em><em>default=None</em>) – Dict with keywords passed to the <cite>matplotlib.pyplot.plot</cite> call.
For one-way partial dependence plots.</p></li>
<li><p><strong>contour_kw</strong> (<em>dict</em><em>, </em><em>default=None</em>) – Dict with keywords passed to the <cite>matplotlib.pyplot.contourf</cite>
call for two-way partial dependence plots.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>display</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#sklearn.inspection.PartialDependenceDisplay" title="sklearn.inspection.PartialDependenceDisplay"><code class="xref py py-class docutils literal notranslate"><span class="pre">PartialDependenceDisplay</span></code></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sklearn.inspection.partial_dependence">
<span class="sig-prename descclassname"><span class="pre">sklearn.inspection.</span></span><span class="sig-name descname"><span class="pre">partial_dependence</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">estimator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">response_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">percentiles</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.05,</span> <span class="pre">0.95)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grid_resolution</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kind</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'legacy'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.inspection.partial_dependence" title="Permalink to this definition">¶</a></dt>
<dd><p>Partial dependence of <code class="docutils literal notranslate"><span class="pre">features</span></code>.</p>
<p>Partial dependence of a feature (or a set of features) corresponds to
the average response of an estimator for each possible value of the
feature.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>For <a class="reference internal" href="sklearn.ensemble.html#sklearn.ensemble.GradientBoostingClassifier" title="sklearn.ensemble.GradientBoostingClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingClassifier</span></code></a> and
<a class="reference internal" href="sklearn.ensemble.html#sklearn.ensemble.GradientBoostingRegressor" title="sklearn.ensemble.GradientBoostingRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingRegressor</span></code></a>, the
<cite>‘recursion’</cite> method (used by default) will not account for the <cite>init</cite>
predictor of the boosting process. In practice, this will produce
the same values as <cite>‘brute’</cite> up to a constant offset in the target
response, provided that <cite>init</cite> is a constant estimator (which is the
default). However, if <cite>init</cite> is not a constant estimator, the
partial dependence values are incorrect for <cite>‘recursion’</cite> because the
offset will be sample-dependent. It is preferable to use the <cite>‘brute’</cite>
method. Note that this only applies to
<a class="reference internal" href="sklearn.ensemble.html#sklearn.ensemble.GradientBoostingClassifier" title="sklearn.ensemble.GradientBoostingClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingClassifier</span></code></a> and
<a class="reference internal" href="sklearn.ensemble.html#sklearn.ensemble.GradientBoostingRegressor" title="sklearn.ensemble.GradientBoostingRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingRegressor</span></code></a>, not to
<a class="reference internal" href="sklearn.ensemble.html#sklearn.ensemble.HistGradientBoostingClassifier" title="sklearn.ensemble.HistGradientBoostingClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">HistGradientBoostingClassifier</span></code></a> and
<a class="reference internal" href="sklearn.ensemble.html#sklearn.ensemble.HistGradientBoostingRegressor" title="sklearn.ensemble.HistGradientBoostingRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">HistGradientBoostingRegressor</span></code></a>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>BaseEstimator</em>) – A fitted estimator object implementing <span class="xref std std-term">predict</span>,
<span class="xref std std-term">predict_proba</span>, or <span class="xref std std-term">decision_function</span>.
Multioutput-multiclass classifiers are not supported.</p></li>
<li><p><strong>X</strong> (<em>{array-like</em><em> or </em><em>dataframe} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – <code class="docutils literal notranslate"><span class="pre">X</span></code> is used to generate a grid of values for the target
<code class="docutils literal notranslate"><span class="pre">features</span></code> (where the partial dependence will be evaluated), and
also to generate values for the complement features when the
<cite>method</cite> is ‘brute’.</p></li>
<li><p><strong>features</strong> (<em>array-like of {int</em><em>, </em><em>str}</em>) – The feature (e.g. <cite>[0]</cite>) or pair of interacting features
(e.g. <cite>[(0, 1)]</cite>) for which the partial dependency should be computed.</p></li>
<li><p><strong>response_method</strong> (<em>{'auto'</em><em>, </em><em>'predict_proba'</em><em>, </em><em>'decision_function'}</em><em>,             </em><em>default='auto'</em>) – Specifies whether to use <span class="xref std std-term">predict_proba</span> or
<span class="xref std std-term">decision_function</span> as the target response. For regressors
this parameter is ignored and the response is always the output of
<span class="xref std std-term">predict</span>. By default, <span class="xref std std-term">predict_proba</span> is tried first
and we revert to <span class="xref std std-term">decision_function</span> if it doesn’t exist. If
<code class="docutils literal notranslate"><span class="pre">method</span></code> is ‘recursion’, the response is always the output of
<span class="xref std std-term">decision_function</span>.</p></li>
<li><p><strong>percentiles</strong> (<em>tuple of float</em><em>, </em><em>default=</em><em>(</em><em>0.05</em><em>, </em><em>0.95</em><em>)</em>) – The lower and upper percentile used to create the extreme values
for the grid. Must be in [0, 1].</p></li>
<li><p><strong>grid_resolution</strong> (<em>int</em><em>, </em><em>default=100</em>) – The number of equally spaced points on the grid, for each target
feature.</p></li>
<li><p><strong>method</strong> (<em>{'auto'</em><em>, </em><em>'recursion'</em><em>, </em><em>'brute'}</em><em>, </em><em>default='auto'</em>) – <p>The method used to calculate the averaged predictions:</p>
<ul>
<li><p><cite>’recursion’</cite> is only supported for some tree-based estimators
(namely
<a class="reference internal" href="sklearn.ensemble.html#sklearn.ensemble.GradientBoostingClassifier" title="sklearn.ensemble.GradientBoostingClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingClassifier</span></code></a>,
<a class="reference internal" href="sklearn.ensemble.html#sklearn.ensemble.GradientBoostingRegressor" title="sklearn.ensemble.GradientBoostingRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingRegressor</span></code></a>,
<a class="reference internal" href="sklearn.ensemble.html#sklearn.ensemble.HistGradientBoostingClassifier" title="sklearn.ensemble.HistGradientBoostingClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">HistGradientBoostingClassifier</span></code></a>,
<a class="reference internal" href="sklearn.ensemble.html#sklearn.ensemble.HistGradientBoostingRegressor" title="sklearn.ensemble.HistGradientBoostingRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">HistGradientBoostingRegressor</span></code></a>,
<a class="reference internal" href="sklearn.tree.html#sklearn.tree.DecisionTreeRegressor" title="sklearn.tree.DecisionTreeRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">DecisionTreeRegressor</span></code></a>,
<a class="reference internal" href="sklearn.ensemble.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomForestRegressor</span></code></a>,
) when <cite>kind=’average’</cite>.
This is more efficient in terms of speed.
With this method, the target response of a
classifier is always the decision function, not the predicted
probabilities. Since the <cite>‘recursion’</cite> method implicitely computes
the average of the Individual Conditional Expectation (ICE) by
design, it is not compatible with ICE and thus <cite>kind</cite> must be
<cite>‘average’</cite>.</p></li>
<li><p><cite>’brute’</cite> is supported for any estimator, but is more
computationally intensive.</p></li>
<li><p><cite>’auto’</cite>: the <cite>‘recursion’</cite> is used for estimators that support it,
and <cite>‘brute’</cite> is used otherwise.</p></li>
</ul>
<p>Please see <span class="xref std std-ref">this note</span> for
differences between the <cite>‘brute’</cite> and <cite>‘recursion’</cite> method.</p>
</p></li>
<li><p><strong>kind</strong> (<em>{'legacy'</em><em>, </em><em>'average'</em><em>, </em><em>'individual'</em><em>, </em><em>'both'}</em><em>, </em><em>default='legacy'</em>) – <p>Whether to return the partial dependence averaged across all the
samples in the dataset or one line per sample or both.
See Returns below.</p>
<p>Note that the fast <cite>method=’recursion’</cite> option is only available for
<cite>kind=’average’</cite>. Plotting individual dependencies requires using the
slower <cite>method=’brute’</cite> option.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 0.24: </span><cite>kind=’legacy’</cite> is deprecated and will be removed in version 1.1.
<cite>kind=’average’</cite> will be the new default. It is intended to migrate
from the ndarray output to <code class="xref py py-class docutils literal notranslate"><span class="pre">Bunch</span></code> output.</p>
</div>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul>
<li><p><strong>predictions</strong> (ndarray or <code class="xref py py-class docutils literal notranslate"><span class="pre">Bunch</span></code>) –</p>
<ul>
<li><dl class="simple">
<dt>if <cite>kind=’legacy’</cite>, return value is ndarray of shape (n_outputs,                 len(values[0]), len(values[1]), …)</dt><dd><p>The predictions for all the points in the grid, averaged
over all samples in X (or over the training data if <code class="docutils literal notranslate"><span class="pre">method</span></code>
is ‘recursion’).</p>
</dd>
</dl>
</li>
<li><dl>
<dt>if <cite>kind=’individual’</cite>, <cite>‘average’</cite> or <cite>‘both’</cite>, return value is                 <code class="xref py py-class docutils literal notranslate"><span class="pre">Bunch</span></code></dt><dd><p>Dictionary-like object, with the following attributes.</p>
<dl class="simple">
<dt>individual<span class="classifier">ndarray of shape (n_outputs, n_instances,                     len(values[0]), len(values[1]), …)</span></dt><dd><p>The predictions for all the points in the grid for all
samples in X. This is also known as Individual
Conditional Expectation (ICE)</p>
</dd>
<dt>average<span class="classifier">ndarray of shape (n_outputs, len(values[0]),                     len(values[1]), …)</span></dt><dd><p>The predictions for all the points in the grid, averaged
over all samples in X (or over the training data if
<code class="docutils literal notranslate"><span class="pre">method</span></code> is ‘recursion’).
Only available when kind=’both’.</p>
</dd>
<dt>values<span class="classifier">seq of 1d ndarrays</span></dt><dd><p>The values with which the grid has been created. The generated
grid is a cartesian product of the arrays in <code class="docutils literal notranslate"><span class="pre">values</span></code>.
<code class="docutils literal notranslate"><span class="pre">len(values)</span> <span class="pre">==</span> <span class="pre">len(features)</span></code>. The size of each array
<code class="docutils literal notranslate"><span class="pre">values[j]</span></code> is either <code class="docutils literal notranslate"><span class="pre">grid_resolution</span></code>, or the number of
unique values in <code class="docutils literal notranslate"><span class="pre">X[:,</span> <span class="pre">j]</span></code>, whichever is smaller.</p>
</dd>
</dl>
</dd>
</dl>
</li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">n_outputs</span></code> corresponds to the number of classes in a multi-class
setting, or to the number of tasks for multi-output regression.
For classical regression and binary classification <code class="docutils literal notranslate"><span class="pre">n_outputs==1</span></code>.
<code class="docutils literal notranslate"><span class="pre">n_values_feature_j</span></code> corresponds to the size <code class="docutils literal notranslate"><span class="pre">values[j]</span></code>.</p>
</li>
<li><p><strong>values</strong> (<em>seq of 1d ndarrays</em>) – The values with which the grid has been created. The generated grid
is a cartesian product of the arrays in <code class="docutils literal notranslate"><span class="pre">values</span></code>. <code class="docutils literal notranslate"><span class="pre">len(values)</span> <span class="pre">==</span>
<span class="pre">len(features)</span></code>. The size of each array <code class="docutils literal notranslate"><span class="pre">values[j]</span></code> is either
<code class="docutils literal notranslate"><span class="pre">grid_resolution</span></code>, or the number of unique values in <code class="docutils literal notranslate"><span class="pre">X[:,</span> <span class="pre">j]</span></code>,
whichever is smaller. Only available when <cite>kind=”legacy”</cite>.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.inspection.plot_partial_dependence" title="sklearn.inspection.plot_partial_dependence"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_partial_dependence</span></code></a></dt><dd><p>Plot Partial Dependence.</p>
</dd>
<dt><a class="reference internal" href="#sklearn.inspection.PartialDependenceDisplay" title="sklearn.inspection.PartialDependenceDisplay"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PartialDependenceDisplay</span></code></a></dt><dd><p>Partial Dependence visualization.</p>
</dd>
</dl>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gb</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">partial_dependence</span><span class="p">(</span><span class="n">gb</span><span class="p">,</span> <span class="n">features</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">percentiles</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
<span class="gp">... </span>                   <span class="n">grid_resolution</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> 
<span class="go">(array([[-4.52...,  4.52...]]), [array([ 0.,  1.])])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sklearn.inspection.permutation_importance">
<span class="sig-prename descclassname"><span class="pre">sklearn.inspection.</span></span><span class="sig-name descname"><span class="pre">permutation_importance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">estimator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_repeats</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.inspection.permutation_importance" title="Permalink to this definition">¶</a></dt>
<dd><p>Permutation importance for feature evaluation <a class="reference internal" href="#bre" id="id1"><span>[BRE]</span></a>.</p>
<p>The <span class="xref std std-term">estimator</span> is required to be a fitted estimator. <cite>X</cite> can be the
data set used to train the estimator or a hold-out set. The permutation
importance of a feature is calculated as follows. First, a baseline metric,
defined by <span class="xref std std-term">scoring</span>, is evaluated on a (potentially different)
dataset defined by the <cite>X</cite>. Next, a feature column from the validation set
is permuted and the metric is evaluated again. The permutation importance
is defined to be the difference between the baseline metric and metric from
permutating the feature column.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>object</em>) – An estimator that has already been <span class="xref std std-term">fitted</span> and is compatible
with <span class="xref std std-term">scorer</span>.</p></li>
<li><p><strong>X</strong> (<em>ndarray</em><em> or </em><em>DataFrame</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Data on which permutation importance will be computed.</p></li>
<li><p><strong>y</strong> (<em>array-like</em><em> or </em><em>None</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>) or </em><em>(</em><em>n_samples</em><em>, </em><em>n_classes</em><em>)</em>) – Targets for supervised or <cite>None</cite> for unsupervised.</p></li>
<li><p><strong>scoring</strong> (<em>str</em><em>, </em><em>callable</em><em>, </em><em>list</em><em>, </em><em>tuple</em><em>, or </em><em>dict</em><em>, </em><em>default=None</em>) – <p>Scorer to use.
If <cite>scoring</cite> represents a single score, one can use:</p>
<ul>
<li><p>a single string (see <span class="xref std std-ref">scoring_parameter</span>);</p></li>
<li><p>a callable (see <span class="xref std std-ref">scoring</span>) that returns a single value.</p></li>
</ul>
<p>If <cite>scoring</cite> represents multiple scores, one can use:</p>
<ul>
<li><p>a list or tuple of unique strings;</p></li>
<li><p>a callable returning a dictionary where the keys are the metric
names and the values are the metric scores;</p></li>
<li><p>a dictionary with metric names as keys and callables a values.</p></li>
</ul>
<p>Passing multiple scores to <cite>scoring</cite> is more efficient than calling
<cite>permutation_importance</cite> for each of the scores as it reuses
predictions to avoid redundant computation.</p>
<p>If None, the estimator’s default scorer is used.</p>
</p></li>
<li><p><strong>n_repeats</strong> (<em>int</em><em>, </em><em>default=5</em>) – Number of times to permute a feature.</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Number of jobs to run in parallel. The computation is done by computing
permutation score for each columns and parallelized over the columns.
<cite>None</cite> means 1 unless in a <code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context.
<cite>-1</cite> means using all processors. See <span class="xref std std-term">Glossary</span>
for more details.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em>, </em><em>default=None</em>) – Pseudo-random number generator to control the permutations of each
feature.
Pass an int to get reproducible results across function calls.
See :term: <cite>Glossary &lt;random_state&gt;</cite>.</p></li>
<li><p><strong>sample_weight</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – <p>Sample weights used in scoring.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p><strong>result</strong> – Dictionary-like object, with the following attributes.</p>
<dl class="simple">
<dt>importances_mean<span class="classifier">ndarray of shape (n_features, )</span></dt><dd><p>Mean of feature importance over <cite>n_repeats</cite>.</p>
</dd>
<dt>importances_std<span class="classifier">ndarray of shape (n_features, )</span></dt><dd><p>Standard deviation over <cite>n_repeats</cite>.</p>
</dd>
<dt>importances<span class="classifier">ndarray of shape (n_features, n_repeats)</span></dt><dd><p>Raw permutation importance scores.</p>
</dd>
</dl>
<p>If there are multiple scoring metrics in the scoring parameter
<cite>result</cite> is a dict with scorer names as keys (e.g. ‘roc_auc’) and
<cite>Bunch</cite> objects like above as values.</p>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Bunch</span></code> or dict of such instances</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="bre"><span class="brackets"><a class="fn-backref" href="#id1">BRE</a></span></dt>
<dd><p>L. Breiman, “Random Forests”, Machine Learning, 45(1), 5-32,
2001. <a class="reference external" href="https://doi.org/10.1023/A:1010933404324">https://doi.org/10.1023/A:1010933404324</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.inspection</span> <span class="kn">import</span> <span class="n">permutation_importance</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span>
<span class="gp">... </span>     <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">permutation_importance</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>                                <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span><span class="o">.</span><span class="n">importances_mean</span>
<span class="go">array([0.4666..., 0.       , 0.       ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span><span class="o">.</span><span class="n">importances_std</span>
<span class="go">array([0.2211..., 0.       , 0.       ])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sklearn.inspection.plot_partial_dependence">
<span class="sig-prename descclassname"><span class="pre">sklearn.inspection.</span></span><span class="sig-name descname"><span class="pre">plot_partial_dependence</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">estimator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">response_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_cols</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grid_resolution</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">percentiles</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.05,</span> <span class="pre">0.95)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">line_kw</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">contour_kw</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kind</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'average'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.inspection.plot_partial_dependence" title="Permalink to this definition">¶</a></dt>
<dd><p>Partial dependence (PD) and individual conditional expectation (ICE)
plots.</p>
<p>Partial dependence plots, individual conditional expectation plots or an
overlay of both of them can be plotted by setting the <code class="docutils literal notranslate"><span class="pre">kind</span></code>
parameter.
The <code class="docutils literal notranslate"><span class="pre">len(features)</span></code> plots are arranged in a grid with <code class="docutils literal notranslate"><span class="pre">n_cols</span></code>
columns. Two-way partial dependence plots are plotted as contour plots. The
deciles of the feature values will be shown with tick marks on the x-axes
for one-way plots, and on both axes for two-way plots.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sklearn.inspection.plot_partial_dependence" title="sklearn.inspection.plot_partial_dependence"><code class="xref py py-func docutils literal notranslate"><span class="pre">plot_partial_dependence()</span></code></a> does not support using the same axes
with multiple calls. To plot the the partial dependence for multiple
estimators, please pass the axes created by the first call to the
second call:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.inspection</span> <span class="kn">import</span> <span class="n">plot_partial_dependence</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_friedman1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_friedman1</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">est1</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">est2</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">disp1</span> <span class="o">=</span> <span class="n">plot_partial_dependence</span><span class="p">(</span><span class="n">est1</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span>
<span class="gp">... </span>                                <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>  
<span class="gp">&gt;&gt;&gt; </span><span class="n">disp2</span> <span class="o">=</span> <span class="n">plot_partial_dependence</span><span class="p">(</span><span class="n">est2</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
<span class="gp">... </span>                                <span class="n">ax</span><span class="o">=</span><span class="n">disp1</span><span class="o">.</span><span class="n">axes_</span><span class="p">)</span>  
</pre></div>
</div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>For <a class="reference internal" href="sklearn.ensemble.html#sklearn.ensemble.GradientBoostingClassifier" title="sklearn.ensemble.GradientBoostingClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingClassifier</span></code></a> and
<a class="reference internal" href="sklearn.ensemble.html#sklearn.ensemble.GradientBoostingRegressor" title="sklearn.ensemble.GradientBoostingRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingRegressor</span></code></a>, the
<cite>‘recursion’</cite> method (used by default) will not account for the <cite>init</cite>
predictor of the boosting process. In practice, this will produce
the same values as <cite>‘brute’</cite> up to a constant offset in the target
response, provided that <cite>init</cite> is a constant estimator (which is the
default). However, if <cite>init</cite> is not a constant estimator, the
partial dependence values are incorrect for <cite>‘recursion’</cite> because the
offset will be sample-dependent. It is preferable to use the <cite>‘brute’</cite>
method. Note that this only applies to
<a class="reference internal" href="sklearn.ensemble.html#sklearn.ensemble.GradientBoostingClassifier" title="sklearn.ensemble.GradientBoostingClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingClassifier</span></code></a> and
<a class="reference internal" href="sklearn.ensemble.html#sklearn.ensemble.GradientBoostingRegressor" title="sklearn.ensemble.GradientBoostingRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingRegressor</span></code></a>, not to
<a class="reference internal" href="sklearn.ensemble.html#sklearn.ensemble.HistGradientBoostingClassifier" title="sklearn.ensemble.HistGradientBoostingClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">HistGradientBoostingClassifier</span></code></a> and
<a class="reference internal" href="sklearn.ensemble.html#sklearn.ensemble.HistGradientBoostingRegressor" title="sklearn.ensemble.HistGradientBoostingRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">HistGradientBoostingRegressor</span></code></a>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>BaseEstimator</em>) – A fitted estimator object implementing <span class="xref std std-term">predict</span>,
<span class="xref std std-term">predict_proba</span>, or <span class="xref std std-term">decision_function</span>.
Multioutput-multiclass classifiers are not supported.</p></li>
<li><p><strong>X</strong> (<em>{array-like</em><em> or </em><em>dataframe} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – <code class="docutils literal notranslate"><span class="pre">X</span></code> is used to generate a grid of values for the target
<code class="docutils literal notranslate"><span class="pre">features</span></code> (where the partial dependence will be evaluated), and
also to generate values for the complement features when the
<cite>method</cite> is <cite>‘brute’</cite>.</p></li>
<li><p><strong>features</strong> (<em>list of {int</em><em>, </em><em>str</em><em>, </em><em>pair of int</em><em>, </em><em>pair of str}</em>) – The target features for which to create the PDPs.
If <cite>features[i]</cite> is an integer or a string, a one-way PDP is created;
if <cite>features[i]</cite> is a tuple, a two-way PDP is created (only supported
with <cite>kind=’average’</cite>). Each tuple must be of size 2.
if any entry is a string, then it must be in <code class="docutils literal notranslate"><span class="pre">feature_names</span></code>.</p></li>
<li><p><strong>feature_names</strong> (<em>array-like of shape</em><em> (</em><em>n_features</em><em>,</em><em>)</em><em>, </em><em>dtype=str</em><em>, </em><em>default=None</em>) – Name of each feature; <cite>feature_names[i]</cite> holds the name of the feature
with index <cite>i</cite>.
By default, the name of the feature corresponds to their numerical
index for NumPy array and their column name for pandas dataframe.</p></li>
<li><p><strong>target</strong> (<em>int</em><em>, </em><em>default=None</em>) – <ul>
<li><p>In a multiclass setting, specifies the class for which the PDPs
should be computed. Note that for binary classification, the
positive class (index 1) is always used.</p></li>
<li><p>In a multioutput setting, specifies the task for which the PDPs
should be computed.</p></li>
</ul>
<p>Ignored in binary classification or classical regression settings.</p>
</p></li>
<li><p><strong>response_method</strong> (<em>{'auto'</em><em>, </em><em>'predict_proba'</em><em>, </em><em>'decision_function'}</em><em>,             </em><em>default='auto'</em>) – Specifies whether to use <span class="xref std std-term">predict_proba</span> or
<span class="xref std std-term">decision_function</span> as the target response. For regressors
this parameter is ignored and the response is always the output of
<span class="xref std std-term">predict</span>. By default, <span class="xref std std-term">predict_proba</span> is tried first
and we revert to <span class="xref std std-term">decision_function</span> if it doesn’t exist. If
<code class="docutils literal notranslate"><span class="pre">method</span></code> is <cite>‘recursion’</cite>, the response is always the output of
<span class="xref std std-term">decision_function</span>.</p></li>
<li><p><strong>n_cols</strong> (<em>int</em><em>, </em><em>default=3</em>) – The maximum number of columns in the grid plot. Only active when <cite>ax</cite>
is a single axis or <cite>None</cite>.</p></li>
<li><p><strong>grid_resolution</strong> (<em>int</em><em>, </em><em>default=100</em>) – The number of equally spaced points on the axes of the plots, for each
target feature.</p></li>
<li><p><strong>percentiles</strong> (<em>tuple of float</em><em>, </em><em>default=</em><em>(</em><em>0.05</em><em>, </em><em>0.95</em><em>)</em>) – The lower and upper percentile used to create the extreme values
for the PDP axes. Must be in [0, 1].</p></li>
<li><p><strong>method</strong> (<em>str</em><em>, </em><em>default='auto'</em>) – <p>The method used to calculate the averaged predictions:</p>
<ul>
<li><p><cite>’recursion’</cite> is only supported for some tree-based estimators
(namely
<a class="reference internal" href="sklearn.ensemble.html#sklearn.ensemble.GradientBoostingClassifier" title="sklearn.ensemble.GradientBoostingClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingClassifier</span></code></a>,
<a class="reference internal" href="sklearn.ensemble.html#sklearn.ensemble.GradientBoostingRegressor" title="sklearn.ensemble.GradientBoostingRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingRegressor</span></code></a>,
<a class="reference internal" href="sklearn.ensemble.html#sklearn.ensemble.HistGradientBoostingClassifier" title="sklearn.ensemble.HistGradientBoostingClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">HistGradientBoostingClassifier</span></code></a>,
<a class="reference internal" href="sklearn.ensemble.html#sklearn.ensemble.HistGradientBoostingRegressor" title="sklearn.ensemble.HistGradientBoostingRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">HistGradientBoostingRegressor</span></code></a>,
<a class="reference internal" href="sklearn.tree.html#sklearn.tree.DecisionTreeRegressor" title="sklearn.tree.DecisionTreeRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">DecisionTreeRegressor</span></code></a>,
<a class="reference internal" href="sklearn.ensemble.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomForestRegressor</span></code></a>
but is more efficient in terms of speed.
With this method, the target response of a
classifier is always the decision function, not the predicted
probabilities. Since the <cite>‘recursion’</cite> method implicitely computes
the average of the ICEs by design, it is not compatible with ICE and
thus <cite>kind</cite> must be <cite>‘average’</cite>.</p></li>
<li><p><cite>’brute’</cite> is supported for any estimator, but is more
computationally intensive.</p></li>
<li><p><cite>’auto’</cite>: the <cite>‘recursion’</cite> is used for estimators that support it,
and <cite>‘brute’</cite> is used otherwise.</p></li>
</ul>
<p>Please see <span class="xref std std-ref">this note</span> for
differences between the <cite>‘brute’</cite> and <cite>‘recursion’</cite> method.</p>
</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default=None</em>) – <p>The number of CPUs to use to compute the partial dependences.
Computation is parallelized over features specified by the <cite>features</cite>
parameter.</p>
<p><code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a <code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context.
<code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all processors. See <span class="xref std std-term">Glossary</span>
for more details.</p>
</p></li>
<li><p><strong>verbose</strong> (<em>int</em><em>, </em><em>default=0</em>) – Verbose output during PD computations.</p></li>
<li><p><strong>line_kw</strong> (<em>dict</em><em>, </em><em>default=None</em>) – Dict with keywords passed to the <code class="docutils literal notranslate"><span class="pre">matplotlib.pyplot.plot</span></code> call.
For one-way partial dependence plots.</p></li>
<li><p><strong>contour_kw</strong> (<em>dict</em><em>, </em><em>default=None</em>) – Dict with keywords passed to the <code class="docutils literal notranslate"><span class="pre">matplotlib.pyplot.contourf</span></code> call.
For two-way partial dependence plots.</p></li>
<li><p><strong>ax</strong> (<em>Matplotlib axes</em><em> or </em><em>array-like of Matplotlib axes</em><em>, </em><em>default=None</em>) – <ul>
<li><p>If a single axis is passed in, it is treated as a bounding axes
and a grid of partial dependence plots will be drawn within
these bounds. The <cite>n_cols</cite> parameter controls the number of
columns in the grid.</p></li>
<li><p>If an array-like of axes are passed in, the partial dependence
plots will be drawn directly into these axes.</p></li>
<li><p>If <cite>None</cite>, a figure and a bounding axes is created and treated
as the single axes case.</p></li>
</ul>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.22.</span></p>
</div>
</p></li>
<li><p><strong>kind</strong> (<em>{'average'</em><em>, </em><em>'individual'</em><em>, </em><em>'both'}</em><em>, </em><em>default='average'</em>) – <dl class="simple">
<dt>Whether to plot the partial dependence averaged across all the samples</dt><dd><p>in the dataset or one line per sample or both.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">kind='average'</span></code> results in the traditional PD plot;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kind='individual'</span></code> results in the ICE plot.</p></li>
</ul>
</dd>
</dl>
<p>Note that the fast <code class="docutils literal notranslate"><span class="pre">method='recursion'</span></code> option is only available for
<code class="docutils literal notranslate"><span class="pre">kind='average'</span></code>. Plotting individual dependencies requires using the
slower <code class="docutils literal notranslate"><span class="pre">method='brute'</span></code> option.</p>
<blockquote>
<div><div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
</div></blockquote>
</p></li>
<li><p><strong>subsample</strong> (<em>float</em><em>, </em><em>int</em><em> or </em><em>None</em><em>, </em><em>default=1000</em>) – <p>Sampling for ICE curves when <cite>kind</cite> is ‘individual’ or ‘both’.
If <cite>float</cite>, should be between 0.0 and 1.0 and represent the proportion
of the dataset to be used to plot ICE curves. If <cite>int</cite>, represents the
absolute number samples to use.</p>
<p>Note that the full dataset is still used to calculate averaged partial
dependence when <cite>kind=’both’</cite>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – <p>Controls the randomness of the selected samples when subsamples is not
<cite>None</cite> and <cite>kind</cite> is either <cite>‘both’</cite> or <cite>‘individual’</cite>.
See <span class="xref std std-term">Glossary</span> for details.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>display</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#sklearn.inspection.PartialDependenceDisplay" title="sklearn.inspection.PartialDependenceDisplay"><code class="xref py py-class docutils literal notranslate"><span class="pre">PartialDependenceDisplay</span></code></a></p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.inspection.partial_dependence" title="sklearn.inspection.partial_dependence"><code class="xref py py-obj docutils literal notranslate"><span class="pre">partial_dependence</span></code></a></dt><dd><p>Compute Partial Dependence values.</p>
</dd>
<dt><a class="reference internal" href="#sklearn.inspection.PartialDependenceDisplay" title="sklearn.inspection.PartialDependenceDisplay"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PartialDependenceDisplay</span></code></a></dt><dd><p>Partial Dependence visualization.</p>
</dd>
</dl>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_friedman1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_friedman1</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">GradientBoostingRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plot_partial_dependence</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)])</span> 
</pre></div>
</div>
</dd></dl>

</section>
</section>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, Tommaso Fioravanti

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>