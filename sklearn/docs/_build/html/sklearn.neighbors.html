

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>sklearn.neighbors package &mdash; sqlearn  documentation</title>
  

  
  
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> sqlearn
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="modules.html">sqlearn</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">sqlearn</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>sklearn.neighbors package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/sklearn.neighbors.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="sklearn-neighbors-package">
<h1>sklearn.neighbors package<a class="headerlink" href="#sklearn-neighbors-package" title="Permalink to this headline">¶</a></h1>
<section id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="sklearn.neighbors.tests.html">sklearn.neighbors.tests package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="sklearn.neighbors.tests.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.neighbors.tests.html#sklearn-neighbors-tests-test-ball-tree-module">sklearn.neighbors.tests.test_ball_tree module</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.neighbors.tests.html#sklearn-neighbors-tests-test-dist-metrics-module">sklearn.neighbors.tests.test_dist_metrics module</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.neighbors.tests.html#module-sklearn.neighbors.tests.test_graph">sklearn.neighbors.tests.test_graph module</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.neighbors.tests.html#sklearn-neighbors-tests-test-kd-tree-module">sklearn.neighbors.tests.test_kd_tree module</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.neighbors.tests.html#sklearn-neighbors-tests-test-kde-module">sklearn.neighbors.tests.test_kde module</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.neighbors.tests.html#sklearn-neighbors-tests-test-lof-module">sklearn.neighbors.tests.test_lof module</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.neighbors.tests.html#sklearn-neighbors-tests-test-nca-module">sklearn.neighbors.tests.test_nca module</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.neighbors.tests.html#sklearn-neighbors-tests-test-nearest-centroid-module">sklearn.neighbors.tests.test_nearest_centroid module</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.neighbors.tests.html#sklearn-neighbors-tests-test-neighbors-module">sklearn.neighbors.tests.test_neighbors module</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.neighbors.tests.html#module-sklearn.neighbors.tests.test_neighbors_pipeline">sklearn.neighbors.tests.test_neighbors_pipeline module</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.neighbors.tests.html#sklearn-neighbors-tests-test-neighbors-tree-module">sklearn.neighbors.tests.test_neighbors_tree module</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.neighbors.tests.html#sklearn-neighbors-tests-test-quad-tree-module">sklearn.neighbors.tests.test_quad_tree module</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.neighbors.tests.html#module-sklearn.neighbors.tests">Module contents</a></li>
</ul>
</li>
</ul>
</div>
</section>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</section>
<section id="module-sklearn.neighbors.setup">
<span id="sklearn-neighbors-setup-module"></span><h2>sklearn.neighbors.setup module<a class="headerlink" href="#module-sklearn.neighbors.setup" title="Permalink to this headline">¶</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="sklearn.neighbors.setup.configuration">
<span class="sig-prename descclassname"><span class="pre">sklearn.neighbors.setup.</span></span><span class="sig-name descname"><span class="pre">configuration</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parent_package</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.setup.configuration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</section>
<section id="module-sklearn.neighbors">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-sklearn.neighbors" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-sklearn.neighbors" title="sklearn.neighbors"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.neighbors</span></code></a> module implements the k-nearest neighbors
algorithm.</p>
<dl class="py class">
<dt class="sig sig-object py" id="sklearn.neighbors.BallTree">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.neighbors.</span></span><span class="sig-name descname"><span class="pre">BallTree</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">leaf_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">40</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'minkowski'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.BallTree" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.neighbors._ball_tree.BinaryTree</span></code></p>
<p>BallTree for fast generalized N-point problems</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – n_samples is the number of points in the data set, and
n_features is the dimension of the parameter space.
Note: if X is a C-contiguous array of doubles then data will
not be copied. Otherwise, an internal copy will be made.</p></li>
<li><p><strong>leaf_size</strong> (<em>positive int</em><em>, </em><em>default=40</em>) – Number of points at which to switch to brute-force. Changing
leaf_size will not affect the results of a query, but can
significantly impact the speed of a query and the memory required
to store the constructed tree.  The amount of memory needed to
store the tree scales as approximately n_samples / leaf_size.
For a specified <code class="docutils literal notranslate"><span class="pre">leaf_size</span></code>, a leaf node is guaranteed to
satisfy <code class="docutils literal notranslate"><span class="pre">leaf_size</span> <span class="pre">&lt;=</span> <span class="pre">n_points</span> <span class="pre">&lt;=</span> <span class="pre">2</span> <span class="pre">*</span> <span class="pre">leaf_size</span></code>, except in
the case that <code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">&lt;</span> <span class="pre">leaf_size</span></code>.</p></li>
<li><p><strong>metric</strong> (<em>str</em><em> or </em><em>DistanceMetric object</em>) – the distance metric to use for the tree.  Default=’minkowski’
with p=2 (that is, a euclidean metric). See the documentation
of the DistanceMetric class for a list of available metrics.
ball_tree.valid_metrics gives a list of the metrics which
are valid for BallTree.</p></li>
<li><p><strong>class.</strong> (<em>Additional keywords are passed to the distance metric</em>) – </p></li>
<li><p><strong>Note</strong> (<em>Callable functions in the metric parameter are NOT supported for KDTree</em>) – </p></li>
<li><p><strong>performance.</strong> (<em>and Ball Tree. Function call overhead will result in very poor</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.BallTree.data">
<span class="sig-name descname"><span class="pre">data</span></span><a class="headerlink" href="#sklearn.neighbors.BallTree.data" title="Permalink to this definition">¶</a></dt>
<dd><p>The training data</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>memory view</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<p>Query for k-nearest neighbors</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random_sample</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>  <span class="c1"># 10 points in 3 dimensions</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tree</span> <span class="o">=</span> <span class="n">BallTree</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">leaf_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>              
<span class="gp">&gt;&gt;&gt; </span><span class="n">dist</span><span class="p">,</span> <span class="n">ind</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">1</span><span class="p">],</span> <span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>                
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span>  <span class="c1"># indices of 3 closest neighbors</span>
<span class="go">[0 3 1]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span>  <span class="c1"># distances to 3 closest neighbors</span>
<span class="go">[ 0.          0.19662693  0.29473397]</span>
</pre></div>
</div>
<p>Pickle and Unpickle a tree.  Note that the state of the tree is saved in the
pickle operation: the tree needs not be rebuilt upon unpickling.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pickle</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random_sample</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>  <span class="c1"># 10 points in 3 dimensions</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tree</span> <span class="o">=</span> <span class="n">BallTree</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">leaf_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>        
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">tree</span><span class="p">)</span>                     
<span class="gp">&gt;&gt;&gt; </span><span class="n">tree_copy</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>                
<span class="gp">&gt;&gt;&gt; </span><span class="n">dist</span><span class="p">,</span> <span class="n">ind</span> <span class="o">=</span> <span class="n">tree_copy</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">1</span><span class="p">],</span> <span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>     
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span>  <span class="c1"># indices of 3 closest neighbors</span>
<span class="go">[0 3 1]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span>  <span class="c1"># distances to 3 closest neighbors</span>
<span class="go">[ 0.          0.19662693  0.29473397]</span>
</pre></div>
</div>
<p>Query for neighbors within a given radius</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random_sample</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>  <span class="c1"># 10 points in 3 dimensions</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tree</span> <span class="o">=</span> <span class="n">BallTree</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">leaf_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>     
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">tree</span><span class="o">.</span><span class="n">query_radius</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">1</span><span class="p">],</span> <span class="n">r</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">count_only</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ind</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">query_radius</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">1</span><span class="p">],</span> <span class="n">r</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>  
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span>  <span class="c1"># indices of neighbors within distance 0.3</span>
<span class="go">[3 0 1]</span>
</pre></div>
</div>
<p>Compute a gaussian kernel density estimate:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random_sample</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tree</span> <span class="o">=</span> <span class="n">BallTree</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>                
<span class="gp">&gt;&gt;&gt; </span><span class="n">tree</span><span class="o">.</span><span class="n">kernel_density</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">3</span><span class="p">],</span> <span class="n">h</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;gaussian&#39;</span><span class="p">)</span>
<span class="go">array([ 6.94114649,  7.83281226,  7.2071716 ])</span>
</pre></div>
</div>
<p>Compute a two-point auto-correlation function</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random_sample</span><span class="p">((</span><span class="mi">30</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tree</span> <span class="o">=</span> <span class="n">BallTree</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>                
<span class="gp">&gt;&gt;&gt; </span><span class="n">tree</span><span class="o">.</span><span class="n">two_point_correlation</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
<span class="go">array([ 30,  62, 278, 580, 820])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.neighbors.DistanceMetric">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.neighbors.</span></span><span class="sig-name descname"><span class="pre">DistanceMetric</span></span><a class="headerlink" href="#sklearn.neighbors.DistanceMetric" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>DistanceMetric class</p>
<p>This class provides a uniform interface to fast distance metric
functions.  The various metrics can be accessed via the <a class="reference internal" href="#sklearn.neighbors.DistanceMetric.get_metric" title="sklearn.neighbors.DistanceMetric.get_metric"><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_metric()</span></code></a>
class method and the metric string identifier (see below).</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">DistanceMetric</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dist</span> <span class="o">=</span> <span class="n">DistanceMetric</span><span class="o">.</span><span class="n">get_metric</span><span class="p">(</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
<span class="go">         [3, 4, 5]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dist</span><span class="o">.</span><span class="n">pairwise</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([[ 0.        ,  5.19615242],</span>
<span class="go">       [ 5.19615242,  0.        ]])</span>
</pre></div>
</div>
<p>Available Metrics</p>
<p>The following lists the string metric identifiers and the associated
distance metric classes:</p>
<p><strong>Metrics intended for real-valued vector spaces:</strong></p>
<table class="docutils align-default">
<colgroup>
<col style="width: 19%" />
<col style="width: 27%" />
<col style="width: 11%" />
<col style="width: 42%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>identifier</p></td>
<td><p>class name</p></td>
<td><p>args</p></td>
<td><p>distance function</p></td>
</tr>
<tr class="row-even"><td><p>“euclidean”</p></td>
<td><p>EuclideanDistance</p></td>
<td><ul class="simple">
<li></li>
</ul>
</td>
<td><p><code class="docutils literal notranslate"><span class="pre">sqrt(sum((x</span> <span class="pre">-</span> <span class="pre">y)^2))</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>“manhattan”</p></td>
<td><p>ManhattanDistance</p></td>
<td><ul class="simple">
<li></li>
</ul>
</td>
<td><p><code class="docutils literal notranslate"><span class="pre">sum(|x</span> <span class="pre">-</span> <span class="pre">y|)</span></code></p></td>
</tr>
<tr class="row-even"><td><p>“chebyshev”</p></td>
<td><p>ChebyshevDistance</p></td>
<td><ul class="simple">
<li></li>
</ul>
</td>
<td><p><code class="docutils literal notranslate"><span class="pre">max(|x</span> <span class="pre">-</span> <span class="pre">y|)</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>“minkowski”</p></td>
<td><p>MinkowskiDistance</p></td>
<td><p>p</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sum(|x</span> <span class="pre">-</span> <span class="pre">y|^p)^(1/p)</span></code></p></td>
</tr>
<tr class="row-even"><td><p>“wminkowski”</p></td>
<td><p>WMinkowskiDistance</p></td>
<td><p>p, w</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sum(|w</span> <span class="pre">*</span> <span class="pre">(x</span> <span class="pre">-</span> <span class="pre">y)|^p)^(1/p)</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>“seuclidean”</p></td>
<td><p>SEuclideanDistance</p></td>
<td><p>V</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sqrt(sum((x</span> <span class="pre">-</span> <span class="pre">y)^2</span> <span class="pre">/</span> <span class="pre">V))</span></code></p></td>
</tr>
<tr class="row-even"><td><p>“mahalanobis”</p></td>
<td><p>MahalanobisDistance</p></td>
<td><p>V or VI</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sqrt((x</span> <span class="pre">-</span> <span class="pre">y)'</span> <span class="pre">V^-1</span> <span class="pre">(x</span> <span class="pre">-</span> <span class="pre">y))</span></code></p></td>
</tr>
</tbody>
</table>
<p><strong>Metrics intended for two-dimensional vector spaces:</strong>  Note that the haversine
distance metric requires data in the form of [latitude, longitude] and both
inputs and outputs are in units of radians.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 13%" />
<col style="width: 19%" />
<col style="width: 68%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>identifier</p></td>
<td><p>class name</p></td>
<td><p>distance function</p></td>
</tr>
<tr class="row-even"><td><p>“haversine”</p></td>
<td><p>HaversineDistance</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">2</span> <span class="pre">arcsin(sqrt(sin^2(0.5*dx)</span> <span class="pre">+</span> <span class="pre">cos(x1)cos(x2)sin^2(0.5*dy)))</span></code></p></td>
</tr>
</tbody>
</table>
<p><strong>Metrics intended for integer-valued vector spaces:</strong>  Though intended
for integer-valued vectors, these are also valid metrics in the case of
real-valued vectors.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 18%" />
<col style="width: 27%" />
<col style="width: 55%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>identifier</p></td>
<td><p>class name</p></td>
<td><p>distance function</p></td>
</tr>
<tr class="row-even"><td><p>“hamming”</p></td>
<td><p>HammingDistance</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">N_unequal(x,</span> <span class="pre">y)</span> <span class="pre">/</span> <span class="pre">N_tot</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>“canberra”</p></td>
<td><p>CanberraDistance</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sum(|x</span> <span class="pre">-</span> <span class="pre">y|</span> <span class="pre">/</span> <span class="pre">(|x|</span> <span class="pre">+</span> <span class="pre">|y|))</span></code></p></td>
</tr>
<tr class="row-even"><td><p>“braycurtis”</p></td>
<td><p>BrayCurtisDistance</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sum(|x</span> <span class="pre">-</span> <span class="pre">y|)</span> <span class="pre">/</span> <span class="pre">(sum(|x|)</span> <span class="pre">+</span> <span class="pre">sum(|y|))</span></code></p></td>
</tr>
</tbody>
</table>
<p><strong>Metrics intended for boolean-valued vector spaces:</strong>  Any nonzero entry
is evaluated to “True”.  In the listings below, the following
abbreviations are used:</p>
<blockquote>
<div><ul class="simple">
<li><p>N  : number of dimensions</p></li>
<li><p>NTT : number of dims in which both values are True</p></li>
<li><p>NTF : number of dims in which the first value is True, second is False</p></li>
<li><p>NFT : number of dims in which the first value is False, second is True</p></li>
<li><p>NFF : number of dims in which both values are False</p></li>
<li><p>NNEQ : number of non-equal dimensions, NNEQ = NTF + NFT</p></li>
<li><p>NNZ : number of nonzero dimensions, NNZ = NTF + NFT + NTT</p></li>
</ul>
</div></blockquote>
<table class="docutils align-default">
<colgroup>
<col style="width: 24%" />
<col style="width: 32%" />
<col style="width: 44%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>identifier</p></td>
<td><p>class name</p></td>
<td><p>distance function</p></td>
</tr>
<tr class="row-even"><td><p>“jaccard”</p></td>
<td><p>JaccardDistance</p></td>
<td><p>NNEQ / NNZ</p></td>
</tr>
<tr class="row-odd"><td><p>“matching”</p></td>
<td><p>MatchingDistance</p></td>
<td><p>NNEQ / N</p></td>
</tr>
<tr class="row-even"><td><p>“dice”</p></td>
<td><p>DiceDistance</p></td>
<td><p>NNEQ / (NTT + NNZ)</p></td>
</tr>
<tr class="row-odd"><td><p>“kulsinski”</p></td>
<td><p>KulsinskiDistance</p></td>
<td><p>(NNEQ + N - NTT) / (NNEQ + N)</p></td>
</tr>
<tr class="row-even"><td><p>“rogerstanimoto”</p></td>
<td><p>RogersTanimotoDistance</p></td>
<td><p>2 * NNEQ / (N + NNEQ)</p></td>
</tr>
<tr class="row-odd"><td><p>“russellrao”</p></td>
<td><p>RussellRaoDistance</p></td>
<td><p>(N - NTT) / N</p></td>
</tr>
<tr class="row-even"><td><p>“sokalmichener”</p></td>
<td><p>SokalMichenerDistance</p></td>
<td><p>2 * NNEQ / (N + NNEQ)</p></td>
</tr>
<tr class="row-odd"><td><p>“sokalsneath”</p></td>
<td><p>SokalSneathDistance</p></td>
<td><p>NNEQ / (NNEQ + 0.5 * NTT)</p></td>
</tr>
</tbody>
</table>
<p><strong>User-defined distance:</strong></p>
<table class="docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 45%" />
<col style="width: 21%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>identifier</p></td>
<td><p>class name</p></td>
<td><p>args</p></td>
</tr>
<tr class="row-even"><td><p>“pyfunc”</p></td>
<td><p>PyFuncDistance</p></td>
<td><p>func</p></td>
</tr>
</tbody>
</table>
<p>Here <code class="docutils literal notranslate"><span class="pre">func</span></code> is a function which takes two one-dimensional numpy
arrays, and returns a distance.  Note that in order to be used within
the BallTree, the distance must be a true metric:
i.e. it must satisfy the following properties</p>
<ol class="arabic simple">
<li><p>Non-negativity: d(x, y) &gt;= 0</p></li>
<li><p>Identity: d(x, y) = 0 if and only if x == y</p></li>
<li><p>Symmetry: d(x, y) = d(y, x)</p></li>
<li><p>Triangle Inequality: d(x, y) + d(y, z) &gt;= d(x, z)</p></li>
</ol>
<p>Because of the Python object overhead involved in calling the python
function, this will be fairly slow, but it will have the same
scaling as other distances.</p>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.DistanceMetric.dist_to_rdist">
<span class="sig-name descname"><span class="pre">dist_to_rdist</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.DistanceMetric.dist_to_rdist" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert the true distance to the reduced distance.</p>
<p>The reduced distance, defined for some metrics, is a computationally
more efficient measure which preserves the rank of the true distance.
For example, in the Euclidean distance metric, the reduced distance
is the squared-euclidean distance.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.DistanceMetric.get_metric">
<span class="sig-name descname"><span class="pre">get_metric</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.DistanceMetric.get_metric" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the given distance metric from the string identifier.</p>
<p>See the docstring of DistanceMetric for a list of available metrics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metric</strong> (<em>string</em><em> or </em><em>class name</em>) – The distance metric to use</p></li>
<li><p><strong>**kwargs</strong> – additional arguments will be passed to the requested metric</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.DistanceMetric.pairwise">
<span class="sig-name descname"><span class="pre">pairwise</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.DistanceMetric.pairwise" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the pairwise distances between X and Y</p>
<p>This is a convenience routine for the sake of testing.  For many
metrics, the utilities in scipy.spatial.distance.cdist and
scipy.spatial.distance.pdist will be faster.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like</em>) – Array of shape (Nx, D), representing Nx points in D dimensions.</p></li>
<li><p><strong>Y</strong> (<em>array-like</em><em> (</em><em>optional</em><em>)</em>) – Array of shape (Ny, D), representing Ny points in D dimensions.
If not specified, then Y=X.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>dist</strong> – The shape (Nx, Ny) array of pairwise distances between points in
X and Y.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.DistanceMetric.rdist_to_dist">
<span class="sig-name descname"><span class="pre">rdist_to_dist</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.DistanceMetric.rdist_to_dist" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert the Reduced distance to the true distance.</p>
<p>The reduced distance, defined for some metrics, is a computationally
more efficient measure which preserves the rank of the true distance.
For example, in the Euclidean distance metric, the reduced distance
is the squared-euclidean distance.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.neighbors.KDTree">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.neighbors.</span></span><span class="sig-name descname"><span class="pre">KDTree</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">leaf_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">40</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'minkowski'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.KDTree" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.neighbors._kd_tree.BinaryTree</span></code></p>
<p>KDTree for fast generalized N-point problems</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – n_samples is the number of points in the data set, and
n_features is the dimension of the parameter space.
Note: if X is a C-contiguous array of doubles then data will
not be copied. Otherwise, an internal copy will be made.</p></li>
<li><p><strong>leaf_size</strong> (<em>positive int</em><em>, </em><em>default=40</em>) – Number of points at which to switch to brute-force. Changing
leaf_size will not affect the results of a query, but can
significantly impact the speed of a query and the memory required
to store the constructed tree.  The amount of memory needed to
store the tree scales as approximately n_samples / leaf_size.
For a specified <code class="docutils literal notranslate"><span class="pre">leaf_size</span></code>, a leaf node is guaranteed to
satisfy <code class="docutils literal notranslate"><span class="pre">leaf_size</span> <span class="pre">&lt;=</span> <span class="pre">n_points</span> <span class="pre">&lt;=</span> <span class="pre">2</span> <span class="pre">*</span> <span class="pre">leaf_size</span></code>, except in
the case that <code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">&lt;</span> <span class="pre">leaf_size</span></code>.</p></li>
<li><p><strong>metric</strong> (<em>str</em><em> or </em><em>DistanceMetric object</em>) – the distance metric to use for the tree.  Default=’minkowski’
with p=2 (that is, a euclidean metric). See the documentation
of the DistanceMetric class for a list of available metrics.
kd_tree.valid_metrics gives a list of the metrics which
are valid for KDTree.</p></li>
<li><p><strong>class.</strong> (<em>Additional keywords are passed to the distance metric</em>) – </p></li>
<li><p><strong>Note</strong> (<em>Callable functions in the metric parameter are NOT supported for KDTree</em>) – </p></li>
<li><p><strong>performance.</strong> (<em>and Ball Tree. Function call overhead will result in very poor</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.KDTree.data">
<span class="sig-name descname"><span class="pre">data</span></span><a class="headerlink" href="#sklearn.neighbors.KDTree.data" title="Permalink to this definition">¶</a></dt>
<dd><p>The training data</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>memory view</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<p>Query for k-nearest neighbors</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random_sample</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>  <span class="c1"># 10 points in 3 dimensions</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tree</span> <span class="o">=</span> <span class="n">KDTree</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">leaf_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>              
<span class="gp">&gt;&gt;&gt; </span><span class="n">dist</span><span class="p">,</span> <span class="n">ind</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">1</span><span class="p">],</span> <span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>                
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span>  <span class="c1"># indices of 3 closest neighbors</span>
<span class="go">[0 3 1]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span>  <span class="c1"># distances to 3 closest neighbors</span>
<span class="go">[ 0.          0.19662693  0.29473397]</span>
</pre></div>
</div>
<p>Pickle and Unpickle a tree.  Note that the state of the tree is saved in the
pickle operation: the tree needs not be rebuilt upon unpickling.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pickle</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random_sample</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>  <span class="c1"># 10 points in 3 dimensions</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tree</span> <span class="o">=</span> <span class="n">KDTree</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">leaf_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>        
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">tree</span><span class="p">)</span>                     
<span class="gp">&gt;&gt;&gt; </span><span class="n">tree_copy</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>                
<span class="gp">&gt;&gt;&gt; </span><span class="n">dist</span><span class="p">,</span> <span class="n">ind</span> <span class="o">=</span> <span class="n">tree_copy</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">1</span><span class="p">],</span> <span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>     
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span>  <span class="c1"># indices of 3 closest neighbors</span>
<span class="go">[0 3 1]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span>  <span class="c1"># distances to 3 closest neighbors</span>
<span class="go">[ 0.          0.19662693  0.29473397]</span>
</pre></div>
</div>
<p>Query for neighbors within a given radius</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random_sample</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>  <span class="c1"># 10 points in 3 dimensions</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tree</span> <span class="o">=</span> <span class="n">KDTree</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">leaf_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>     
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">tree</span><span class="o">.</span><span class="n">query_radius</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">1</span><span class="p">],</span> <span class="n">r</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">count_only</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ind</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">query_radius</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">1</span><span class="p">],</span> <span class="n">r</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>  
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span>  <span class="c1"># indices of neighbors within distance 0.3</span>
<span class="go">[3 0 1]</span>
</pre></div>
</div>
<p>Compute a gaussian kernel density estimate:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random_sample</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tree</span> <span class="o">=</span> <span class="n">KDTree</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>                
<span class="gp">&gt;&gt;&gt; </span><span class="n">tree</span><span class="o">.</span><span class="n">kernel_density</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">3</span><span class="p">],</span> <span class="n">h</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;gaussian&#39;</span><span class="p">)</span>
<span class="go">array([ 6.94114649,  7.83281226,  7.2071716 ])</span>
</pre></div>
</div>
<p>Compute a two-point auto-correlation function</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random_sample</span><span class="p">((</span><span class="mi">30</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tree</span> <span class="o">=</span> <span class="n">KDTree</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>                
<span class="gp">&gt;&gt;&gt; </span><span class="n">tree</span><span class="o">.</span><span class="n">two_point_correlation</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
<span class="go">array([ 30,  62, 278, 580, 820])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.neighbors.KNeighborsClassifier">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.neighbors.</span></span><span class="sig-name descname"><span class="pre">KNeighborsClassifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_neighbors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'uniform'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">leaf_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">30</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'minkowski'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.KNeighborsClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.neighbors._base.KNeighborsMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.ClassifierMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.neighbors._base.NeighborsBase</span></code></p>
<p>Classifier implementing the k-nearest neighbors vote.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_neighbors</strong> (<em>int</em><em>, </em><em>default=5</em>) – Number of neighbors to use by default for <code class="xref py py-meth docutils literal notranslate"><span class="pre">kneighbors()</span></code> queries.</p></li>
<li><p><strong>weights</strong> (<em>{'uniform'</em><em>, </em><em>'distance'}</em><em> or </em><em>callable</em><em>, </em><em>default='uniform'</em>) – <p>weight function used in prediction.  Possible values:</p>
<ul>
<li><p>’uniform’ : uniform weights.  All points in each neighborhood
are weighted equally.</p></li>
<li><p>’distance’ : weight points by the inverse of their distance.
in this case, closer neighbors of a query point will have a
greater influence than neighbors which are further away.</p></li>
<li><p>[callable] : a user-defined function which accepts an
array of distances, and returns an array of the same shape
containing the weights.</p></li>
</ul>
</p></li>
<li><p><strong>algorithm</strong> (<em>{'auto'</em><em>, </em><em>'ball_tree'</em><em>, </em><em>'kd_tree'</em><em>, </em><em>'brute'}</em><em>, </em><em>default='auto'</em>) – <p>Algorithm used to compute the nearest neighbors:</p>
<ul>
<li><p>’ball_tree’ will use <a class="reference internal" href="#sklearn.neighbors.BallTree" title="sklearn.neighbors.BallTree"><code class="xref py py-class docutils literal notranslate"><span class="pre">BallTree</span></code></a></p></li>
<li><p>’kd_tree’ will use <a class="reference internal" href="#sklearn.neighbors.KDTree" title="sklearn.neighbors.KDTree"><code class="xref py py-class docutils literal notranslate"><span class="pre">KDTree</span></code></a></p></li>
<li><p>’brute’ will use a brute-force search.</p></li>
<li><p>’auto’ will attempt to decide the most appropriate algorithm
based on the values passed to <a class="reference internal" href="#sklearn.neighbors.KNeighborsClassifier.fit" title="sklearn.neighbors.KNeighborsClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p></li>
</ul>
<p>Note: fitting on sparse input will override the setting of
this parameter, using brute force.</p>
</p></li>
<li><p><strong>leaf_size</strong> (<em>int</em><em>, </em><em>default=30</em>) – Leaf size passed to BallTree or KDTree.  This can affect the
speed of the construction and query, as well as the memory
required to store the tree.  The optimal value depends on the
nature of the problem.</p></li>
<li><p><strong>p</strong> (<em>int</em><em>, </em><em>default=2</em>) – Power parameter for the Minkowski metric. When p = 1, this is
equivalent to using manhattan_distance (l1), and euclidean_distance
(l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.</p></li>
<li><p><strong>metric</strong> (<em>str</em><em> or </em><em>callable</em><em>, </em><em>default='minkowski'</em>) – the distance metric to use for the tree.  The default metric is
minkowski, and with p=2 is equivalent to the standard Euclidean
metric. See the documentation of <a class="reference internal" href="#sklearn.neighbors.DistanceMetric" title="sklearn.neighbors.DistanceMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">DistanceMetric</span></code></a> for a
list of available metrics.
If metric is “precomputed”, X is assumed to be a distance matrix and
must be square during fit. X may be a <span class="xref std std-term">sparse graph</span>,
in which case only “nonzero” elements may be considered neighbors.</p></li>
<li><p><strong>metric_params</strong> (<em>dict</em><em>, </em><em>default=None</em>) – Additional keyword arguments for the metric function.</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default=None</em>) – The number of parallel jobs to run for neighbors search.
<code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a <code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context.
<code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all processors. See <span class="xref std std-term">Glossary</span>
for more details.
Doesn’t affect <a class="reference internal" href="#sklearn.neighbors.KNeighborsClassifier.fit" title="sklearn.neighbors.KNeighborsClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.KNeighborsClassifier.classes_">
<span class="sig-name descname"><span class="pre">classes_</span></span><a class="headerlink" href="#sklearn.neighbors.KNeighborsClassifier.classes_" title="Permalink to this definition">¶</a></dt>
<dd><p>Class labels known to the classifier</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array of shape (n_classes,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.KNeighborsClassifier.effective_metric_">
<span class="sig-name descname"><span class="pre">effective_metric_</span></span><a class="headerlink" href="#sklearn.neighbors.KNeighborsClassifier.effective_metric_" title="Permalink to this definition">¶</a></dt>
<dd><p>The distance metric used. It will be same as the <cite>metric</cite> parameter
or a synonym of it, e.g. ‘euclidean’ if the <cite>metric</cite> parameter set to
‘minkowski’ and <cite>p</cite> parameter set to 2.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>str or callble</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.KNeighborsClassifier.effective_metric_params_">
<span class="sig-name descname"><span class="pre">effective_metric_params_</span></span><a class="headerlink" href="#sklearn.neighbors.KNeighborsClassifier.effective_metric_params_" title="Permalink to this definition">¶</a></dt>
<dd><p>Additional keyword arguments for the metric function. For most metrics
will be same with <cite>metric_params</cite> parameter, but may also contain the
<cite>p</cite> parameter value if the <cite>effective_metric_</cite> attribute is set to
‘minkowski’.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.KNeighborsClassifier.n_samples_fit_">
<span class="sig-name descname"><span class="pre">n_samples_fit_</span></span><a class="headerlink" href="#sklearn.neighbors.KNeighborsClassifier.n_samples_fit_" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of samples in the fitted data.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.KNeighborsClassifier.outputs_2d_">
<span class="sig-name descname"><span class="pre">outputs_2d_</span></span><a class="headerlink" href="#sklearn.neighbors.KNeighborsClassifier.outputs_2d_" title="Permalink to this definition">¶</a></dt>
<dd><p>False when <cite>y</cite>’s shape is (n_samples, ) or (n_samples, 1) during fit
otherwise True.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">neigh</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">neigh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">KNeighborsClassifier(...)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">neigh</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mf">1.1</span><span class="p">]]))</span>
<span class="go">[0]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">neigh</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">([[</span><span class="mf">0.9</span><span class="p">]]))</span>
<span class="go">[[0.66666667 0.33333333]]</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#sklearn.neighbors.RadiusNeighborsClassifier" title="sklearn.neighbors.RadiusNeighborsClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RadiusNeighborsClassifier</span></code></a>, <a class="reference internal" href="#sklearn.neighbors.KNeighborsRegressor" title="sklearn.neighbors.KNeighborsRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">KNeighborsRegressor</span></code></a>, <a class="reference internal" href="#sklearn.neighbors.RadiusNeighborsRegressor" title="sklearn.neighbors.RadiusNeighborsRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RadiusNeighborsRegressor</span></code></a>, <a class="reference internal" href="#sklearn.neighbors.NearestNeighbors" title="sklearn.neighbors.NearestNeighbors"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NearestNeighbors</span></code></a></p>
</div>
<p class="rubric">Notes</p>
<p>See <span class="xref std std-ref">Nearest Neighbors</span> in the online documentation
for a discussion of the choice of <code class="docutils literal notranslate"><span class="pre">algorithm</span></code> and <code class="docutils literal notranslate"><span class="pre">leaf_size</span></code>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Regarding the Nearest Neighbors algorithms, if it is found that two
neighbors, neighbor <cite>k+1</cite> and <cite>k</cite>, have identical distances
but different labels, the results will depend on the ordering of the
training data.</p>
</div>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm">https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.KNeighborsClassifier.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.KNeighborsClassifier.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the k-nearest neighbors classifier from the training dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>) or                 </em><em>(</em><em>n_samples</em><em>, </em><em>n_samples</em><em>) </em><em>if metric='precomputed'</em>) – Training data.</p></li>
<li><p><strong>y</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or                 </em><em>(</em><em>n_samples</em><em>, </em><em>n_outputs</em><em>)</em>) – Target values.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – The fitted k-nearest neighbors classifier.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#sklearn.neighbors.KNeighborsClassifier" title="sklearn.neighbors.KNeighborsClassifier">KNeighborsClassifier</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.KNeighborsClassifier.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.KNeighborsClassifier.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the class labels for the provided data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_queries</em><em>, </em><em>n_features</em><em>)</em><em>,                 or </em><em>(</em><em>n_queries</em><em>, </em><em>n_indexed</em><em>) </em><em>if metric == 'precomputed'</em>) – Test samples.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> – Class labels for each data sample.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray of shape (n_queries,) or (n_queries, n_outputs)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.KNeighborsClassifier.predict_proba">
<span class="sig-name descname"><span class="pre">predict_proba</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.KNeighborsClassifier.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Return probability estimates for the test data X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_queries</em><em>, </em><em>n_features</em><em>)</em><em>,                 or </em><em>(</em><em>n_queries</em><em>, </em><em>n_indexed</em><em>) </em><em>if metric == 'precomputed'</em>) – Test samples.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>p</strong> – of such arrays if n_outputs &gt; 1.
The class probabilities of the input samples. Classes are ordered
by lexicographic order.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray of shape (n_queries, n_classes), or a list of n_outputs</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.neighbors.KNeighborsRegressor">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.neighbors.</span></span><span class="sig-name descname"><span class="pre">KNeighborsRegressor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_neighbors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'uniform'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">leaf_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">30</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'minkowski'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.KNeighborsRegressor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.neighbors._base.KNeighborsMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.RegressorMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.neighbors._base.NeighborsBase</span></code></p>
<p>Regression based on k-nearest neighbors.</p>
<p>The target is predicted by local interpolation of the targets
associated of the nearest neighbors in the training set.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.9.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_neighbors</strong> (<em>int</em><em>, </em><em>default=5</em>) – Number of neighbors to use by default for <code class="xref py py-meth docutils literal notranslate"><span class="pre">kneighbors()</span></code> queries.</p></li>
<li><p><strong>weights</strong> (<em>{'uniform'</em><em>, </em><em>'distance'}</em><em> or </em><em>callable</em><em>, </em><em>default='uniform'</em>) – <p>weight function used in prediction.  Possible values:</p>
<ul>
<li><p>’uniform’ : uniform weights.  All points in each neighborhood
are weighted equally.</p></li>
<li><p>’distance’ : weight points by the inverse of their distance.
in this case, closer neighbors of a query point will have a
greater influence than neighbors which are further away.</p></li>
<li><p>[callable] : a user-defined function which accepts an
array of distances, and returns an array of the same shape
containing the weights.</p></li>
</ul>
<p>Uniform weights are used by default.</p>
</p></li>
<li><p><strong>algorithm</strong> (<em>{'auto'</em><em>, </em><em>'ball_tree'</em><em>, </em><em>'kd_tree'</em><em>, </em><em>'brute'}</em><em>, </em><em>default='auto'</em>) – <p>Algorithm used to compute the nearest neighbors:</p>
<ul>
<li><p>’ball_tree’ will use <a class="reference internal" href="#sklearn.neighbors.BallTree" title="sklearn.neighbors.BallTree"><code class="xref py py-class docutils literal notranslate"><span class="pre">BallTree</span></code></a></p></li>
<li><p>’kd_tree’ will use <a class="reference internal" href="#sklearn.neighbors.KDTree" title="sklearn.neighbors.KDTree"><code class="xref py py-class docutils literal notranslate"><span class="pre">KDTree</span></code></a></p></li>
<li><p>’brute’ will use a brute-force search.</p></li>
<li><p>’auto’ will attempt to decide the most appropriate algorithm
based on the values passed to <a class="reference internal" href="#sklearn.neighbors.KNeighborsRegressor.fit" title="sklearn.neighbors.KNeighborsRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p></li>
</ul>
<p>Note: fitting on sparse input will override the setting of
this parameter, using brute force.</p>
</p></li>
<li><p><strong>leaf_size</strong> (<em>int</em><em>, </em><em>default=30</em>) – Leaf size passed to BallTree or KDTree.  This can affect the
speed of the construction and query, as well as the memory
required to store the tree.  The optimal value depends on the
nature of the problem.</p></li>
<li><p><strong>p</strong> (<em>int</em><em>, </em><em>default=2</em>) – Power parameter for the Minkowski metric. When p = 1, this is
equivalent to using manhattan_distance (l1), and euclidean_distance
(l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.</p></li>
<li><p><strong>metric</strong> (<em>str</em><em> or </em><em>callable</em><em>, </em><em>default='minkowski'</em>) – the distance metric to use for the tree.  The default metric is
minkowski, and with p=2 is equivalent to the standard Euclidean
metric. See the documentation of <a class="reference internal" href="#sklearn.neighbors.DistanceMetric" title="sklearn.neighbors.DistanceMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">DistanceMetric</span></code></a> for a
list of available metrics.
If metric is “precomputed”, X is assumed to be a distance matrix and
must be square during fit. X may be a <span class="xref std std-term">sparse graph</span>,
in which case only “nonzero” elements may be considered neighbors.</p></li>
<li><p><strong>metric_params</strong> (<em>dict</em><em>, </em><em>default=None</em>) – Additional keyword arguments for the metric function.</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default=None</em>) – The number of parallel jobs to run for neighbors search.
<code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a <code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context.
<code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all processors. See <span class="xref std std-term">Glossary</span>
for more details.
Doesn’t affect <a class="reference internal" href="#sklearn.neighbors.KNeighborsRegressor.fit" title="sklearn.neighbors.KNeighborsRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.KNeighborsRegressor.effective_metric_">
<span class="sig-name descname"><span class="pre">effective_metric_</span></span><a class="headerlink" href="#sklearn.neighbors.KNeighborsRegressor.effective_metric_" title="Permalink to this definition">¶</a></dt>
<dd><p>The distance metric to use. It will be same as the <cite>metric</cite> parameter
or a synonym of it, e.g. ‘euclidean’ if the <cite>metric</cite> parameter set to
‘minkowski’ and <cite>p</cite> parameter set to 2.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>str or callable</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.KNeighborsRegressor.effective_metric_params_">
<span class="sig-name descname"><span class="pre">effective_metric_params_</span></span><a class="headerlink" href="#sklearn.neighbors.KNeighborsRegressor.effective_metric_params_" title="Permalink to this definition">¶</a></dt>
<dd><p>Additional keyword arguments for the metric function. For most metrics
will be same with <cite>metric_params</cite> parameter, but may also contain the
<cite>p</cite> parameter value if the <cite>effective_metric_</cite> attribute is set to
‘minkowski’.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.KNeighborsRegressor.n_samples_fit_">
<span class="sig-name descname"><span class="pre">n_samples_fit_</span></span><a class="headerlink" href="#sklearn.neighbors.KNeighborsRegressor.n_samples_fit_" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of samples in the fitted data.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">neigh</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">neigh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">KNeighborsRegressor(...)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">neigh</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mf">1.5</span><span class="p">]]))</span>
<span class="go">[0.5]</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#sklearn.neighbors.NearestNeighbors" title="sklearn.neighbors.NearestNeighbors"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NearestNeighbors</span></code></a>, <a class="reference internal" href="#sklearn.neighbors.RadiusNeighborsRegressor" title="sklearn.neighbors.RadiusNeighborsRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RadiusNeighborsRegressor</span></code></a>, <a class="reference internal" href="#sklearn.neighbors.KNeighborsClassifier" title="sklearn.neighbors.KNeighborsClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">KNeighborsClassifier</span></code></a>, <a class="reference internal" href="#sklearn.neighbors.RadiusNeighborsClassifier" title="sklearn.neighbors.RadiusNeighborsClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RadiusNeighborsClassifier</span></code></a></p>
</div>
<p class="rubric">Notes</p>
<p>See <span class="xref std std-ref">Nearest Neighbors</span> in the online documentation
for a discussion of the choice of <code class="docutils literal notranslate"><span class="pre">algorithm</span></code> and <code class="docutils literal notranslate"><span class="pre">leaf_size</span></code>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Regarding the Nearest Neighbors algorithms, if it is found that two
neighbors, neighbor <cite>k+1</cite> and <cite>k</cite>, have identical distances but
different labels, the results will depend on the ordering of the
training data.</p>
</div>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm">https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.KNeighborsRegressor.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.KNeighborsRegressor.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the k-nearest neighbors regressor from the training dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>) or                 </em><em>(</em><em>n_samples</em><em>, </em><em>n_samples</em><em>) </em><em>if metric='precomputed'</em>) – Training data.</p></li>
<li><p><strong>y</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or                 </em><em>(</em><em>n_samples</em><em>, </em><em>n_outputs</em><em>)</em>) – Target values.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – The fitted k-nearest neighbors regressor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#sklearn.neighbors.KNeighborsRegressor" title="sklearn.neighbors.KNeighborsRegressor">KNeighborsRegressor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.KNeighborsRegressor.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.KNeighborsRegressor.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the target for the provided data</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_queries</em><em>, </em><em>n_features</em><em>)</em><em>,                 or </em><em>(</em><em>n_queries</em><em>, </em><em>n_indexed</em><em>) </em><em>if metric == 'precomputed'</em>) – Test samples.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> – Target values.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray of shape (n_queries,) or (n_queries, n_outputs), dtype=int</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.neighbors.KNeighborsTransformer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.neighbors.</span></span><span class="sig-name descname"><span class="pre">KNeighborsTransformer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'distance'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_neighbors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">leaf_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">30</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'minkowski'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.KNeighborsTransformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.neighbors._base.KNeighborsMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.TransformerMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.neighbors._base.NeighborsBase</span></code></p>
<p>Transform X into a (weighted) graph of k nearest neighbors</p>
<p>The transformed data is a sparse graph as returned by kneighbors_graph.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.22.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mode</strong> (<em>{'distance'</em><em>, </em><em>'connectivity'}</em><em>, </em><em>default='distance'</em>) – Type of returned matrix: ‘connectivity’ will return the connectivity
matrix with ones and zeros, and ‘distance’ will return the distances
between neighbors according to the given metric.</p></li>
<li><p><strong>n_neighbors</strong> (<em>int</em><em>, </em><em>default=5</em>) – Number of neighbors for each sample in the transformed sparse graph.
For compatibility reasons, as each sample is considered as its own
neighbor, one extra neighbor will be computed when mode == ‘distance’.
In this case, the sparse graph contains (n_neighbors + 1) neighbors.</p></li>
<li><p><strong>algorithm</strong> (<em>{'auto'</em><em>, </em><em>'ball_tree'</em><em>, </em><em>'kd_tree'</em><em>, </em><em>'brute'}</em><em>, </em><em>default='auto'</em>) – <p>Algorithm used to compute the nearest neighbors:</p>
<ul>
<li><p>’ball_tree’ will use <a class="reference internal" href="#sklearn.neighbors.BallTree" title="sklearn.neighbors.BallTree"><code class="xref py py-class docutils literal notranslate"><span class="pre">BallTree</span></code></a></p></li>
<li><p>’kd_tree’ will use <a class="reference internal" href="#sklearn.neighbors.KDTree" title="sklearn.neighbors.KDTree"><code class="xref py py-class docutils literal notranslate"><span class="pre">KDTree</span></code></a></p></li>
<li><p>’brute’ will use a brute-force search.</p></li>
<li><p>’auto’ will attempt to decide the most appropriate algorithm
based on the values passed to <a class="reference internal" href="#sklearn.neighbors.KNeighborsTransformer.fit" title="sklearn.neighbors.KNeighborsTransformer.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p></li>
</ul>
<p>Note: fitting on sparse input will override the setting of
this parameter, using brute force.</p>
</p></li>
<li><p><strong>leaf_size</strong> (<em>int</em><em>, </em><em>default=30</em>) – Leaf size passed to BallTree or KDTree.  This can affect the
speed of the construction and query, as well as the memory
required to store the tree.  The optimal value depends on the
nature of the problem.</p></li>
<li><p><strong>metric</strong> (<em>str</em><em> or </em><em>callable</em><em>, </em><em>default='minkowski'</em>) – <p>metric to use for distance computation. Any metric from scikit-learn
or scipy.spatial.distance can be used.</p>
<p>If metric is a callable function, it is called on each
pair of instances (rows) and the resulting value recorded. The callable
should take two arrays as input and return one value indicating the
distance between them. This works for Scipy’s metrics, but is less
efficient than passing the metric name as a string.</p>
<p>Distance matrices are not supported.</p>
<p>Valid values for metric are:</p>
<ul>
<li><p>from scikit-learn: [‘cityblock’, ‘cosine’, ‘euclidean’, ‘l1’, ‘l2’,
‘manhattan’]</p></li>
<li><p>from scipy.spatial.distance: [‘braycurtis’, ‘canberra’, ‘chebyshev’,
‘correlation’, ‘dice’, ‘hamming’, ‘jaccard’, ‘kulsinski’,
‘mahalanobis’, ‘minkowski’, ‘rogerstanimoto’, ‘russellrao’,
‘seuclidean’, ‘sokalmichener’, ‘sokalsneath’, ‘sqeuclidean’,
‘yule’]</p></li>
</ul>
<p>See the documentation for scipy.spatial.distance for details on these
metrics.</p>
</p></li>
<li><p><strong>p</strong> (<em>int</em><em>, </em><em>default=2</em>) – Parameter for the Minkowski metric from
sklearn.metrics.pairwise.pairwise_distances. When p = 1, this is
equivalent to using manhattan_distance (l1), and euclidean_distance
(l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.</p></li>
<li><p><strong>metric_params</strong> (<em>dict</em><em>, </em><em>default=None</em>) – Additional keyword arguments for the metric function.</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default=1</em>) – The number of parallel jobs to run for neighbors search.
If <code class="docutils literal notranslate"><span class="pre">-1</span></code>, then the number of jobs is set to the number of CPU cores.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.KNeighborsTransformer.effective_metric_">
<span class="sig-name descname"><span class="pre">effective_metric_</span></span><a class="headerlink" href="#sklearn.neighbors.KNeighborsTransformer.effective_metric_" title="Permalink to this definition">¶</a></dt>
<dd><p>The distance metric used. It will be same as the <cite>metric</cite> parameter
or a synonym of it, e.g. ‘euclidean’ if the <cite>metric</cite> parameter set to
‘minkowski’ and <cite>p</cite> parameter set to 2.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>str or callable</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.KNeighborsTransformer.effective_metric_params_">
<span class="sig-name descname"><span class="pre">effective_metric_params_</span></span><a class="headerlink" href="#sklearn.neighbors.KNeighborsTransformer.effective_metric_params_" title="Permalink to this definition">¶</a></dt>
<dd><p>Additional keyword arguments for the metric function. For most metrics
will be same with <cite>metric_params</cite> parameter, but may also contain the
<cite>p</cite> parameter value if the <cite>effective_metric_</cite> attribute is set to
‘minkowski’.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.KNeighborsTransformer.n_samples_fit_">
<span class="sig-name descname"><span class="pre">n_samples_fit_</span></span><a class="headerlink" href="#sklearn.neighbors.KNeighborsTransformer.n_samples_fit_" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of samples in the fitted data.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">Isomap</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsTransformer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">KNeighborsTransformer</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;distance&#39;</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">Isomap</span><span class="p">(</span><span class="n">neighbors_algorithm</span><span class="o">=</span><span class="s1">&#39;precomputed&#39;</span><span class="p">))</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.KNeighborsTransformer.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.KNeighborsTransformer.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the k-nearest neighbors transformer from the training dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>) or                 </em><em>(</em><em>n_samples</em><em>, </em><em>n_samples</em><em>) </em><em>if metric='precomputed'</em>) – Training data.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – The fitted k-nearest neighbors transformer.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#sklearn.neighbors.KNeighborsTransformer" title="sklearn.neighbors.KNeighborsTransformer">KNeighborsTransformer</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.KNeighborsTransformer.fit_transform">
<span class="sig-name descname"><span class="pre">fit_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.KNeighborsTransformer.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Training set.</p></li>
<li><p><strong>y</strong> (<em>ignored</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Xt</strong> – Xt[i, j] is assigned the weight of edge that connects i to j.
Only the neighbors have an explicit value.
The diagonal is always explicit.
The matrix is of CSR format.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>sparse matrix of shape (n_samples, n_samples)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.KNeighborsTransformer.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.KNeighborsTransformer.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the (weighted) graph of Neighbors for points in X</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples_transform</em><em>, </em><em>n_features</em><em>)</em>) – Sample data.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Xt</strong> – Xt[i, j] is assigned the weight of edge that connects i to j.
Only the neighbors have an explicit value.
The diagonal is always explicit.
The matrix is of CSR format.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>sparse matrix of shape (n_samples_transform, n_samples_fit)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.neighbors.KernelDensity">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.neighbors.</span></span><span class="sig-name descname"><span class="pre">KernelDensity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bandwidth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gaussian'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'euclidean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">atol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rtol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">breadth_first</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">leaf_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">40</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.KernelDensity" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.BaseEstimator</span></code></p>
<p>Kernel Density Estimation.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>bandwidth</strong> (<em>float</em><em>, </em><em>default=1.0</em>) – The bandwidth of the kernel.</p></li>
<li><p><strong>algorithm</strong> (<em>{'kd_tree'</em><em>, </em><em>'ball_tree'</em><em>, </em><em>'auto'}</em><em>, </em><em>default='auto'</em>) – The tree algorithm to use.</p></li>
<li><p><strong>kernel</strong> (<em>{'gaussian'</em><em>, </em><em>'tophat'</em><em>, </em><em>'epanechnikov'</em><em>, </em><em>'exponential'</em><em>, </em><em>'linear'</em><em>,                  </em><em>'cosine'}</em><em>, </em><em>default='gaussian'</em>) – The kernel to use.</p></li>
<li><p><strong>metric</strong> (<em>str</em><em>, </em><em>default='euclidean'</em>) – The distance metric to use.  Note that not all metrics are
valid with all algorithms.  Refer to the documentation of
<a class="reference internal" href="#sklearn.neighbors.BallTree" title="sklearn.neighbors.BallTree"><code class="xref py py-class docutils literal notranslate"><span class="pre">BallTree</span></code></a> and <a class="reference internal" href="#sklearn.neighbors.KDTree" title="sklearn.neighbors.KDTree"><code class="xref py py-class docutils literal notranslate"><span class="pre">KDTree</span></code></a> for a description of
available algorithms.  Note that the normalization of the density
output is correct only for the Euclidean distance metric. Default
is ‘euclidean’.</p></li>
<li><p><strong>atol</strong> (<em>float</em><em>, </em><em>default=0</em>) – The desired absolute tolerance of the result.  A larger tolerance will
generally lead to faster execution.</p></li>
<li><p><strong>rtol</strong> (<em>float</em><em>, </em><em>default=0</em>) – The desired relative tolerance of the result.  A larger tolerance will
generally lead to faster execution.</p></li>
<li><p><strong>breadth_first</strong> (<em>bool</em><em>, </em><em>default=True</em>) – If true (default), use a breadth-first approach to the problem.
Otherwise use a depth-first approach.</p></li>
<li><p><strong>leaf_size</strong> (<em>int</em><em>, </em><em>default=40</em>) – Specify the leaf size of the underlying tree.  See <a class="reference internal" href="#sklearn.neighbors.BallTree" title="sklearn.neighbors.BallTree"><code class="xref py py-class docutils literal notranslate"><span class="pre">BallTree</span></code></a>
or <a class="reference internal" href="#sklearn.neighbors.KDTree" title="sklearn.neighbors.KDTree"><code class="xref py py-class docutils literal notranslate"><span class="pre">KDTree</span></code></a> for details.</p></li>
<li><p><strong>metric_params</strong> (<em>dict</em><em>, </em><em>default=None</em>) – Additional parameters to be passed to the tree for use with the
metric.  For more information, see the documentation of
<a class="reference internal" href="#sklearn.neighbors.BallTree" title="sklearn.neighbors.BallTree"><code class="xref py py-class docutils literal notranslate"><span class="pre">BallTree</span></code></a> or <a class="reference internal" href="#sklearn.neighbors.KDTree" title="sklearn.neighbors.KDTree"><code class="xref py py-class docutils literal notranslate"><span class="pre">KDTree</span></code></a>.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.KernelDensity.tree_">
<span class="sig-name descname"><span class="pre">tree_</span></span><a class="headerlink" href="#sklearn.neighbors.KernelDensity.tree_" title="Permalink to this definition">¶</a></dt>
<dd><p>The tree algorithm for fast generalized N-point problems.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">BinaryTree</span></code> instance</p>
</dd>
</dl>
</dd></dl>

<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.neighbors.KDTree" title="sklearn.neighbors.KDTree"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sklearn.neighbors.KDTree</span></code></a></dt><dd><p>K-dimensional tree for fast generalized N-point problems.</p>
</dd>
<dt><a class="reference internal" href="#sklearn.neighbors.BallTree" title="sklearn.neighbors.BallTree"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sklearn.neighbors.BallTree</span></code></a></dt><dd><p>Ball tree for fast generalized N-point problems.</p>
</dd>
</dl>
</div>
<p class="rubric">Examples</p>
<p>Compute a gaussian kernel density estimate with a fixed bandwidth.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random_sample</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kde</span> <span class="o">=</span> <span class="n">KernelDensity</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;gaussian&#39;</span><span class="p">,</span> <span class="n">bandwidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">log_density</span> <span class="o">=</span> <span class="n">kde</span><span class="o">.</span><span class="n">score_samples</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">log_density</span>
<span class="go">array([-1.52955942, -1.51462041, -1.60244657])</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.KernelDensity.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.KernelDensity.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the Kernel Density model on the data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – List of n_features-dimensional data points.  Each row
corresponds to a single data point.</p></li>
<li><p><strong>y</strong> (<em>None</em>) – Ignored. This parameter exists only for compatibility with
<code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code>.</p></li>
<li><p><strong>sample_weight</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – <p>List of sample weights attached to the data X.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.20.</span></p>
</div>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – Returns instance of object.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.KernelDensity.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.KernelDensity.sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate random samples from the model.</p>
<p>Currently, this is implemented only for gaussian and tophat kernels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_samples</strong> (<em>int</em><em>, </em><em>default=1</em>) – Number of samples to generate.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Determines random number generation used to generate
random samples. Pass an int for reproducible results
across multiple function calls.
See :term: <cite>Glossary &lt;random_state&gt;</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X</strong> – List of samples.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array-like of shape (n_samples, n_features)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.KernelDensity.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.KernelDensity.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the total log probability density under the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – List of n_features-dimensional data points.  Each row
corresponds to a single data point.</p></li>
<li><p><strong>y</strong> (<em>None</em>) – Ignored. This parameter exists only for compatibility with
<code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>logprob</strong> – Total log-likelihood of the data in X. This is normalized to be a
probability density, so the value will be low for high-dimensional
data.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.KernelDensity.score_samples">
<span class="sig-name descname"><span class="pre">score_samples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.KernelDensity.score_samples" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the log density model on the data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – An array of points to query.  Last dimension should match dimension
of training data (n_features).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>density</strong> – The array of log(density) evaluations. These are normalized to be
probability densities, so values will be low for high-dimensional
data.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray of shape (n_samples,)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.neighbors.LocalOutlierFactor">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.neighbors.</span></span><span class="sig-name descname"><span class="pre">LocalOutlierFactor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_neighbors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">leaf_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">30</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'minkowski'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">contamination</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">novelty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.LocalOutlierFactor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.neighbors._base.KNeighborsMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.OutlierMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.neighbors._base.NeighborsBase</span></code></p>
<p>Unsupervised Outlier Detection using Local Outlier Factor (LOF)</p>
<p>The anomaly score of each sample is called Local Outlier Factor.
It measures the local deviation of density of a given sample with
respect to its neighbors.
It is local in that the anomaly score depends on how isolated the object
is with respect to the surrounding neighborhood.
More precisely, locality is given by k-nearest neighbors, whose distance
is used to estimate the local density.
By comparing the local density of a sample to the local densities of
its neighbors, one can identify samples that have a substantially lower
density than their neighbors. These are considered outliers.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.19.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_neighbors</strong> (<em>int</em><em>, </em><em>default=20</em>) – Number of neighbors to use by default for <code class="xref py py-meth docutils literal notranslate"><span class="pre">kneighbors()</span></code> queries.
If n_neighbors is larger than the number of samples provided,
all samples will be used.</p></li>
<li><p><strong>algorithm</strong> (<em>{'auto'</em><em>, </em><em>'ball_tree'</em><em>, </em><em>'kd_tree'</em><em>, </em><em>'brute'}</em><em>, </em><em>default='auto'</em>) – <p>Algorithm used to compute the nearest neighbors:</p>
<ul>
<li><p>’ball_tree’ will use <a class="reference internal" href="#sklearn.neighbors.BallTree" title="sklearn.neighbors.BallTree"><code class="xref py py-class docutils literal notranslate"><span class="pre">BallTree</span></code></a></p></li>
<li><p>’kd_tree’ will use <a class="reference internal" href="#sklearn.neighbors.KDTree" title="sklearn.neighbors.KDTree"><code class="xref py py-class docutils literal notranslate"><span class="pre">KDTree</span></code></a></p></li>
<li><p>’brute’ will use a brute-force search.</p></li>
<li><p>’auto’ will attempt to decide the most appropriate algorithm
based on the values passed to <a class="reference internal" href="#sklearn.neighbors.LocalOutlierFactor.fit" title="sklearn.neighbors.LocalOutlierFactor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p></li>
</ul>
<p>Note: fitting on sparse input will override the setting of
this parameter, using brute force.</p>
</p></li>
<li><p><strong>leaf_size</strong> (<em>int</em><em>, </em><em>default=30</em>) – Leaf size passed to <a class="reference internal" href="#sklearn.neighbors.BallTree" title="sklearn.neighbors.BallTree"><code class="xref py py-class docutils literal notranslate"><span class="pre">BallTree</span></code></a> or <a class="reference internal" href="#sklearn.neighbors.KDTree" title="sklearn.neighbors.KDTree"><code class="xref py py-class docutils literal notranslate"><span class="pre">KDTree</span></code></a>. This can
affect the speed of the construction and query, as well as the memory
required to store the tree. The optimal value depends on the
nature of the problem.</p></li>
<li><p><strong>metric</strong> (<em>str</em><em> or </em><em>callable</em><em>, </em><em>default='minkowski'</em>) – <p>metric used for the distance computation. Any metric from scikit-learn
or scipy.spatial.distance can be used.</p>
<p>If metric is “precomputed”, X is assumed to be a distance matrix and
must be square. X may be a sparse matrix, in which case only “nonzero”
elements may be considered neighbors.</p>
<p>If metric is a callable function, it is called on each
pair of instances (rows) and the resulting value recorded. The callable
should take two arrays as input and return one value indicating the
distance between them. This works for Scipy’s metrics, but is less
efficient than passing the metric name as a string.</p>
<p>Valid values for metric are:</p>
<ul>
<li><p>from scikit-learn: [‘cityblock’, ‘cosine’, ‘euclidean’, ‘l1’, ‘l2’,
‘manhattan’]</p></li>
<li><p>from scipy.spatial.distance: [‘braycurtis’, ‘canberra’, ‘chebyshev’,
‘correlation’, ‘dice’, ‘hamming’, ‘jaccard’, ‘kulsinski’,
‘mahalanobis’, ‘minkowski’, ‘rogerstanimoto’, ‘russellrao’,
‘seuclidean’, ‘sokalmichener’, ‘sokalsneath’, ‘sqeuclidean’,
‘yule’]</p></li>
</ul>
<p>See the documentation for scipy.spatial.distance for details on these
metrics:
<a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/spatial.distance.html">https://docs.scipy.org/doc/scipy/reference/spatial.distance.html</a></p>
</p></li>
<li><p><strong>p</strong> (<em>int</em><em>, </em><em>default=2</em>) – Parameter for the Minkowski metric from
<a class="reference internal" href="sklearn.metrics.html#sklearn.metrics.pairwise.pairwise_distances" title="sklearn.metrics.pairwise.pairwise_distances"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.pairwise.pairwise_distances()</span></code></a>. When p = 1, this
is equivalent to using manhattan_distance (l1), and euclidean_distance
(l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.</p></li>
<li><p><strong>metric_params</strong> (<em>dict</em><em>, </em><em>default=None</em>) – Additional keyword arguments for the metric function.</p></li>
<li><p><strong>contamination</strong> (<em>'auto'</em><em> or </em><em>float</em><em>, </em><em>default='auto'</em>) – <p>The amount of contamination of the data set, i.e. the proportion
of outliers in the data set. When fitting this is used to define the
threshold on the scores of the samples.</p>
<ul>
<li><p>if ‘auto’, the threshold is determined as in the
original paper,</p></li>
<li><p>if a float, the contamination should be in the range (0, 0.5].</p></li>
</ul>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.22: </span>The default value of <code class="docutils literal notranslate"><span class="pre">contamination</span></code> changed from 0.1
to <code class="docutils literal notranslate"><span class="pre">'auto'</span></code>.</p>
</div>
</p></li>
<li><p><strong>novelty</strong> (<em>bool</em><em>, </em><em>default=False</em>) – <p>By default, LocalOutlierFactor is only meant to be used for outlier
detection (novelty=False). Set novelty to True if you want to use
LocalOutlierFactor for novelty detection. In this case be aware that
you should only use predict, decision_function and score_samples
on new unseen data and not on the training set.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.20.</span></p>
</div>
</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default=None</em>) – The number of parallel jobs to run for neighbors search.
<code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a <code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context.
<code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all processors. See <span class="xref std std-term">Glossary</span>
for more details.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.LocalOutlierFactor.negative_outlier_factor_">
<span class="sig-name descname"><span class="pre">negative_outlier_factor_</span></span><a class="headerlink" href="#sklearn.neighbors.LocalOutlierFactor.negative_outlier_factor_" title="Permalink to this definition">¶</a></dt>
<dd><p>The opposite LOF of the training samples. The higher, the more normal.
Inliers tend to have a LOF score close to 1
(<code class="docutils literal notranslate"><span class="pre">negative_outlier_factor_</span></code> close to -1), while outliers tend to have
a larger LOF score.</p>
<p>The local outlier factor (LOF) of a sample captures its
supposed ‘degree of abnormality’.
It is the average of the ratio of the local reachability density of
a sample and those of its k-nearest neighbors.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray of shape (n_samples,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.LocalOutlierFactor.n_neighbors_">
<span class="sig-name descname"><span class="pre">n_neighbors_</span></span><a class="headerlink" href="#sklearn.neighbors.LocalOutlierFactor.n_neighbors_" title="Permalink to this definition">¶</a></dt>
<dd><p>The actual number of neighbors used for <code class="xref py py-meth docutils literal notranslate"><span class="pre">kneighbors()</span></code> queries.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.LocalOutlierFactor.offset_">
<span class="sig-name descname"><span class="pre">offset_</span></span><a class="headerlink" href="#sklearn.neighbors.LocalOutlierFactor.offset_" title="Permalink to this definition">¶</a></dt>
<dd><p>Offset used to obtain binary labels from the raw scores.
Observations having a negative_outlier_factor smaller than <cite>offset_</cite>
are detected as abnormal.
The offset is set to -1.5 (inliers score around -1), except when a
contamination parameter different than “auto” is provided. In that
case, the offset is defined in such a way we obtain the expected
number of outliers in training.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.20.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.LocalOutlierFactor.effective_metric_">
<span class="sig-name descname"><span class="pre">effective_metric_</span></span><a class="headerlink" href="#sklearn.neighbors.LocalOutlierFactor.effective_metric_" title="Permalink to this definition">¶</a></dt>
<dd><p>The effective metric used for the distance computation.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.LocalOutlierFactor.effective_metric_params_">
<span class="sig-name descname"><span class="pre">effective_metric_params_</span></span><a class="headerlink" href="#sklearn.neighbors.LocalOutlierFactor.effective_metric_params_" title="Permalink to this definition">¶</a></dt>
<dd><p>The effective additional keyword arguments for the metric function.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.LocalOutlierFactor.n_samples_fit_">
<span class="sig-name descname"><span class="pre">n_samples_fit_</span></span><a class="headerlink" href="#sklearn.neighbors.LocalOutlierFactor.n_samples_fit_" title="Permalink to this definition">¶</a></dt>
<dd><p>It is the number of samples in the fitted data.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">LocalOutlierFactor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mf">1.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">],</span> <span class="p">[</span><span class="mf">101.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">LocalOutlierFactor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([ 1,  1, -1,  1])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">negative_outlier_factor_</span>
<span class="go">array([ -0.9821...,  -1.0370..., -73.3697...,  -0.9821...])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id1"><span class="brackets">1</span></dt>
<dd><p>Breunig, M. M., Kriegel, H. P., Ng, R. T., &amp; Sander, J. (2000, May).
LOF: identifying density-based local outliers. In ACM sigmod record.</p>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="sklearn.neighbors.LocalOutlierFactor.decision_function">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">decision_function</span></span><a class="headerlink" href="#sklearn.neighbors.LocalOutlierFactor.decision_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Shifted opposite of the Local Outlier Factor of X.</p>
<p>Bigger is better, i.e. large values correspond to inliers.</p>
<p><strong>Only available for novelty detection (when novelty is set to True).</strong>
The shift offset allows a zero threshold for being an outlier.
The argument X is supposed to contain <em>new data</em>: if X contains a
point from training, it considers the later in its own neighborhood.
Also, the samples in X are not considered in the neighborhood of any
point.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The query sample or samples to compute the Local Outlier Factor
w.r.t. the training samples.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>shifted_opposite_lof_scores</strong> – The shifted opposite of the Local Outlier Factor of each input
samples. The lower, the more abnormal. Negative scores represent
outliers, positive scores represent inliers.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray of shape (n_samples,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.LocalOutlierFactor.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.LocalOutlierFactor.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the local outlier factor detector from the training dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>) or                 </em><em>(</em><em>n_samples</em><em>, </em><em>n_samples</em><em>) </em><em>if metric='precomputed'</em>) – Training data.</p></li>
<li><p><strong>y</strong> (<em>Ignored</em>) – Not used, present for API consistency by convention.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – The fitted local outlier factor detector.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#sklearn.neighbors.LocalOutlierFactor" title="sklearn.neighbors.LocalOutlierFactor">LocalOutlierFactor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="sklearn.neighbors.LocalOutlierFactor.fit_predict">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">fit_predict</span></span><a class="headerlink" href="#sklearn.neighbors.LocalOutlierFactor.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Fits the model to the training set X and returns the labels.</p>
<p><strong>Not available for novelty detection (when novelty is set to True).</strong>
Label is 1 for an inlier and -1 for an outlier according to the LOF
score and the contamination parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em><em>, </em><em>default=None</em>) – The query sample or samples to compute the Local Outlier Factor
w.r.t. to the training samples.</p></li>
<li><p><strong>y</strong> (<em>Ignored</em>) – Not used, present for API consistency by convention.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>is_inlier</strong> – Returns -1 for anomalies/outliers and 1 for inliers.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray of shape (n_samples,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="sklearn.neighbors.LocalOutlierFactor.predict">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">predict</span></span><a class="headerlink" href="#sklearn.neighbors.LocalOutlierFactor.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the labels (1 inlier, -1 outlier) of X according to LOF.</p>
<p><strong>Only available for novelty detection (when novelty is set to True).</strong>
This method allows to generalize prediction to <em>new observations</em> (not
in the training set).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The query sample or samples to compute the Local Outlier Factor
w.r.t. to the training samples.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>is_inlier</strong> – Returns -1 for anomalies/outliers and +1 for inliers.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray of shape (n_samples,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="sklearn.neighbors.LocalOutlierFactor.score_samples">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">score_samples</span></span><a class="headerlink" href="#sklearn.neighbors.LocalOutlierFactor.score_samples" title="Permalink to this definition">¶</a></dt>
<dd><p>Opposite of the Local Outlier Factor of X.</p>
<p>It is the opposite as bigger is better, i.e. large values correspond
to inliers.</p>
<p><strong>Only available for novelty detection (when novelty is set to True).</strong>
The argument X is supposed to contain <em>new data</em>: if X contains a
point from training, it considers the later in its own neighborhood.
Also, the samples in X are not considered in the neighborhood of any
point.
The score_samples on training data is available by considering the
the <code class="docutils literal notranslate"><span class="pre">negative_outlier_factor_</span></code> attribute.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The query sample or samples to compute the Local Outlier Factor
w.r.t. the training samples.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>opposite_lof_scores</strong> – The opposite of the Local Outlier Factor of each input samples.
The lower, the more abnormal.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray of shape (n_samples,)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.neighbors.NearestCentroid">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.neighbors.</span></span><span class="sig-name descname"><span class="pre">NearestCentroid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'euclidean'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shrink_threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.NearestCentroid" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.ClassifierMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.BaseEstimator</span></code></p>
<p>Nearest centroid classifier.</p>
<p>Each class is represented by its centroid, with test samples classified to
the class with the nearest centroid.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metric</strong> (<em>str</em><em> or </em><em>callable</em>) – <p>The metric to use when calculating distance between instances in a
feature array. If metric is a string or callable, it must be one of
the options allowed by metrics.pairwise.pairwise_distances for its
metric parameter.
The centroids for the samples corresponding to each class is the point
from which the sum of the distances (according to the metric) of all
samples that belong to that particular class are minimized.
If the “manhattan” metric is provided, this centroid is the median and
for all other metrics, the centroid is now set to be the mean.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.19: </span><code class="docutils literal notranslate"><span class="pre">metric='precomputed'</span></code> was deprecated and now raises an error</p>
</div>
</p></li>
<li><p><strong>shrink_threshold</strong> (<em>float</em><em>, </em><em>default=None</em>) – Threshold for shrinking centroids to remove features.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.NearestCentroid.centroids_">
<span class="sig-name descname"><span class="pre">centroids_</span></span><a class="headerlink" href="#sklearn.neighbors.NearestCentroid.centroids_" title="Permalink to this definition">¶</a></dt>
<dd><p>Centroid of each class.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like of shape (n_classes, n_features)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.NearestCentroid.classes_">
<span class="sig-name descname"><span class="pre">classes_</span></span><a class="headerlink" href="#sklearn.neighbors.NearestCentroid.classes_" title="Permalink to this definition">¶</a></dt>
<dd><p>The unique classes labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array of shape (n_classes,)</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">NearestCentroid</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">NearestCentroid</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">NearestCentroid()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.8</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]]))</span>
<span class="go">[1]</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.neighbors.KNeighborsClassifier" title="sklearn.neighbors.KNeighborsClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">KNeighborsClassifier</span></code></a></dt><dd><p>Nearest neighbors classifier.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>When used for text classification with tf-idf vectors, this classifier is
also known as the Rocchio classifier.</p>
<p class="rubric">References</p>
<p>Tibshirani, R., Hastie, T., Narasimhan, B., &amp; Chu, G. (2002). Diagnosis of
multiple cancer types by shrunken centroids of gene expression. Proceedings
of the National Academy of Sciences of the United States of America,
99(10), 6567-6572. The National Academy of Sciences.</p>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.NearestCentroid.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.NearestCentroid.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the NearestCentroid model according to the given training data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Training vector, where n_samples is the number of samples and
n_features is the number of features.
Note that centroid shrinking cannot be used with sparse matrices.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Target values (integers)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.NearestCentroid.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.NearestCentroid.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform classification on an array of test vectors X.</p>
<p>The predicted class C for each sample in X is returned.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – </p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>C</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray of shape (n_samples,)</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>If the metric constructor parameter is “precomputed”, X is assumed to
be the distance matrix between the data to be predicted and
<code class="docutils literal notranslate"><span class="pre">self.centroids_</span></code>.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.neighbors.NearestNeighbors">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.neighbors.</span></span><span class="sig-name descname"><span class="pre">NearestNeighbors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_neighbors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">radius</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">leaf_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">30</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'minkowski'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.NearestNeighbors" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.neighbors._base.KNeighborsMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.neighbors._base.RadiusNeighborsMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.neighbors._base.NeighborsBase</span></code></p>
<p>Unsupervised learner for implementing neighbor searches.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.9.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_neighbors</strong> (<em>int</em><em>, </em><em>default=5</em>) – Number of neighbors to use by default for <code class="xref py py-meth docutils literal notranslate"><span class="pre">kneighbors()</span></code> queries.</p></li>
<li><p><strong>radius</strong> (<em>float</em><em>, </em><em>default=1.0</em>) – Range of parameter space to use by default for <code class="xref py py-meth docutils literal notranslate"><span class="pre">radius_neighbors()</span></code>
queries.</p></li>
<li><p><strong>algorithm</strong> (<em>{'auto'</em><em>, </em><em>'ball_tree'</em><em>, </em><em>'kd_tree'</em><em>, </em><em>'brute'}</em><em>, </em><em>default='auto'</em>) – <p>Algorithm used to compute the nearest neighbors:</p>
<ul>
<li><p>’ball_tree’ will use <a class="reference internal" href="#sklearn.neighbors.BallTree" title="sklearn.neighbors.BallTree"><code class="xref py py-class docutils literal notranslate"><span class="pre">BallTree</span></code></a></p></li>
<li><p>’kd_tree’ will use <a class="reference internal" href="#sklearn.neighbors.KDTree" title="sklearn.neighbors.KDTree"><code class="xref py py-class docutils literal notranslate"><span class="pre">KDTree</span></code></a></p></li>
<li><p>’brute’ will use a brute-force search.</p></li>
<li><p>’auto’ will attempt to decide the most appropriate algorithm
based on the values passed to <a class="reference internal" href="#sklearn.neighbors.NearestNeighbors.fit" title="sklearn.neighbors.NearestNeighbors.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p></li>
</ul>
<p>Note: fitting on sparse input will override the setting of
this parameter, using brute force.</p>
</p></li>
<li><p><strong>leaf_size</strong> (<em>int</em><em>, </em><em>default=30</em>) – Leaf size passed to BallTree or KDTree.  This can affect the
speed of the construction and query, as well as the memory
required to store the tree.  The optimal value depends on the
nature of the problem.</p></li>
<li><p><strong>metric</strong> (<em>str</em><em> or </em><em>callable</em><em>, </em><em>default='minkowski'</em>) – the distance metric to use for the tree.  The default metric is
minkowski, and with p=2 is equivalent to the standard Euclidean
metric. See the documentation of <a class="reference internal" href="#sklearn.neighbors.DistanceMetric" title="sklearn.neighbors.DistanceMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">DistanceMetric</span></code></a> for a
list of available metrics.
If metric is “precomputed”, X is assumed to be a distance matrix and
must be square during fit. X may be a <span class="xref std std-term">sparse graph</span>,
in which case only “nonzero” elements may be considered neighbors.</p></li>
<li><p><strong>p</strong> (<em>int</em><em>, </em><em>default=2</em>) – Parameter for the Minkowski metric from
sklearn.metrics.pairwise.pairwise_distances. When p = 1, this is
equivalent to using manhattan_distance (l1), and euclidean_distance
(l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.</p></li>
<li><p><strong>metric_params</strong> (<em>dict</em><em>, </em><em>default=None</em>) – Additional keyword arguments for the metric function.</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default=None</em>) – The number of parallel jobs to run for neighbors search.
<code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a <code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context.
<code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all processors. See <span class="xref std std-term">Glossary</span>
for more details.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.NearestNeighbors.effective_metric_">
<span class="sig-name descname"><span class="pre">effective_metric_</span></span><a class="headerlink" href="#sklearn.neighbors.NearestNeighbors.effective_metric_" title="Permalink to this definition">¶</a></dt>
<dd><p>Metric used to compute distances to neighbors.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.NearestNeighbors.effective_metric_params_">
<span class="sig-name descname"><span class="pre">effective_metric_params_</span></span><a class="headerlink" href="#sklearn.neighbors.NearestNeighbors.effective_metric_params_" title="Permalink to this definition">¶</a></dt>
<dd><p>Parameters for the metric used to compute distances to neighbors.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.NearestNeighbors.n_samples_fit_">
<span class="sig-name descname"><span class="pre">n_samples_fit_</span></span><a class="headerlink" href="#sklearn.neighbors.NearestNeighbors.n_samples_fit_" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of samples in the fitted data.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">NearestNeighbors</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">neigh</span> <span class="o">=</span> <span class="n">NearestNeighbors</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">radius</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">neigh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
<span class="go">NearestNeighbors(...)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">neigh</span><span class="o">.</span><span class="n">kneighbors</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">]],</span> <span class="mi">2</span><span class="p">,</span> <span class="n">return_distance</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">array([[2, 0]]...)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">nbrs</span> <span class="o">=</span> <span class="n">neigh</span><span class="o">.</span><span class="n">radius_neighbors</span><span class="p">(</span>
<span class="gp">... </span>   <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">]],</span> <span class="mf">0.4</span><span class="p">,</span> <span class="n">return_distance</span><span class="o">=</span><span class="kc">False</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">nbrs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
<span class="go">array(2)</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#sklearn.neighbors.KNeighborsClassifier" title="sklearn.neighbors.KNeighborsClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">KNeighborsClassifier</span></code></a>, <a class="reference internal" href="#sklearn.neighbors.RadiusNeighborsClassifier" title="sklearn.neighbors.RadiusNeighborsClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RadiusNeighborsClassifier</span></code></a>, <a class="reference internal" href="#sklearn.neighbors.KNeighborsRegressor" title="sklearn.neighbors.KNeighborsRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">KNeighborsRegressor</span></code></a>, <a class="reference internal" href="#sklearn.neighbors.RadiusNeighborsRegressor" title="sklearn.neighbors.RadiusNeighborsRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RadiusNeighborsRegressor</span></code></a>, <a class="reference internal" href="#sklearn.neighbors.BallTree" title="sklearn.neighbors.BallTree"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BallTree</span></code></a></p>
</div>
<p class="rubric">Notes</p>
<p>See <span class="xref std std-ref">Nearest Neighbors</span> in the online documentation
for a discussion of the choice of <code class="docutils literal notranslate"><span class="pre">algorithm</span></code> and <code class="docutils literal notranslate"><span class="pre">leaf_size</span></code>.</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm">https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.NearestNeighbors.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.NearestNeighbors.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the nearest neighbors estimator from the training dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>) or                 </em><em>(</em><em>n_samples</em><em>, </em><em>n_samples</em><em>) </em><em>if metric='precomputed'</em>) – Training data.</p></li>
<li><p><strong>y</strong> (<em>Ignored</em>) – Not used, present for API consistency by convention.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – The fitted nearest neighbors estimator.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#sklearn.neighbors.NearestNeighbors" title="sklearn.neighbors.NearestNeighbors">NearestNeighbors</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.neighbors.NeighborhoodComponentsAnalysis">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.neighbors.</span></span><span class="sig-name descname"><span class="pre">NeighborhoodComponentsAnalysis</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_components</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.NeighborhoodComponentsAnalysis" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.TransformerMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.BaseEstimator</span></code></p>
<p>Neighborhood Components Analysis</p>
<p>Neighborhood Component Analysis (NCA) is a machine learning algorithm for
metric learning. It learns a linear transformation in a supervised fashion
to improve the classification accuracy of a stochastic nearest neighbors
rule in the transformed space.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_components</strong> (<em>int</em><em>, </em><em>default=None</em>) – Preferred dimensionality of the projected space.
If None it will be set to <code class="docutils literal notranslate"><span class="pre">n_features</span></code>.</p></li>
<li><p><strong>init</strong> (<em>{'auto'</em><em>, </em><em>'pca'</em><em>, </em><em>'lda'</em><em>, </em><em>'identity'</em><em>, </em><em>'random'}</em><em> or </em><em>ndarray of shape</em><em>             (</em><em>n_features_a</em><em>, </em><em>n_features_b</em><em>)</em><em>, </em><em>default='auto'</em>) – <p>Initialization of the linear transformation. Possible options are
‘auto’, ‘pca’, ‘lda’, ‘identity’, ‘random’, and a numpy array of shape
(n_features_a, n_features_b).</p>
<dl class="simple">
<dt>’auto’</dt><dd><p>Depending on <code class="docutils literal notranslate"><span class="pre">n_components</span></code>, the most reasonable initialization
will be chosen. If <code class="docutils literal notranslate"><span class="pre">n_components</span> <span class="pre">&lt;=</span> <span class="pre">n_classes</span></code> we use ‘lda’, as
it uses labels information. If not, but
<code class="docutils literal notranslate"><span class="pre">n_components</span> <span class="pre">&lt;</span> <span class="pre">min(n_features,</span> <span class="pre">n_samples)</span></code>, we use ‘pca’, as
it projects data in meaningful directions (those of higher
variance). Otherwise, we just use ‘identity’.</p>
</dd>
<dt>’pca’</dt><dd><p><code class="docutils literal notranslate"><span class="pre">n_components</span></code> principal components of the inputs passed
to <a class="reference internal" href="#sklearn.neighbors.NeighborhoodComponentsAnalysis.fit" title="sklearn.neighbors.NeighborhoodComponentsAnalysis.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> will be used to initialize the transformation.
(See <code class="xref py py-class docutils literal notranslate"><span class="pre">PCA</span></code>)</p>
</dd>
<dt>’lda’</dt><dd><p><code class="docutils literal notranslate"><span class="pre">min(n_components,</span> <span class="pre">n_classes)</span></code> most discriminative
components of the inputs passed to <a class="reference internal" href="#sklearn.neighbors.NeighborhoodComponentsAnalysis.fit" title="sklearn.neighbors.NeighborhoodComponentsAnalysis.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> will be used to
initialize the transformation. (If <code class="docutils literal notranslate"><span class="pre">n_components</span> <span class="pre">&gt;</span> <span class="pre">n_classes</span></code>,
the rest of the components will be zero.) (See
<code class="xref py py-class docutils literal notranslate"><span class="pre">LinearDiscriminantAnalysis</span></code>)</p>
</dd>
<dt>’identity’</dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">n_components</span></code> is strictly smaller than the
dimensionality of the inputs passed to <a class="reference internal" href="#sklearn.neighbors.NeighborhoodComponentsAnalysis.fit" title="sklearn.neighbors.NeighborhoodComponentsAnalysis.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>, the identity
matrix will be truncated to the first <code class="docutils literal notranslate"><span class="pre">n_components</span></code> rows.</p>
</dd>
<dt>’random’</dt><dd><p>The initial transformation will be a random array of shape
<cite>(n_components, n_features)</cite>. Each value is sampled from the
standard normal distribution.</p>
</dd>
<dt>numpy array</dt><dd><p>n_features_b must match the dimensionality of the inputs passed to
<a class="reference internal" href="#sklearn.neighbors.NeighborhoodComponentsAnalysis.fit" title="sklearn.neighbors.NeighborhoodComponentsAnalysis.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> and n_features_a must be less than or equal to that.
If <code class="docutils literal notranslate"><span class="pre">n_components</span></code> is not None, n_features_a must match it.</p>
</dd>
</dl>
</p></li>
<li><p><strong>warm_start</strong> (<em>bool</em><em>, </em><em>default=False</em>) – If True and <a class="reference internal" href="#sklearn.neighbors.NeighborhoodComponentsAnalysis.fit" title="sklearn.neighbors.NeighborhoodComponentsAnalysis.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> has been called before, the solution of the
previous call to <a class="reference internal" href="#sklearn.neighbors.NeighborhoodComponentsAnalysis.fit" title="sklearn.neighbors.NeighborhoodComponentsAnalysis.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> is used as the initial linear
transformation (<code class="docutils literal notranslate"><span class="pre">n_components</span></code> and <code class="docutils literal notranslate"><span class="pre">init</span></code> will be ignored).</p></li>
<li><p><strong>max_iter</strong> (<em>int</em><em>, </em><em>default=50</em>) – Maximum number of iterations in the optimization.</p></li>
<li><p><strong>tol</strong> (<em>float</em><em>, </em><em>default=1e-5</em>) – Convergence tolerance for the optimization.</p></li>
<li><p><strong>callback</strong> (<em>callable</em><em>, </em><em>default=None</em>) – If not None, this function is called after every iteration of the
optimizer, taking as arguments the current solution (flattened
transformation matrix) and the number of iterations. This might be
useful in case one wants to examine or store the transformation
found after each iteration.</p></li>
<li><p><strong>verbose</strong> (<em>int</em><em>, </em><em>default=0</em>) – If 0, no progress messages will be printed.
If 1, progress messages will be printed to stdout.
If &gt; 1, progress messages will be printed and the <code class="docutils literal notranslate"><span class="pre">disp</span></code>
parameter of <code class="xref py py-func docutils literal notranslate"><span class="pre">scipy.optimize.minimize()</span></code> will be set to
<code class="docutils literal notranslate"><span class="pre">verbose</span> <span class="pre">-</span> <span class="pre">2</span></code>.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em> or </em><em>numpy.RandomState</em><em>, </em><em>default=None</em>) – A pseudo random number generator object or a seed for it if int. If
<code class="docutils literal notranslate"><span class="pre">init='random'</span></code>, <code class="docutils literal notranslate"><span class="pre">random_state</span></code> is used to initialize the random
transformation. If <code class="docutils literal notranslate"><span class="pre">init='pca'</span></code>, <code class="docutils literal notranslate"><span class="pre">random_state</span></code> is passed as an
argument to PCA when initializing the transformation. Pass an int
for reproducible results across multiple function calls.
See :term: <cite>Glossary &lt;random_state&gt;</cite>.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.NeighborhoodComponentsAnalysis.components_">
<span class="sig-name descname"><span class="pre">components_</span></span><a class="headerlink" href="#sklearn.neighbors.NeighborhoodComponentsAnalysis.components_" title="Permalink to this definition">¶</a></dt>
<dd><p>The linear transformation learned during fitting.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray of shape (n_components, n_features)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.NeighborhoodComponentsAnalysis.n_iter_">
<span class="sig-name descname"><span class="pre">n_iter_</span></span><a class="headerlink" href="#sklearn.neighbors.NeighborhoodComponentsAnalysis.n_iter_" title="Permalink to this definition">¶</a></dt>
<dd><p>Counts the number of iterations performed by the optimizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.NeighborhoodComponentsAnalysis.random_state_">
<span class="sig-name descname"><span class="pre">random_state_</span></span><a class="headerlink" href="#sklearn.neighbors.NeighborhoodComponentsAnalysis.random_state_" title="Permalink to this definition">¶</a></dt>
<dd><p>Pseudo random number generator object used during initialization.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>numpy.RandomState</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">NeighborhoodComponentsAnalysis</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
<span class="gp">... </span><span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nca</span> <span class="o">=</span> <span class="n">NeighborhoodComponentsAnalysis</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="go">NeighborhoodComponentsAnalysis(...)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="go">KNeighborsClassifier(...)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
<span class="go">0.933333...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">nca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">y_train</span><span class="p">)</span>
<span class="go">KNeighborsClassifier(...)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">nca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">y_test</span><span class="p">))</span>
<span class="go">0.961904...</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id2"><span class="brackets">1</span></dt>
<dd><p>J. Goldberger, G. Hinton, S. Roweis, R. Salakhutdinov.
“Neighbourhood Components Analysis”. Advances in Neural Information
Processing Systems. 17, 513-520, 2005.
<a class="reference external" href="http://www.cs.nyu.edu/~roweis/papers/ncanips.pdf">http://www.cs.nyu.edu/~roweis/papers/ncanips.pdf</a></p>
</dd>
<dt class="label" id="id3"><span class="brackets">2</span></dt>
<dd><p>Wikipedia entry on Neighborhood Components Analysis
<a class="reference external" href="https://en.wikipedia.org/wiki/Neighbourhood_components_analysis">https://en.wikipedia.org/wiki/Neighbourhood_components_analysis</a></p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.NeighborhoodComponentsAnalysis.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.NeighborhoodComponentsAnalysis.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model according to the given training data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training samples.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The corresponding training labels.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – returns a trained NeighborhoodComponentsAnalysis model.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.NeighborhoodComponentsAnalysis.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.NeighborhoodComponentsAnalysis.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the learned transformation to the given data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Data samples.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_embedded</strong> – The data samples transformed.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray of shape (n_samples, n_components)</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>NotFittedError</strong> – If <a class="reference internal" href="#sklearn.neighbors.NeighborhoodComponentsAnalysis.fit" title="sklearn.neighbors.NeighborhoodComponentsAnalysis.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> has not been called before.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.neighbors.RadiusNeighborsClassifier">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.neighbors.</span></span><span class="sig-name descname"><span class="pre">RadiusNeighborsClassifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">radius</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'uniform'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">leaf_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">30</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'minkowski'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outlier_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.RadiusNeighborsClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.neighbors._base.RadiusNeighborsMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.ClassifierMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.neighbors._base.NeighborsBase</span></code></p>
<p>Classifier implementing a vote among neighbors within a given radius</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>radius</strong> (<em>float</em><em>, </em><em>default=1.0</em>) – Range of parameter space to use by default for <code class="xref py py-meth docutils literal notranslate"><span class="pre">radius_neighbors()</span></code>
queries.</p></li>
<li><p><strong>weights</strong> (<em>{'uniform'</em><em>, </em><em>'distance'}</em><em> or </em><em>callable</em><em>, </em><em>default='uniform'</em>) – <p>weight function used in prediction.  Possible values:</p>
<ul>
<li><p>’uniform’ : uniform weights.  All points in each neighborhood
are weighted equally.</p></li>
<li><p>’distance’ : weight points by the inverse of their distance.
in this case, closer neighbors of a query point will have a
greater influence than neighbors which are further away.</p></li>
<li><p>[callable] : a user-defined function which accepts an
array of distances, and returns an array of the same shape
containing the weights.</p></li>
</ul>
<p>Uniform weights are used by default.</p>
</p></li>
<li><p><strong>algorithm</strong> (<em>{'auto'</em><em>, </em><em>'ball_tree'</em><em>, </em><em>'kd_tree'</em><em>, </em><em>'brute'}</em><em>, </em><em>default='auto'</em>) – <p>Algorithm used to compute the nearest neighbors:</p>
<ul>
<li><p>’ball_tree’ will use <a class="reference internal" href="#sklearn.neighbors.BallTree" title="sklearn.neighbors.BallTree"><code class="xref py py-class docutils literal notranslate"><span class="pre">BallTree</span></code></a></p></li>
<li><p>’kd_tree’ will use <a class="reference internal" href="#sklearn.neighbors.KDTree" title="sklearn.neighbors.KDTree"><code class="xref py py-class docutils literal notranslate"><span class="pre">KDTree</span></code></a></p></li>
<li><p>’brute’ will use a brute-force search.</p></li>
<li><p>’auto’ will attempt to decide the most appropriate algorithm
based on the values passed to <a class="reference internal" href="#sklearn.neighbors.RadiusNeighborsClassifier.fit" title="sklearn.neighbors.RadiusNeighborsClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p></li>
</ul>
<p>Note: fitting on sparse input will override the setting of
this parameter, using brute force.</p>
</p></li>
<li><p><strong>leaf_size</strong> (<em>int</em><em>, </em><em>default=30</em>) – Leaf size passed to BallTree or KDTree.  This can affect the
speed of the construction and query, as well as the memory
required to store the tree.  The optimal value depends on the
nature of the problem.</p></li>
<li><p><strong>p</strong> (<em>int</em><em>, </em><em>default=2</em>) – Power parameter for the Minkowski metric. When p = 1, this is
equivalent to using manhattan_distance (l1), and euclidean_distance
(l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.</p></li>
<li><p><strong>metric</strong> (<em>str</em><em> or </em><em>callable</em><em>, </em><em>default='minkowski'</em>) – the distance metric to use for the tree.  The default metric is
minkowski, and with p=2 is equivalent to the standard Euclidean
metric. See the documentation of <a class="reference internal" href="#sklearn.neighbors.DistanceMetric" title="sklearn.neighbors.DistanceMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">DistanceMetric</span></code></a> for a
list of available metrics.
If metric is “precomputed”, X is assumed to be a distance matrix and
must be square during fit. X may be a <span class="xref std std-term">sparse graph</span>,
in which case only “nonzero” elements may be considered neighbors.</p></li>
<li><p><strong>outlier_label</strong> (<em>{manual label</em><em>, </em><em>'most_frequent'}</em><em>, </em><em>default=None</em>) – <p>label for outlier samples (samples with no neighbors in given radius).</p>
<ul>
<li><p>manual label: str or int label (should be the same type as y)
or list of manual labels if multi-output is used.</p></li>
<li><p>’most_frequent’ : assign the most frequent label of y to outliers.</p></li>
<li><p>None : when any outlier is detected, ValueError will be raised.</p></li>
</ul>
</p></li>
<li><p><strong>metric_params</strong> (<em>dict</em><em>, </em><em>default=None</em>) – Additional keyword arguments for the metric function.</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default=None</em>) – The number of parallel jobs to run for neighbors search.
<code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a <code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context.
<code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all processors. See <span class="xref std std-term">Glossary</span>
for more details.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.RadiusNeighborsClassifier.classes_">
<span class="sig-name descname"><span class="pre">classes_</span></span><a class="headerlink" href="#sklearn.neighbors.RadiusNeighborsClassifier.classes_" title="Permalink to this definition">¶</a></dt>
<dd><p>Class labels known to the classifier.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray of shape (n_classes,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.RadiusNeighborsClassifier.effective_metric_">
<span class="sig-name descname"><span class="pre">effective_metric_</span></span><a class="headerlink" href="#sklearn.neighbors.RadiusNeighborsClassifier.effective_metric_" title="Permalink to this definition">¶</a></dt>
<dd><p>The distance metric used. It will be same as the <cite>metric</cite> parameter
or a synonym of it, e.g. ‘euclidean’ if the <cite>metric</cite> parameter set to
‘minkowski’ and <cite>p</cite> parameter set to 2.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>str or callable</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.RadiusNeighborsClassifier.effective_metric_params_">
<span class="sig-name descname"><span class="pre">effective_metric_params_</span></span><a class="headerlink" href="#sklearn.neighbors.RadiusNeighborsClassifier.effective_metric_params_" title="Permalink to this definition">¶</a></dt>
<dd><p>Additional keyword arguments for the metric function. For most metrics
will be same with <cite>metric_params</cite> parameter, but may also contain the
<cite>p</cite> parameter value if the <cite>effective_metric_</cite> attribute is set to
‘minkowski’.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.RadiusNeighborsClassifier.n_samples_fit_">
<span class="sig-name descname"><span class="pre">n_samples_fit_</span></span><a class="headerlink" href="#sklearn.neighbors.RadiusNeighborsClassifier.n_samples_fit_" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of samples in the fitted data.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.RadiusNeighborsClassifier.outlier_label_">
<span class="sig-name descname"><span class="pre">outlier_label_</span></span><a class="headerlink" href="#sklearn.neighbors.RadiusNeighborsClassifier.outlier_label_" title="Permalink to this definition">¶</a></dt>
<dd><p>Label which is given for outlier samples (samples with no neighbors
on given radius).</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int or array-like of shape (n_class,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.RadiusNeighborsClassifier.outputs_2d_">
<span class="sig-name descname"><span class="pre">outputs_2d_</span></span><a class="headerlink" href="#sklearn.neighbors.RadiusNeighborsClassifier.outputs_2d_" title="Permalink to this definition">¶</a></dt>
<dd><p>False when <cite>y</cite>’s shape is (n_samples, ) or (n_samples, 1) during fit
otherwise True.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">RadiusNeighborsClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">neigh</span> <span class="o">=</span> <span class="n">RadiusNeighborsClassifier</span><span class="p">(</span><span class="n">radius</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">neigh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">RadiusNeighborsClassifier(...)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">neigh</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mf">1.5</span><span class="p">]]))</span>
<span class="go">[0]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">neigh</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">]]))</span>
<span class="go">[[0.66666667 0.33333333]]</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#sklearn.neighbors.KNeighborsClassifier" title="sklearn.neighbors.KNeighborsClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">KNeighborsClassifier</span></code></a>, <a class="reference internal" href="#sklearn.neighbors.RadiusNeighborsRegressor" title="sklearn.neighbors.RadiusNeighborsRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RadiusNeighborsRegressor</span></code></a>, <a class="reference internal" href="#sklearn.neighbors.KNeighborsRegressor" title="sklearn.neighbors.KNeighborsRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">KNeighborsRegressor</span></code></a>, <a class="reference internal" href="#sklearn.neighbors.NearestNeighbors" title="sklearn.neighbors.NearestNeighbors"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NearestNeighbors</span></code></a></p>
</div>
<p class="rubric">Notes</p>
<p>See <span class="xref std std-ref">Nearest Neighbors</span> in the online documentation
for a discussion of the choice of <code class="docutils literal notranslate"><span class="pre">algorithm</span></code> and <code class="docutils literal notranslate"><span class="pre">leaf_size</span></code>.</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm">https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.RadiusNeighborsClassifier.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.RadiusNeighborsClassifier.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the radius neighbors classifier from the training dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>) or                 </em><em>(</em><em>n_samples</em><em>, </em><em>n_samples</em><em>) </em><em>if metric='precomputed'</em>) – Training data.</p></li>
<li><p><strong>y</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or                 </em><em>(</em><em>n_samples</em><em>, </em><em>n_outputs</em><em>)</em>) – Target values.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – The fitted radius neighbors classifier.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#sklearn.neighbors.RadiusNeighborsClassifier" title="sklearn.neighbors.RadiusNeighborsClassifier">RadiusNeighborsClassifier</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.RadiusNeighborsClassifier.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.RadiusNeighborsClassifier.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the class labels for the provided data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_queries</em><em>, </em><em>n_features</em><em>)</em><em>,                 or </em><em>(</em><em>n_queries</em><em>, </em><em>n_indexed</em><em>) </em><em>if metric == 'precomputed'</em>) – Test samples.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> – Class labels for each data sample.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray of shape (n_queries,) or (n_queries, n_outputs)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.RadiusNeighborsClassifier.predict_proba">
<span class="sig-name descname"><span class="pre">predict_proba</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.RadiusNeighborsClassifier.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Return probability estimates for the test data X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_queries</em><em>, </em><em>n_features</em><em>)</em><em>,                 or </em><em>(</em><em>n_queries</em><em>, </em><em>n_indexed</em><em>) </em><em>if metric == 'precomputed'</em>) – Test samples.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>p</strong> – of such arrays if n_outputs &gt; 1.
The class probabilities of the input samples. Classes are ordered
by lexicographic order.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray of shape (n_queries, n_classes), or a list of n_outputs</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.neighbors.RadiusNeighborsRegressor">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.neighbors.</span></span><span class="sig-name descname"><span class="pre">RadiusNeighborsRegressor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">radius</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'uniform'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">leaf_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">30</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'minkowski'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.RadiusNeighborsRegressor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.neighbors._base.RadiusNeighborsMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.RegressorMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.neighbors._base.NeighborsBase</span></code></p>
<p>Regression based on neighbors within a fixed radius.</p>
<p>The target is predicted by local interpolation of the targets
associated of the nearest neighbors in the training set.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.9.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>radius</strong> (<em>float</em><em>, </em><em>default=1.0</em>) – Range of parameter space to use by default for <code class="xref py py-meth docutils literal notranslate"><span class="pre">radius_neighbors()</span></code>
queries.</p></li>
<li><p><strong>weights</strong> (<em>{'uniform'</em><em>, </em><em>'distance'}</em><em> or </em><em>callable</em><em>, </em><em>default='uniform'</em>) – <p>weight function used in prediction.  Possible values:</p>
<ul>
<li><p>’uniform’ : uniform weights.  All points in each neighborhood
are weighted equally.</p></li>
<li><p>’distance’ : weight points by the inverse of their distance.
in this case, closer neighbors of a query point will have a
greater influence than neighbors which are further away.</p></li>
<li><p>[callable] : a user-defined function which accepts an
array of distances, and returns an array of the same shape
containing the weights.</p></li>
</ul>
<p>Uniform weights are used by default.</p>
</p></li>
<li><p><strong>algorithm</strong> (<em>{'auto'</em><em>, </em><em>'ball_tree'</em><em>, </em><em>'kd_tree'</em><em>, </em><em>'brute'}</em><em>, </em><em>default='auto'</em>) – <p>Algorithm used to compute the nearest neighbors:</p>
<ul>
<li><p>’ball_tree’ will use <a class="reference internal" href="#sklearn.neighbors.BallTree" title="sklearn.neighbors.BallTree"><code class="xref py py-class docutils literal notranslate"><span class="pre">BallTree</span></code></a></p></li>
<li><p>’kd_tree’ will use <a class="reference internal" href="#sklearn.neighbors.KDTree" title="sklearn.neighbors.KDTree"><code class="xref py py-class docutils literal notranslate"><span class="pre">KDTree</span></code></a></p></li>
<li><p>’brute’ will use a brute-force search.</p></li>
<li><p>’auto’ will attempt to decide the most appropriate algorithm
based on the values passed to <a class="reference internal" href="#sklearn.neighbors.RadiusNeighborsRegressor.fit" title="sklearn.neighbors.RadiusNeighborsRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p></li>
</ul>
<p>Note: fitting on sparse input will override the setting of
this parameter, using brute force.</p>
</p></li>
<li><p><strong>leaf_size</strong> (<em>int</em><em>, </em><em>default=30</em>) – Leaf size passed to BallTree or KDTree.  This can affect the
speed of the construction and query, as well as the memory
required to store the tree.  The optimal value depends on the
nature of the problem.</p></li>
<li><p><strong>p</strong> (<em>int</em><em>, </em><em>default=2</em>) – Power parameter for the Minkowski metric. When p = 1, this is
equivalent to using manhattan_distance (l1), and euclidean_distance
(l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.</p></li>
<li><p><strong>metric</strong> (<em>str</em><em> or </em><em>callable</em><em>, </em><em>default='minkowski'</em>) – the distance metric to use for the tree.  The default metric is
minkowski, and with p=2 is equivalent to the standard Euclidean
metric. See the documentation of <a class="reference internal" href="#sklearn.neighbors.DistanceMetric" title="sklearn.neighbors.DistanceMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">DistanceMetric</span></code></a> for a
list of available metrics.
If metric is “precomputed”, X is assumed to be a distance matrix and
must be square during fit. X may be a <span class="xref std std-term">sparse graph</span>,
in which case only “nonzero” elements may be considered neighbors.</p></li>
<li><p><strong>metric_params</strong> (<em>dict</em><em>, </em><em>default=None</em>) – Additional keyword arguments for the metric function.</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default=None</em>) – The number of parallel jobs to run for neighbors search.
<code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a <code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context.
<code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all processors. See <span class="xref std std-term">Glossary</span>
for more details.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.RadiusNeighborsRegressor.effective_metric_">
<span class="sig-name descname"><span class="pre">effective_metric_</span></span><a class="headerlink" href="#sklearn.neighbors.RadiusNeighborsRegressor.effective_metric_" title="Permalink to this definition">¶</a></dt>
<dd><p>The distance metric to use. It will be same as the <cite>metric</cite> parameter
or a synonym of it, e.g. ‘euclidean’ if the <cite>metric</cite> parameter set to
‘minkowski’ and <cite>p</cite> parameter set to 2.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>str or callable</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.RadiusNeighborsRegressor.effective_metric_params_">
<span class="sig-name descname"><span class="pre">effective_metric_params_</span></span><a class="headerlink" href="#sklearn.neighbors.RadiusNeighborsRegressor.effective_metric_params_" title="Permalink to this definition">¶</a></dt>
<dd><p>Additional keyword arguments for the metric function. For most metrics
will be same with <cite>metric_params</cite> parameter, but may also contain the
<cite>p</cite> parameter value if the <cite>effective_metric_</cite> attribute is set to
‘minkowski’.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.RadiusNeighborsRegressor.n_samples_fit_">
<span class="sig-name descname"><span class="pre">n_samples_fit_</span></span><a class="headerlink" href="#sklearn.neighbors.RadiusNeighborsRegressor.n_samples_fit_" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of samples in the fitted data.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">RadiusNeighborsRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">neigh</span> <span class="o">=</span> <span class="n">RadiusNeighborsRegressor</span><span class="p">(</span><span class="n">radius</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">neigh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">RadiusNeighborsRegressor(...)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">neigh</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mf">1.5</span><span class="p">]]))</span>
<span class="go">[0.5]</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#sklearn.neighbors.NearestNeighbors" title="sklearn.neighbors.NearestNeighbors"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NearestNeighbors</span></code></a>, <a class="reference internal" href="#sklearn.neighbors.KNeighborsRegressor" title="sklearn.neighbors.KNeighborsRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">KNeighborsRegressor</span></code></a>, <a class="reference internal" href="#sklearn.neighbors.KNeighborsClassifier" title="sklearn.neighbors.KNeighborsClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">KNeighborsClassifier</span></code></a>, <a class="reference internal" href="#sklearn.neighbors.RadiusNeighborsClassifier" title="sklearn.neighbors.RadiusNeighborsClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RadiusNeighborsClassifier</span></code></a></p>
</div>
<p class="rubric">Notes</p>
<p>See <span class="xref std std-ref">Nearest Neighbors</span> in the online documentation
for a discussion of the choice of <code class="docutils literal notranslate"><span class="pre">algorithm</span></code> and <code class="docutils literal notranslate"><span class="pre">leaf_size</span></code>.</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm">https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.RadiusNeighborsRegressor.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.RadiusNeighborsRegressor.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the radius neighbors regressor from the training dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>) or                 </em><em>(</em><em>n_samples</em><em>, </em><em>n_samples</em><em>) </em><em>if metric='precomputed'</em>) – Training data.</p></li>
<li><p><strong>y</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or                 </em><em>(</em><em>n_samples</em><em>, </em><em>n_outputs</em><em>)</em>) – Target values.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – The fitted radius neighbors regressor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#sklearn.neighbors.RadiusNeighborsRegressor" title="sklearn.neighbors.RadiusNeighborsRegressor">RadiusNeighborsRegressor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.RadiusNeighborsRegressor.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.RadiusNeighborsRegressor.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the target for the provided data</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_queries</em><em>, </em><em>n_features</em><em>)</em><em>,                 or </em><em>(</em><em>n_queries</em><em>, </em><em>n_indexed</em><em>) </em><em>if metric == 'precomputed'</em>) – Test samples.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> – Target values.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray of shape (n_queries,) or (n_queries, n_outputs),                 dtype=double</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.neighbors.RadiusNeighborsTransformer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.neighbors.</span></span><span class="sig-name descname"><span class="pre">RadiusNeighborsTransformer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'distance'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">radius</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">leaf_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">30</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'minkowski'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.RadiusNeighborsTransformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.neighbors._base.RadiusNeighborsMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.TransformerMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.neighbors._base.NeighborsBase</span></code></p>
<p>Transform X into a (weighted) graph of neighbors nearer than a radius</p>
<p>The transformed data is a sparse graph as returned by
radius_neighbors_graph.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.22.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mode</strong> (<em>{'distance'</em><em>, </em><em>'connectivity'}</em><em>, </em><em>default='distance'</em>) – Type of returned matrix: ‘connectivity’ will return the connectivity
matrix with ones and zeros, and ‘distance’ will return the distances
between neighbors according to the given metric.</p></li>
<li><p><strong>radius</strong> (<em>float</em><em>, </em><em>default=1.</em>) – Radius of neighborhood in the transformed sparse graph.</p></li>
<li><p><strong>algorithm</strong> (<em>{'auto'</em><em>, </em><em>'ball_tree'</em><em>, </em><em>'kd_tree'</em><em>, </em><em>'brute'}</em><em>, </em><em>default='auto'</em>) – <p>Algorithm used to compute the nearest neighbors:</p>
<ul>
<li><p>’ball_tree’ will use <a class="reference internal" href="#sklearn.neighbors.BallTree" title="sklearn.neighbors.BallTree"><code class="xref py py-class docutils literal notranslate"><span class="pre">BallTree</span></code></a></p></li>
<li><p>’kd_tree’ will use <a class="reference internal" href="#sklearn.neighbors.KDTree" title="sklearn.neighbors.KDTree"><code class="xref py py-class docutils literal notranslate"><span class="pre">KDTree</span></code></a></p></li>
<li><p>’brute’ will use a brute-force search.</p></li>
<li><p>’auto’ will attempt to decide the most appropriate algorithm
based on the values passed to <a class="reference internal" href="#sklearn.neighbors.RadiusNeighborsTransformer.fit" title="sklearn.neighbors.RadiusNeighborsTransformer.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p></li>
</ul>
<p>Note: fitting on sparse input will override the setting of
this parameter, using brute force.</p>
</p></li>
<li><p><strong>leaf_size</strong> (<em>int</em><em>, </em><em>default=30</em>) – Leaf size passed to BallTree or KDTree.  This can affect the
speed of the construction and query, as well as the memory
required to store the tree.  The optimal value depends on the
nature of the problem.</p></li>
<li><p><strong>metric</strong> (<em>str</em><em> or </em><em>callable</em><em>, </em><em>default='minkowski'</em>) – <p>metric to use for distance computation. Any metric from scikit-learn
or scipy.spatial.distance can be used.</p>
<p>If metric is a callable function, it is called on each
pair of instances (rows) and the resulting value recorded. The callable
should take two arrays as input and return one value indicating the
distance between them. This works for Scipy’s metrics, but is less
efficient than passing the metric name as a string.</p>
<p>Distance matrices are not supported.</p>
<p>Valid values for metric are:</p>
<ul>
<li><p>from scikit-learn: [‘cityblock’, ‘cosine’, ‘euclidean’, ‘l1’, ‘l2’,
‘manhattan’]</p></li>
<li><p>from scipy.spatial.distance: [‘braycurtis’, ‘canberra’, ‘chebyshev’,
‘correlation’, ‘dice’, ‘hamming’, ‘jaccard’, ‘kulsinski’,
‘mahalanobis’, ‘minkowski’, ‘rogerstanimoto’, ‘russellrao’,
‘seuclidean’, ‘sokalmichener’, ‘sokalsneath’, ‘sqeuclidean’,
‘yule’]</p></li>
</ul>
<p>See the documentation for scipy.spatial.distance for details on these
metrics.</p>
</p></li>
<li><p><strong>p</strong> (<em>int</em><em>, </em><em>default=2</em>) – Parameter for the Minkowski metric from
sklearn.metrics.pairwise.pairwise_distances. When p = 1, this is
equivalent to using manhattan_distance (l1), and euclidean_distance
(l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.</p></li>
<li><p><strong>metric_params</strong> (<em>dict</em><em>, </em><em>default=None</em>) – Additional keyword arguments for the metric function.</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default=1</em>) – The number of parallel jobs to run for neighbors search.
If <code class="docutils literal notranslate"><span class="pre">-1</span></code>, then the number of jobs is set to the number of CPU cores.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.RadiusNeighborsTransformer.effective_metric_">
<span class="sig-name descname"><span class="pre">effective_metric_</span></span><a class="headerlink" href="#sklearn.neighbors.RadiusNeighborsTransformer.effective_metric_" title="Permalink to this definition">¶</a></dt>
<dd><p>The distance metric used. It will be same as the <cite>metric</cite> parameter
or a synonym of it, e.g. ‘euclidean’ if the <cite>metric</cite> parameter set to
‘minkowski’ and <cite>p</cite> parameter set to 2.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>str or callable</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.RadiusNeighborsTransformer.effective_metric_params_">
<span class="sig-name descname"><span class="pre">effective_metric_params_</span></span><a class="headerlink" href="#sklearn.neighbors.RadiusNeighborsTransformer.effective_metric_params_" title="Permalink to this definition">¶</a></dt>
<dd><p>Additional keyword arguments for the metric function. For most metrics
will be same with <cite>metric_params</cite> parameter, but may also contain the
<cite>p</cite> parameter value if the <cite>effective_metric_</cite> attribute is set to
‘minkowski’.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.neighbors.RadiusNeighborsTransformer.n_samples_fit_">
<span class="sig-name descname"><span class="pre">n_samples_fit_</span></span><a class="headerlink" href="#sklearn.neighbors.RadiusNeighborsTransformer.n_samples_fit_" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of samples in the fitted data.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">DBSCAN</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">RadiusNeighborsTransformer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">RadiusNeighborsTransformer</span><span class="p">(</span><span class="n">radius</span><span class="o">=</span><span class="mf">42.0</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;distance&#39;</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">DBSCAN</span><span class="p">(</span><span class="n">min_samples</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;precomputed&#39;</span><span class="p">))</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.RadiusNeighborsTransformer.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.RadiusNeighborsTransformer.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the radius neighbors transformer from the training dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>) or                 </em><em>(</em><em>n_samples</em><em>, </em><em>n_samples</em><em>) </em><em>if metric='precomputed'</em>) – Training data.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – The fitted radius neighbors transformer.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#sklearn.neighbors.RadiusNeighborsTransformer" title="sklearn.neighbors.RadiusNeighborsTransformer">RadiusNeighborsTransformer</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.RadiusNeighborsTransformer.fit_transform">
<span class="sig-name descname"><span class="pre">fit_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.RadiusNeighborsTransformer.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Training set.</p></li>
<li><p><strong>y</strong> (<em>ignored</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Xt</strong> – Xt[i, j] is assigned the weight of edge that connects i to j.
Only the neighbors have an explicit value.
The diagonal is always explicit.
The matrix is of CSR format.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>sparse matrix of shape (n_samples, n_samples)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neighbors.RadiusNeighborsTransformer.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.RadiusNeighborsTransformer.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the (weighted) graph of Neighbors for points in X</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples_transform</em><em>, </em><em>n_features</em><em>)</em>) – Sample data</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Xt</strong> – Xt[i, j] is assigned the weight of edge that connects i to j.
Only the neighbors have an explicit value.
The diagonal is always explicit.
The matrix is of CSR format.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>sparse matrix of shape (n_samples_transform, n_samples_fit)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sklearn.neighbors.kneighbors_graph">
<span class="sig-prename descclassname"><span class="pre">sklearn.neighbors.</span></span><span class="sig-name descname"><span class="pre">kneighbors_graph</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_neighbors</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'connectivity'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'minkowski'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_self</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.kneighbors_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the (weighted) graph of k-Neighbors for points in X</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>) or </em><a class="reference internal" href="#sklearn.neighbors.BallTree" title="sklearn.neighbors.BallTree"><em>BallTree</em></a>) – Sample data, in the form of a numpy array or a precomputed
<a class="reference internal" href="#sklearn.neighbors.BallTree" title="sklearn.neighbors.BallTree"><code class="xref py py-class docutils literal notranslate"><span class="pre">BallTree</span></code></a>.</p></li>
<li><p><strong>n_neighbors</strong> (<em>int</em>) – Number of neighbors for each sample.</p></li>
<li><p><strong>mode</strong> (<em>{'connectivity'</em><em>, </em><em>'distance'}</em><em>, </em><em>default='connectivity'</em>) – Type of returned matrix: ‘connectivity’ will return the connectivity
matrix with ones and zeros, and ‘distance’ will return the distances
between neighbors according to the given metric.</p></li>
<li><p><strong>metric</strong> (<em>str</em><em>, </em><em>default='minkowski'</em>) – The distance metric used to calculate the k-Neighbors for each sample
point. The DistanceMetric class gives a list of available metrics.
The default distance is ‘euclidean’ (‘minkowski’ metric with the p
param equal to 2.)</p></li>
<li><p><strong>p</strong> (<em>int</em><em>, </em><em>default=2</em>) – Power parameter for the Minkowski metric. When p = 1, this is
equivalent to using manhattan_distance (l1), and euclidean_distance
(l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.</p></li>
<li><p><strong>metric_params</strong> (<em>dict</em><em>, </em><em>default=None</em>) – additional keyword arguments for the metric function.</p></li>
<li><p><strong>include_self</strong> (<em>bool</em><em> or </em><em>'auto'</em><em>, </em><em>default=False</em>) – Whether or not to mark each sample as the first nearest neighbor to
itself. If ‘auto’, then True is used for mode=’connectivity’ and False
for mode=’distance’.</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default=None</em>) – The number of parallel jobs to run for neighbors search.
<code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a <code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context.
<code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all processors. See <span class="xref std std-term">Glossary</span>
for more details.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>A</strong> – Graph where A[i, j] is assigned the weight of edge that
connects i to j. The matrix is of CSR format.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>sparse matrix of shape (n_samples, n_samples)</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">kneighbors_graph</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">kneighbors_graph</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;connectivity&#39;</span><span class="p">,</span> <span class="n">include_self</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="go">array([[1., 0., 1.],</span>
<span class="go">       [0., 1., 1.],</span>
<span class="go">       [1., 0., 1.]])</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#sklearn.neighbors.radius_neighbors_graph" title="sklearn.neighbors.radius_neighbors_graph"><code class="xref py py-obj docutils literal notranslate"><span class="pre">radius_neighbors_graph</span></code></a></p>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sklearn.neighbors.radius_neighbors_graph">
<span class="sig-prename descclassname"><span class="pre">sklearn.neighbors.</span></span><span class="sig-name descname"><span class="pre">radius_neighbors_graph</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">radius</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'connectivity'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'minkowski'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_self</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neighbors.radius_neighbors_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the (weighted) graph of Neighbors for points in X</p>
<p>Neighborhoods are restricted the points at a distance lower than
radius.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>) or </em><a class="reference internal" href="#sklearn.neighbors.BallTree" title="sklearn.neighbors.BallTree"><em>BallTree</em></a>) – Sample data, in the form of a numpy array or a precomputed
<a class="reference internal" href="#sklearn.neighbors.BallTree" title="sklearn.neighbors.BallTree"><code class="xref py py-class docutils literal notranslate"><span class="pre">BallTree</span></code></a>.</p></li>
<li><p><strong>radius</strong> (<em>float</em>) – Radius of neighborhoods.</p></li>
<li><p><strong>mode</strong> (<em>{'connectivity'</em><em>, </em><em>'distance'}</em><em>, </em><em>default='connectivity'</em>) – Type of returned matrix: ‘connectivity’ will return the connectivity
matrix with ones and zeros, and ‘distance’ will return the distances
between neighbors according to the given metric.</p></li>
<li><p><strong>metric</strong> (<em>str</em><em>, </em><em>default='minkowski'</em>) – The distance metric used to calculate the neighbors within a
given radius for each sample point. The DistanceMetric class
gives a list of available metrics. The default distance is
‘euclidean’ (‘minkowski’ metric with the param equal to 2.)</p></li>
<li><p><strong>p</strong> (<em>int</em><em>, </em><em>default=2</em>) – Power parameter for the Minkowski metric. When p = 1, this is
equivalent to using manhattan_distance (l1), and euclidean_distance
(l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.</p></li>
<li><p><strong>metric_params</strong> (<em>dict</em><em>, </em><em>default=None</em>) – additional keyword arguments for the metric function.</p></li>
<li><p><strong>include_self</strong> (<em>bool</em><em> or </em><em>'auto'</em><em>, </em><em>default=False</em>) – Whether or not to mark each sample as the first nearest neighbor to
itself. If ‘auto’, then True is used for mode=’connectivity’ and False
for mode=’distance’.</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default=None</em>) – The number of parallel jobs to run for neighbors search.
<code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a <code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context.
<code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all processors. See <span class="xref std std-term">Glossary</span>
for more details.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>A</strong> – Graph where A[i, j] is assigned the weight of edge that connects
i to j. The matrix is of CSR format.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>sparse matrix of shape (n_samples, n_samples)</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">radius_neighbors_graph</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">radius_neighbors_graph</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;connectivity&#39;</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">include_self</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="go">array([[1., 0., 1.],</span>
<span class="go">       [0., 1., 0.],</span>
<span class="go">       [1., 0., 1.]])</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#sklearn.neighbors.kneighbors_graph" title="sklearn.neighbors.kneighbors_graph"><code class="xref py py-obj docutils literal notranslate"><span class="pre">kneighbors_graph</span></code></a></p>
</div>
</dd></dl>

</section>
</section>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, Tommaso Fioravanti

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>