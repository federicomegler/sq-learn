

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>sklearn.model_selection package &mdash; sqlearn  documentation</title>
  

  
  
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> sqlearn
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="modules.html">sqlearn</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">sqlearn</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>sklearn.model_selection package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/sklearn.model_selection.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="sklearn-model-selection-package">
<h1>sklearn.model_selection package<a class="headerlink" href="#sklearn-model-selection-package" title="Permalink to this headline">¶</a></h1>
<section id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="sklearn.model_selection.tests.html">sklearn.model_selection.tests package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="sklearn.model_selection.tests.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.model_selection.tests.html#module-sklearn.model_selection.tests.common">sklearn.model_selection.tests.common module</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.model_selection.tests.html#sklearn-model-selection-tests-test-search-module">sklearn.model_selection.tests.test_search module</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.model_selection.tests.html#sklearn-model-selection-tests-test-split-module">sklearn.model_selection.tests.test_split module</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.model_selection.tests.html#sklearn-model-selection-tests-test-successive-halving-module">sklearn.model_selection.tests.test_successive_halving module</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.model_selection.tests.html#sklearn-model-selection-tests-test-validation-module">sklearn.model_selection.tests.test_validation module</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.model_selection.tests.html#module-sklearn.model_selection.tests">Module contents</a></li>
</ul>
</li>
</ul>
</div>
</section>
<section id="module-sklearn.model_selection">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-sklearn.model_selection" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="sklearn.model_selection.BaseCrossValidator">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">BaseCrossValidator</span></span><a class="headerlink" href="#sklearn.model_selection.BaseCrossValidator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Base class for all cross-validators</p>
<p>Implementations must define <cite>_iter_test_masks</cite> or <cite>_iter_test_indices</cite>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.model_selection.BaseCrossValidator.get_n_splits">
<em class="property"><span class="pre">abstract</span> </em><span class="sig-name descname"><span class="pre">get_n_splits</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.BaseCrossValidator.get_n_splits" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the number of splitting iterations in the cross-validator</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.model_selection.BaseCrossValidator.split">
<span class="sig-name descname"><span class="pre">split</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.BaseCrossValidator.split" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate indices to split data into training and test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Training data, where n_samples is the number of samples
and n_features is the number of features.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The target variable for supervised learning problems.</p></li>
<li><p><strong>groups</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – Group labels for the samples used while splitting the dataset into
train/test set.</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>train</strong> (<em>ndarray</em>) – The training set indices for that split.</p></li>
<li><p><strong>test</strong> (<em>ndarray</em>) – The testing set indices for that split.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.model_selection.GridSearchCV">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">GridSearchCV</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">estimator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_grid</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">refit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_dispatch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'2*n_jobs'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">error_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">nan</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_train_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.GridSearchCV" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.model_selection._search.BaseSearchCV</span></code></p>
<p>Exhaustive search over specified parameter values for an estimator.</p>
<p>Important members are fit, predict.</p>
<p>GridSearchCV implements a “fit” and a “score” method.
It also implements “score_samples”, “predict”, “predict_proba”,
“decision_function”, “transform” and “inverse_transform” if they are
implemented in the estimator used.</p>
<p>The parameters of the estimator used to apply these methods are optimized
by cross-validated grid-search over a parameter grid.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>estimator object.</em>) – This is assumed to implement the scikit-learn estimator interface.
Either estimator needs to provide a <code class="docutils literal notranslate"><span class="pre">score</span></code> function,
or <code class="docutils literal notranslate"><span class="pre">scoring</span></code> must be passed.</p></li>
<li><p><strong>param_grid</strong> (<em>dict</em><em> or </em><em>list of dictionaries</em>) – Dictionary with parameters names (<cite>str</cite>) as keys and lists of
parameter settings to try as values, or a list of such
dictionaries, in which case the grids spanned by each dictionary
in the list are explored. This enables searching over any sequence
of parameter settings.</p></li>
<li><p><strong>scoring</strong> (<em>str</em><em>, </em><em>callable</em><em>, </em><em>list</em><em>, </em><em>tuple</em><em> or </em><em>dict</em><em>, </em><em>default=None</em>) – <p>Strategy to evaluate the performance of the cross-validated model on
the test set.</p>
<p>If <cite>scoring</cite> represents a single score, one can use:</p>
<ul>
<li><p>a single string (see <span class="xref std std-ref">scoring_parameter</span>);</p></li>
<li><p>a callable (see <span class="xref std std-ref">scoring</span>) that returns a single value.</p></li>
</ul>
<p>If <cite>scoring</cite> represents multiple scores, one can use:</p>
<ul>
<li><p>a list or tuple of unique strings;</p></li>
<li><p>a callable returning a dictionary where the keys are the metric
names and the values are the metric scores;</p></li>
<li><p>a dictionary with metric names as keys and callables a values.</p></li>
</ul>
<p>See <span class="xref std std-ref">multimetric_grid_search</span> for an example.</p>
</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default=None</em>) – <p>Number of jobs to run in parallel.
<code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a <code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context.
<code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all processors. See <span class="xref std std-term">Glossary</span>
for more details.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version v0.20: </span><cite>n_jobs</cite> default changed from 1 to None</p>
</div>
</p></li>
<li><p><strong>refit</strong> (<em>bool</em><em>, </em><em>str</em><em>, or </em><em>callable</em><em>, </em><em>default=True</em>) – <p>Refit an estimator using the best found parameters on the whole
dataset.</p>
<p>For multiple metric evaluation, this needs to be a <cite>str</cite> denoting the
scorer that would be used to find the best parameters for refitting
the estimator at the end.</p>
<p>Where there are considerations other than maximum score in
choosing a best estimator, <code class="docutils literal notranslate"><span class="pre">refit</span></code> can be set to a function which
returns the selected <code class="docutils literal notranslate"><span class="pre">best_index_</span></code> given <code class="docutils literal notranslate"><span class="pre">cv_results_</span></code>. In that
case, the <code class="docutils literal notranslate"><span class="pre">best_estimator_</span></code> and <code class="docutils literal notranslate"><span class="pre">best_params_</span></code> will be set
according to the returned <code class="docutils literal notranslate"><span class="pre">best_index_</span></code> while the <code class="docutils literal notranslate"><span class="pre">best_score_</span></code>
attribute will not be available.</p>
<p>The refitted estimator is made available at the <code class="docutils literal notranslate"><span class="pre">best_estimator_</span></code>
attribute and permits using <code class="docutils literal notranslate"><span class="pre">predict</span></code> directly on this
<code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> instance.</p>
<p>Also for multiple metric evaluation, the attributes <code class="docutils literal notranslate"><span class="pre">best_index_</span></code>,
<code class="docutils literal notranslate"><span class="pre">best_score_</span></code> and <code class="docutils literal notranslate"><span class="pre">best_params_</span></code> will only be available if
<code class="docutils literal notranslate"><span class="pre">refit</span></code> is set and all of them will be determined w.r.t this specific
scorer.</p>
<p>See <code class="docutils literal notranslate"><span class="pre">scoring</span></code> parameter to know more about multiple metric
evaluation.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.20: </span>Support for callable added.</p>
</div>
</p></li>
<li><p><strong>cv</strong> (<em>int</em><em>, </em><em>cross-validation generator</em><em> or </em><em>an iterable</em><em>, </em><em>default=None</em>) – <p>Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul>
<li><p>None, to use the default 5-fold cross validation,</p></li>
<li><p>integer, to specify the number of folds in a <cite>(Stratified)KFold</cite>,</p></li>
<li><p><span class="xref std std-term">CV splitter</span>,</p></li>
<li><p>An iterable yielding (train, test) splits as arrays of indices.</p></li>
</ul>
<p>For integer/None inputs, if the estimator is a classifier and <code class="docutils literal notranslate"><span class="pre">y</span></code> is
either binary or multiclass, <a class="reference internal" href="#sklearn.model_selection.StratifiedKFold" title="sklearn.model_selection.StratifiedKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">StratifiedKFold</span></code></a> is used. In all
other cases, <a class="reference internal" href="#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> is used. These splitters are instantiated
with <cite>shuffle=False</cite> so the splits will be the same across calls.</p>
<p>Refer <span class="xref std std-ref">User Guide</span> for the various
cross-validation strategies that can be used here.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.22: </span><code class="docutils literal notranslate"><span class="pre">cv</span></code> default value if None changed from 3-fold to 5-fold.</p>
</div>
</p></li>
<li><p><strong>verbose</strong> (<em>int</em>) – <p>Controls the verbosity: the higher, the more messages.</p>
<ul>
<li><p>&gt;1 : the computation time for each fold and parameter candidate is
displayed;</p></li>
<li><p>&gt;2 : the score is also displayed;</p></li>
<li><p>&gt;3 : the fold and candidate parameter indexes are also displayed
together with the starting time of the computation.</p></li>
</ul>
</p></li>
<li><p><strong>pre_dispatch</strong> (<em>int</em><em>, or </em><em>str</em><em>, </em><em>default=n_jobs</em>) – <p>Controls the number of jobs that get dispatched during parallel
execution. Reducing this number can be useful to avoid an
explosion of memory consumption when more jobs get dispatched
than CPUs can process. This parameter can be:</p>
<blockquote>
<div><ul>
<li><p>None, in which case all the jobs are immediately
created and spawned. Use this for lightweight and
fast-running jobs, to avoid delays due to on-demand
spawning of the jobs</p></li>
<li><p>An int, giving the exact number of total jobs that are
spawned</p></li>
<li><p>A str, giving an expression as a function of n_jobs,
as in ‘2*n_jobs’</p></li>
</ul>
</div></blockquote>
</p></li>
<li><p><strong>error_score</strong> (<em>'raise'</em><em> or </em><em>numeric</em><em>, </em><em>default=np.nan</em>) – Value to assign to the score if an error occurs in estimator fitting.
If set to ‘raise’, the error is raised. If a numeric value is given,
FitFailedWarning is raised. This parameter does not affect the refit
step, which will always raise the error.</p></li>
<li><p><strong>return_train_score</strong> (<em>bool</em><em>, </em><em>default=False</em>) – <p>If <code class="docutils literal notranslate"><span class="pre">False</span></code>, the <code class="docutils literal notranslate"><span class="pre">cv_results_</span></code> attribute will not include training
scores.
Computing training scores is used to get insights on how different
parameter settings impact the overfitting/underfitting trade-off.
However computing the scores on the training set can be computationally
expensive and is not strictly required to select the parameters that
yield the best generalization performance.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.19.</span></p>
</div>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.21: </span>Default value was changed from <code class="docutils literal notranslate"><span class="pre">True</span></code> to <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
</div>
</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span><span class="p">,</span> <span class="n">datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:(</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">),</span> <span class="s1">&#39;C&#39;</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">svc</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">svc</span><span class="p">,</span> <span class="n">parameters</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="go">GridSearchCV(estimator=SVC(),</span>
<span class="go">             param_grid={&#39;C&#39;: [1, 10], &#39;kernel&#39;: (&#39;linear&#39;, &#39;rbf&#39;)})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">sorted</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">cv_results_</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="go">[&#39;mean_fit_time&#39;, &#39;mean_score_time&#39;, &#39;mean_test_score&#39;,...</span>
<span class="go"> &#39;param_C&#39;, &#39;param_kernel&#39;, &#39;params&#39;,...</span>
<span class="go"> &#39;rank_test_score&#39;, &#39;split0_test_score&#39;,...</span>
<span class="go"> &#39;split2_test_score&#39;, ...</span>
<span class="go"> &#39;std_fit_time&#39;, &#39;std_score_time&#39;, &#39;std_test_score&#39;]</span>
</pre></div>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.GridSearchCV.cv_results_">
<span class="sig-name descname"><span class="pre">cv_results_</span></span><a class="headerlink" href="#sklearn.model_selection.GridSearchCV.cv_results_" title="Permalink to this definition">¶</a></dt>
<dd><p>A dict with keys as column headers and values as columns, that can be
imported into a pandas <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code>.</p>
<p>For instance the below given table</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 19%" />
<col style="width: 17%" />
<col style="width: 19%" />
<col style="width: 27%" />
<col style="width: 5%" />
<col style="width: 14%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>param_kernel</p></th>
<th class="head"><p>param_gamma</p></th>
<th class="head"><p>param_degree</p></th>
<th class="head"><p>split0_test_score</p></th>
<th class="head"><p>…</p></th>
<th class="head"><p>rank_t…</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>‘poly’</p></td>
<td><p>–</p></td>
<td><p>2</p></td>
<td><p>0.80</p></td>
<td><p>…</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-odd"><td><p>‘poly’</p></td>
<td><p>–</p></td>
<td><p>3</p></td>
<td><p>0.70</p></td>
<td><p>…</p></td>
<td><p>4</p></td>
</tr>
<tr class="row-even"><td><p>‘rbf’</p></td>
<td><p>0.1</p></td>
<td><p>–</p></td>
<td><p>0.80</p></td>
<td><p>…</p></td>
<td><p>3</p></td>
</tr>
<tr class="row-odd"><td><p>‘rbf’</p></td>
<td><p>0.2</p></td>
<td><p>–</p></td>
<td><p>0.93</p></td>
<td><p>…</p></td>
<td><p>1</p></td>
</tr>
</tbody>
</table>
<p>will be represented by a <code class="docutils literal notranslate"><span class="pre">cv_results_</span></code> dict of:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="s1">&#39;param_kernel&#39;</span><span class="p">:</span> <span class="n">masked_array</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">],</span>
                             <span class="n">mask</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span> <span class="kc">False</span> <span class="kc">False</span> <span class="kc">False</span><span class="p">]</span><span class="o">...</span><span class="p">)</span>
<span class="s1">&#39;param_gamma&#39;</span><span class="p">:</span> <span class="n">masked_array</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="o">--</span> <span class="o">--</span> <span class="mf">0.1</span> <span class="mf">0.2</span><span class="p">],</span>
                            <span class="n">mask</span> <span class="o">=</span> <span class="p">[</span> <span class="kc">True</span>  <span class="kc">True</span> <span class="kc">False</span> <span class="kc">False</span><span class="p">]</span><span class="o">...</span><span class="p">),</span>
<span class="s1">&#39;param_degree&#39;</span><span class="p">:</span> <span class="n">masked_array</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.0</span> <span class="mf">3.0</span> <span class="o">--</span> <span class="o">--</span><span class="p">],</span>
                             <span class="n">mask</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span> <span class="kc">False</span>  <span class="kc">True</span>  <span class="kc">True</span><span class="p">]</span><span class="o">...</span><span class="p">),</span>
<span class="s1">&#39;split0_test_score&#39;</span>  <span class="p">:</span> <span class="p">[</span><span class="mf">0.80</span><span class="p">,</span> <span class="mf">0.70</span><span class="p">,</span> <span class="mf">0.80</span><span class="p">,</span> <span class="mf">0.93</span><span class="p">],</span>
<span class="s1">&#39;split1_test_score&#39;</span>  <span class="p">:</span> <span class="p">[</span><span class="mf">0.82</span><span class="p">,</span> <span class="mf">0.50</span><span class="p">,</span> <span class="mf">0.70</span><span class="p">,</span> <span class="mf">0.78</span><span class="p">],</span>
<span class="s1">&#39;mean_test_score&#39;</span>    <span class="p">:</span> <span class="p">[</span><span class="mf">0.81</span><span class="p">,</span> <span class="mf">0.60</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.85</span><span class="p">],</span>
<span class="s1">&#39;std_test_score&#39;</span>     <span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.08</span><span class="p">],</span>
<span class="s1">&#39;rank_test_score&#39;</span>    <span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="s1">&#39;split0_train_score&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mf">0.80</span><span class="p">,</span> <span class="mf">0.92</span><span class="p">,</span> <span class="mf">0.70</span><span class="p">,</span> <span class="mf">0.93</span><span class="p">],</span>
<span class="s1">&#39;split1_train_score&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mf">0.82</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.70</span><span class="p">,</span> <span class="mf">0.87</span><span class="p">],</span>
<span class="s1">&#39;mean_train_score&#39;</span>   <span class="p">:</span> <span class="p">[</span><span class="mf">0.81</span><span class="p">,</span> <span class="mf">0.74</span><span class="p">,</span> <span class="mf">0.70</span><span class="p">,</span> <span class="mf">0.90</span><span class="p">],</span>
<span class="s1">&#39;std_train_score&#39;</span>    <span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.19</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">],</span>
<span class="s1">&#39;mean_fit_time&#39;</span>      <span class="p">:</span> <span class="p">[</span><span class="mf">0.73</span><span class="p">,</span> <span class="mf">0.63</span><span class="p">,</span> <span class="mf">0.43</span><span class="p">,</span> <span class="mf">0.49</span><span class="p">],</span>
<span class="s1">&#39;std_fit_time&#39;</span>       <span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">],</span>
<span class="s1">&#39;mean_score_time&#39;</span>    <span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.06</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">],</span>
<span class="s1">&#39;std_score_time&#39;</span>     <span class="p">:</span> <span class="p">[</span><span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">],</span>
<span class="s1">&#39;params&#39;</span>             <span class="p">:</span> <span class="p">[{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="s1">&#39;degree&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">},</span> <span class="o">...</span><span class="p">],</span>
<span class="p">}</span>
</pre></div>
</div>
<p>NOTE</p>
<p>The key <code class="docutils literal notranslate"><span class="pre">'params'</span></code> is used to store a list of parameter
settings dicts for all the parameter candidates.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">mean_fit_time</span></code>, <code class="docutils literal notranslate"><span class="pre">std_fit_time</span></code>, <code class="docutils literal notranslate"><span class="pre">mean_score_time</span></code> and
<code class="docutils literal notranslate"><span class="pre">std_score_time</span></code> are all in seconds.</p>
<p>For multi-metric evaluation, the scores for all the scorers are
available in the <code class="docutils literal notranslate"><span class="pre">cv_results_</span></code> dict at the keys ending with that
scorer’s name (<code class="docutils literal notranslate"><span class="pre">'_&lt;scorer_name&gt;'</span></code>) instead of <code class="docutils literal notranslate"><span class="pre">'_score'</span></code> shown
above. (‘split0_test_precision’, ‘mean_train_precision’ etc.)</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict of numpy (masked) ndarrays</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.GridSearchCV.best_estimator_">
<span class="sig-name descname"><span class="pre">best_estimator_</span></span><a class="headerlink" href="#sklearn.model_selection.GridSearchCV.best_estimator_" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimator that was chosen by the search, i.e. estimator
which gave highest score (or smallest loss if specified)
on the left out data. Not available if <code class="docutils literal notranslate"><span class="pre">refit=False</span></code>.</p>
<p>See <code class="docutils literal notranslate"><span class="pre">refit</span></code> parameter for more information on allowed values.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>estimator</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.GridSearchCV.best_score_">
<span class="sig-name descname"><span class="pre">best_score_</span></span><a class="headerlink" href="#sklearn.model_selection.GridSearchCV.best_score_" title="Permalink to this definition">¶</a></dt>
<dd><p>Mean cross-validated score of the best_estimator</p>
<p>For multi-metric evaluation, this is present only if <code class="docutils literal notranslate"><span class="pre">refit</span></code> is
specified.</p>
<p>This attribute is not available if <code class="docutils literal notranslate"><span class="pre">refit</span></code> is a function.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.GridSearchCV.best_params_">
<span class="sig-name descname"><span class="pre">best_params_</span></span><a class="headerlink" href="#sklearn.model_selection.GridSearchCV.best_params_" title="Permalink to this definition">¶</a></dt>
<dd><p>Parameter setting that gave the best results on the hold out data.</p>
<p>For multi-metric evaluation, this is present only if <code class="docutils literal notranslate"><span class="pre">refit</span></code> is
specified.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.GridSearchCV.best_index_">
<span class="sig-name descname"><span class="pre">best_index_</span></span><a class="headerlink" href="#sklearn.model_selection.GridSearchCV.best_index_" title="Permalink to this definition">¶</a></dt>
<dd><p>The index (of the <code class="docutils literal notranslate"><span class="pre">cv_results_</span></code> arrays) which corresponds to the best
candidate parameter setting.</p>
<p>The dict at <code class="docutils literal notranslate"><span class="pre">search.cv_results_['params'][search.best_index_]</span></code> gives
the parameter setting for the best model, that gives the highest
mean score (<code class="docutils literal notranslate"><span class="pre">search.best_score_</span></code>).</p>
<p>For multi-metric evaluation, this is present only if <code class="docutils literal notranslate"><span class="pre">refit</span></code> is
specified.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.GridSearchCV.scorer_">
<span class="sig-name descname"><span class="pre">scorer_</span></span><a class="headerlink" href="#sklearn.model_selection.GridSearchCV.scorer_" title="Permalink to this definition">¶</a></dt>
<dd><p>Scorer function used on the held out data to choose the best
parameters for the model.</p>
<p>For multi-metric evaluation, this attribute holds the validated
<code class="docutils literal notranslate"><span class="pre">scoring</span></code> dict which maps the scorer key to the scorer callable.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>function or a dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.GridSearchCV.n_splits_">
<span class="sig-name descname"><span class="pre">n_splits_</span></span><a class="headerlink" href="#sklearn.model_selection.GridSearchCV.n_splits_" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of cross-validation splits (folds/iterations).</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.GridSearchCV.refit_time_">
<span class="sig-name descname"><span class="pre">refit_time_</span></span><a class="headerlink" href="#sklearn.model_selection.GridSearchCV.refit_time_" title="Permalink to this definition">¶</a></dt>
<dd><p>Seconds used for refitting the best model on the whole dataset.</p>
<p>This is present only if <code class="docutils literal notranslate"><span class="pre">refit</span></code> is not False.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.20.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.GridSearchCV.multimetric_">
<span class="sig-name descname"><span class="pre">multimetric_</span></span><a class="headerlink" href="#sklearn.model_selection.GridSearchCV.multimetric_" title="Permalink to this definition">¶</a></dt>
<dd><p>Whether or not the scorers compute several metrics.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Notes</p>
<p>The parameters selected are those that maximize the score of the left out
data, unless an explicit score is passed in which case it is used instead.</p>
<p>If <cite>n_jobs</cite> was set to a value higher than one, the data is copied for each
point in the grid (and not <cite>n_jobs</cite> times). This is done for efficiency
reasons if individual jobs take very little time, but may raise errors if
the dataset is large and not enough memory is available.  A workaround in
this case is to set <cite>pre_dispatch</cite>. Then, the memory is copied only
<cite>pre_dispatch</cite> many times. A reasonable value for <cite>pre_dispatch</cite> is <cite>2 *
n_jobs</cite>.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.model_selection.ParameterGrid" title="sklearn.model_selection.ParameterGrid"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ParameterGrid</span></code></a></dt><dd><p>Generates all the combinations of a hyperparameter grid.</p>
</dd>
<dt><a class="reference internal" href="#sklearn.model_selection.train_test_split" title="sklearn.model_selection.train_test_split"><code class="xref py py-obj docutils literal notranslate"><span class="pre">train_test_split</span></code></a></dt><dd><p>Utility function to split the data into a development set usable for fitting a GridSearchCV instance and an evaluation set for its final evaluation.</p>
</dd>
<dt><a class="reference internal" href="sklearn.metrics.html#sklearn.metrics.make_scorer" title="sklearn.metrics.make_scorer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sklearn.metrics.make_scorer</span></code></a></dt><dd><p>Make a scorer from a performance metric or loss function.</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.model_selection.GroupKFold">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">GroupKFold</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_splits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.GroupKFold" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.model_selection._split._BaseKFold</span></code></p>
<p>K-fold iterator variant with non-overlapping groups.</p>
<p>The same group will not appear in two different folds (the number of
distinct groups has to be at least equal to the number of folds).</p>
<p>The folds are approximately balanced in the sense that the number of
distinct groups is approximately the same in each fold.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>n_splits</strong> (<em>int</em><em>, </em><em>default=5</em>) – <p>Number of folds. Must be at least 2.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.22: </span><code class="docutils literal notranslate"><span class="pre">n_splits</span></code> default value changed from 3 to 5.</p>
</div>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GroupKFold</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">groups</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">group_kfold</span> <span class="o">=</span> <span class="n">GroupKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">group_kfold</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">group_kfold</span><span class="p">)</span>
<span class="go">GroupKFold(n_splits=2)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">group_kfold</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TRAIN:&quot;</span><span class="p">,</span> <span class="n">train_index</span><span class="p">,</span> <span class="s2">&quot;TEST:&quot;</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="gp">... </span>    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="gp">...</span>
<span class="go">TRAIN: [0 1] TEST: [2 3]</span>
<span class="go">[[1 2]</span>
<span class="go"> [3 4]] [[5 6]</span>
<span class="go"> [7 8]] [1 2] [3 4]</span>
<span class="go">TRAIN: [2 3] TEST: [0 1]</span>
<span class="go">[[5 6]</span>
<span class="go"> [7 8]] [[1 2]</span>
<span class="go"> [3 4]] [3 4] [1 2]</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.model_selection.LeaveOneGroupOut" title="sklearn.model_selection.LeaveOneGroupOut"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LeaveOneGroupOut</span></code></a></dt><dd><p>For splitting the data according to explicit domain-specific stratification of the dataset.</p>
</dd>
</dl>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.model_selection.GroupKFold.split">
<span class="sig-name descname"><span class="pre">split</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.GroupKFold.split" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate indices to split data into training and test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Training data, where n_samples is the number of samples
and n_features is the number of features.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – The target variable for supervised learning problems.</p></li>
<li><p><strong>groups</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Group labels for the samples used while splitting the dataset into
train/test set.</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>train</strong> (<em>ndarray</em>) – The training set indices for that split.</p></li>
<li><p><strong>test</strong> (<em>ndarray</em>) – The testing set indices for that split.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.model_selection.GroupShuffleSplit">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">GroupShuffleSplit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_splits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.GroupShuffleSplit" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#sklearn.model_selection.ShuffleSplit" title="sklearn.model_selection._split.ShuffleSplit"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.model_selection._split.ShuffleSplit</span></code></a></p>
<p>Shuffle-Group(s)-Out cross-validation iterator</p>
<p>Provides randomized train/test indices to split data according to a
third-party provided group. This group information can be used to encode
arbitrary domain specific stratifications of the samples as integers.</p>
<p>For instance the groups could be the year of collection of the samples
and thus allow for cross-validation against time-based splits.</p>
<p>The difference between LeavePGroupsOut and GroupShuffleSplit is that
the former generates splits using all subsets of size <code class="docutils literal notranslate"><span class="pre">p</span></code> unique groups,
whereas GroupShuffleSplit generates a user-determined number of random
test splits, each with a user-determined fraction of unique groups.</p>
<p>For example, a less computationally intensive alternative to
<code class="docutils literal notranslate"><span class="pre">LeavePGroupsOut(p=10)</span></code> would be
<code class="docutils literal notranslate"><span class="pre">GroupShuffleSplit(test_size=10,</span> <span class="pre">n_splits=100)</span></code>.</p>
<p>Note: The parameters <code class="docutils literal notranslate"><span class="pre">test_size</span></code> and <code class="docutils literal notranslate"><span class="pre">train_size</span></code> refer to groups, and
not to samples, as in ShuffleSplit.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_splits</strong> (<em>int</em><em>, </em><em>default=5</em>) – Number of re-shuffling &amp; splitting iterations.</p></li>
<li><p><strong>test_size</strong> (<em>float</em><em>, </em><em>int</em><em>, </em><em>default=0.2</em>) – If float, should be between 0.0 and 1.0 and represent the proportion
of groups to include in the test split (rounded up). If int,
represents the absolute number of test groups. If None, the value is
set to the complement of the train size.
The default will change in version 0.21. It will remain 0.2 only
if <code class="docutils literal notranslate"><span class="pre">train_size</span></code> is unspecified, otherwise it will complement
the specified <code class="docutils literal notranslate"><span class="pre">train_size</span></code>.</p></li>
<li><p><strong>train_size</strong> (<em>float</em><em> or </em><em>int</em><em>, </em><em>default=None</em>) – If float, should be between 0.0 and 1.0 and represent the
proportion of the groups to include in the train split. If
int, represents the absolute number of train groups. If None,
the value is automatically set to the complement of the test size.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Controls the randomness of the training and testing indices produced.
Pass an int for reproducible output across multiple function calls.
See <span class="xref std std-term">Glossary</span>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GroupShuffleSplit</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">groups</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">groups</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(8,)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gss</span> <span class="o">=</span> <span class="n">GroupShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="mf">.7</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gss</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">()</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train_idx</span><span class="p">,</span> <span class="n">test_idx</span> <span class="ow">in</span> <span class="n">gss</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TRAIN:&quot;</span><span class="p">,</span> <span class="n">train_idx</span><span class="p">,</span> <span class="s2">&quot;TEST:&quot;</span><span class="p">,</span> <span class="n">test_idx</span><span class="p">)</span>
<span class="go">TRAIN: [2 3 4 5 6 7] TEST: [0 1]</span>
<span class="go">TRAIN: [0 1 5 6 7] TEST: [2 3 4]</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.model_selection.GroupShuffleSplit.split">
<span class="sig-name descname"><span class="pre">split</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.GroupShuffleSplit.split" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate indices to split data into training and test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Training data, where n_samples is the number of samples
and n_features is the number of features.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – The target variable for supervised learning problems.</p></li>
<li><p><strong>groups</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Group labels for the samples used while splitting the dataset into
train/test set.</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>train</strong> (<em>ndarray</em>) – The training set indices for that split.</p></li>
<li><p><strong>test</strong> (<em>ndarray</em>) – The testing set indices for that split.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Randomized CV splitters may return different results for each call of
split. You can make the results identical by setting <cite>random_state</cite>
to an integer.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingGridSearchCV">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">HalvingGridSearchCV</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">estimator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_grid</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resource</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'n_samples'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_resources</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_resources</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'exhaust'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggressive_elimination</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">refit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">error_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">nan</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_train_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.HalvingGridSearchCV" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.model_selection._search_successive_halving.BaseSuccessiveHalving</span></code></p>
<p>Search over specified parameter values with successive halving.</p>
<p>The search strategy starts evaluating all the candidates with a small
amount of resources and iteratively selects the best candidates, using
more and more resources.</p>
<p>Read more in the <span class="xref std std-ref">User guide</span>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This estimator is still <strong>experimental</strong> for now: the predictions
and the API might change without any deprecation cycle. To use it,
you need to explicitly import <code class="docutils literal notranslate"><span class="pre">enable_halving_search_cv</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># explicitly require this experimental feature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.experimental</span> <span class="kn">import</span> <span class="n">enable_halving_search_cv</span> <span class="c1"># noqa</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># now you can import normally from model_selection</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">HalvingGridSearchCV</span>
</pre></div>
</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>estimator object.</em>) – This is assumed to implement the scikit-learn estimator interface.
Either estimator needs to provide a <code class="docutils literal notranslate"><span class="pre">score</span></code> function,
or <code class="docutils literal notranslate"><span class="pre">scoring</span></code> must be passed.</p></li>
<li><p><strong>param_grid</strong> (<em>dict</em><em> or </em><em>list of dictionaries</em>) – Dictionary with parameters names (string) as keys and lists of
parameter settings to try as values, or a list of such
dictionaries, in which case the grids spanned by each dictionary
in the list are explored. This enables searching over any sequence
of parameter settings.</p></li>
<li><p><strong>factor</strong> (<em>int</em><em> or </em><em>float</em><em>, </em><em>default=3</em>) – The ‘halving’ parameter, which determines the proportion of candidates
that are selected for each subsequent iteration. For example,
<code class="docutils literal notranslate"><span class="pre">factor=3</span></code> means that only one third of the candidates are selected.</p></li>
<li><p><strong>resource</strong> (<code class="docutils literal notranslate"><span class="pre">'n_samples'</span></code> or str, default=’n_samples’) – Defines the resource that increases with each iteration. By default,
the resource is the number of samples. It can also be set to any
parameter of the base estimator that accepts positive integer
values, e.g. ‘n_iterations’ or ‘n_estimators’ for a gradient
boosting estimator. In this case <code class="docutils literal notranslate"><span class="pre">max_resources</span></code> cannot be ‘auto’
and must be set explicitly.</p></li>
<li><p><strong>max_resources</strong> (<em>int</em><em>, </em><em>default='auto'</em>) – The maximum amount of resource that any candidate is allowed to use
for a given iteration. By default, this is set to <code class="docutils literal notranslate"><span class="pre">n_samples</span></code> when
<code class="docutils literal notranslate"><span class="pre">resource='n_samples'</span></code> (default), else an error is raised.</p></li>
<li><p><strong>min_resources</strong> (<em>{'exhaust'</em><em>, </em><em>'smallest'}</em><em> or </em><em>int</em><em>, </em><em>default='exhaust'</em>) – <p>The minimum amount of resource that any candidate is allowed to use
for a given iteration. Equivalently, this defines the amount of
resources <cite>r0</cite> that are allocated for each candidate at the first
iteration.</p>
<ul>
<li><dl class="simple">
<dt>’smallest’ is a heuristic that sets <cite>r0</cite> to a small value:</dt><dd><ul>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">n_splits</span> <span class="pre">*</span> <span class="pre">2</span></code> when <code class="docutils literal notranslate"><span class="pre">resource='n_samples'</span></code> for a regression</dt><dd><p>problem</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">n_classes</span> <span class="pre">*</span> <span class="pre">n_splits</span> <span class="pre">*</span> <span class="pre">2</span></code> when <code class="docutils literal notranslate"><span class="pre">resource='n_samples'</span></code> for a</dt><dd><p>classification problem</p>
</dd>
</dl>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">1</span></code> when <code class="docutils literal notranslate"><span class="pre">resource</span> <span class="pre">!=</span> <span class="pre">'n_samples'</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><p>’exhaust’ will set <cite>r0</cite> such that the <strong>last</strong> iteration uses as
much resources as possible. Namely, the last iteration will use the
highest value smaller than <code class="docutils literal notranslate"><span class="pre">max_resources</span></code> that is a multiple of
both <code class="docutils literal notranslate"><span class="pre">min_resources</span></code> and <code class="docutils literal notranslate"><span class="pre">factor</span></code>. In general, using ‘exhaust’
leads to a more accurate estimator, but is slightly more time
consuming.</p></li>
</ul>
<p>Note that the amount of resources used at each iteration is always a
multiple of <code class="docutils literal notranslate"><span class="pre">min_resources</span></code>.</p>
</p></li>
<li><p><strong>aggressive_elimination</strong> (<em>bool</em><em>, </em><em>default=False</em>) – This is only relevant in cases where there isn’t enough resources to
reduce the remaining candidates to at most <cite>factor</cite> after the last
iteration. If <code class="docutils literal notranslate"><span class="pre">True</span></code>, then the search process will ‘replay’ the
first iteration for as long as needed until the number of candidates
is small enough. This is <code class="docutils literal notranslate"><span class="pre">False</span></code> by default, which means that the
last iteration may evaluate more than <code class="docutils literal notranslate"><span class="pre">factor</span></code> candidates. See
<span class="xref std std-ref">aggressive_elimination</span> for more details.</p></li>
<li><p><strong>cv</strong> (<em>int</em><em>, </em><em>cross-validation generator</em><em> or </em><em>iterable</em><em>, </em><em>default=5</em>) – <p>Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul>
<li><p>integer, to specify the number of folds in a <cite>(Stratified)KFold</cite>,</p></li>
<li><p><span class="xref std std-term">CV splitter</span>,</p></li>
<li><p>An iterable yielding (train, test) splits as arrays of indices.</p></li>
</ul>
<p>For integer/None inputs, if the estimator is a classifier and <code class="docutils literal notranslate"><span class="pre">y</span></code> is
either binary or multiclass, <a class="reference internal" href="#sklearn.model_selection.StratifiedKFold" title="sklearn.model_selection.StratifiedKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">StratifiedKFold</span></code></a> is used. In all
other cases, <a class="reference internal" href="#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> is used. These splitters are instantiated
with <cite>shuffle=False</cite> so the splits will be the same across calls.</p>
<p>Refer <span class="xref std std-ref">User Guide</span> for the various
cross-validation strategies that can be used here.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Due to implementation details, the folds produced by <cite>cv</cite> must be
the same across multiple calls to <cite>cv.split()</cite>. For
built-in <cite>scikit-learn</cite> iterators, this can be achieved by
deactivating shuffling (<cite>shuffle=False</cite>), or by setting the
<cite>cv</cite>’s <cite>random_state</cite> parameter to an integer.</p>
</div>
</p></li>
<li><p><strong>scoring</strong> (<em>string</em><em>, </em><em>callable</em><em>, or </em><em>None</em><em>, </em><em>default=None</em>) – A single string (see <span class="xref std std-ref">scoring_parameter</span>) or a callable
(see <span class="xref std std-ref">scoring</span>) to evaluate the predictions on the test set.
If None, the estimator’s score method is used.</p></li>
<li><p><strong>refit</strong> (<em>bool</em><em>, </em><em>default=True</em>) – <p>If True, refit an estimator using the best found parameters on the
whole dataset.</p>
<p>The refitted estimator is made available at the <code class="docutils literal notranslate"><span class="pre">best_estimator_</span></code>
attribute and permits using <code class="docutils literal notranslate"><span class="pre">predict</span></code> directly on this
<code class="docutils literal notranslate"><span class="pre">HalvingGridSearchCV</span></code> instance.</p>
</p></li>
<li><p><strong>error_score</strong> (<em>'raise'</em><em> or </em><em>numeric</em>) – Value to assign to the score if an error occurs in estimator fitting.
If set to ‘raise’, the error is raised. If a numeric value is given,
FitFailedWarning is raised. This parameter does not affect the refit
step, which will always raise the error. Default is <code class="docutils literal notranslate"><span class="pre">np.nan</span></code></p></li>
<li><p><strong>return_train_score</strong> (<em>bool</em><em>, </em><em>default=False</em>) – If <code class="docutils literal notranslate"><span class="pre">False</span></code>, the <code class="docutils literal notranslate"><span class="pre">cv_results_</span></code> attribute will not include training
scores.
Computing training scores is used to get insights on how different
parameter settings impact the overfitting/underfitting trade-off.
However computing the scores on the training set can be computationally
expensive and is not strictly required to select the parameters that
yield the best generalization performance.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Pseudo random number generator state used for subsampling the dataset
when <cite>resources != ‘n_samples’</cite>. Ignored otherwise.
Pass an int for reproducible output across multiple function calls.
See <span class="xref std std-term">Glossary</span>.</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Number of jobs to run in parallel.
<code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a <code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context.
<code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all processors. See <span class="xref std std-term">Glossary</span>
for more details.</p></li>
<li><p><strong>verbose</strong> (<em>int</em>) – Controls the verbosity: the higher, the more messages.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingGridSearchCV.n_resources_">
<span class="sig-name descname"><span class="pre">n_resources_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingGridSearchCV.n_resources_" title="Permalink to this definition">¶</a></dt>
<dd><p>The amount of resources used at each iteration.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>list of int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingGridSearchCV.n_candidates_">
<span class="sig-name descname"><span class="pre">n_candidates_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingGridSearchCV.n_candidates_" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of candidate parameters that were evaluated at each
iteration.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>list of int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingGridSearchCV.n_remaining_candidates_">
<span class="sig-name descname"><span class="pre">n_remaining_candidates_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingGridSearchCV.n_remaining_candidates_" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of candidate parameters that are left after the last
iteration. It corresponds to <cite>ceil(n_candidates[-1] / factor)</cite></p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingGridSearchCV.max_resources_">
<span class="sig-name descname"><span class="pre">max_resources_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingGridSearchCV.max_resources_" title="Permalink to this definition">¶</a></dt>
<dd><p>The maximum number of resources that any candidate is allowed to use
for a given iteration. Note that since the number of resources used
at each iteration must be a multiple of <code class="docutils literal notranslate"><span class="pre">min_resources_</span></code>, the
actual number of resources used at the last iteration may be smaller
than <code class="docutils literal notranslate"><span class="pre">max_resources_</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingGridSearchCV.min_resources_">
<span class="sig-name descname"><span class="pre">min_resources_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingGridSearchCV.min_resources_" title="Permalink to this definition">¶</a></dt>
<dd><p>The amount of resources that are allocated for each candidate at the
first iteration.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingGridSearchCV.n_iterations_">
<span class="sig-name descname"><span class="pre">n_iterations_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingGridSearchCV.n_iterations_" title="Permalink to this definition">¶</a></dt>
<dd><p>The actual number of iterations that were run. This is equal to
<code class="docutils literal notranslate"><span class="pre">n_required_iterations_</span></code> if <code class="docutils literal notranslate"><span class="pre">aggressive_elimination</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>.
Else, this is equal to <code class="docutils literal notranslate"><span class="pre">min(n_possible_iterations_,</span>
<span class="pre">n_required_iterations_)</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingGridSearchCV.n_possible_iterations_">
<span class="sig-name descname"><span class="pre">n_possible_iterations_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingGridSearchCV.n_possible_iterations_" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of iterations that are possible starting with
<code class="docutils literal notranslate"><span class="pre">min_resources_</span></code> resources and without exceeding
<code class="docutils literal notranslate"><span class="pre">max_resources_</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingGridSearchCV.n_required_iterations_">
<span class="sig-name descname"><span class="pre">n_required_iterations_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingGridSearchCV.n_required_iterations_" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of iterations that are required to end up with less than
<code class="docutils literal notranslate"><span class="pre">factor</span></code> candidates at the last iteration, starting with
<code class="docutils literal notranslate"><span class="pre">min_resources_</span></code> resources. This will be smaller than
<code class="docutils literal notranslate"><span class="pre">n_possible_iterations_</span></code> when there isn’t enough resources.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingGridSearchCV.cv_results_">
<span class="sig-name descname"><span class="pre">cv_results_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingGridSearchCV.cv_results_" title="Permalink to this definition">¶</a></dt>
<dd><p>A dict with keys as column headers and values as columns, that can be
imported into a pandas <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code>. It contains many informations for
analysing the results of a search.
Please refer to the <span class="xref std std-ref">User guide</span>
for details.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict of numpy (masked) ndarrays</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingGridSearchCV.best_estimator_">
<span class="sig-name descname"><span class="pre">best_estimator_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingGridSearchCV.best_estimator_" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimator that was chosen by the search, i.e. estimator
which gave highest score (or smallest loss if specified)
on the left out data. Not available if <code class="docutils literal notranslate"><span class="pre">refit=False</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>estimator or dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingGridSearchCV.best_score_">
<span class="sig-name descname"><span class="pre">best_score_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingGridSearchCV.best_score_" title="Permalink to this definition">¶</a></dt>
<dd><p>Mean cross-validated score of the best_estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingGridSearchCV.best_params_">
<span class="sig-name descname"><span class="pre">best_params_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingGridSearchCV.best_params_" title="Permalink to this definition">¶</a></dt>
<dd><p>Parameter setting that gave the best results on the hold out data.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingGridSearchCV.best_index_">
<span class="sig-name descname"><span class="pre">best_index_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingGridSearchCV.best_index_" title="Permalink to this definition">¶</a></dt>
<dd><p>The index (of the <code class="docutils literal notranslate"><span class="pre">cv_results_</span></code> arrays) which corresponds to the best
candidate parameter setting.</p>
<p>The dict at <code class="docutils literal notranslate"><span class="pre">search.cv_results_['params'][search.best_index_]</span></code> gives
the parameter setting for the best model, that gives the highest
mean score (<code class="docutils literal notranslate"><span class="pre">search.best_score_</span></code>).</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingGridSearchCV.scorer_">
<span class="sig-name descname"><span class="pre">scorer_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingGridSearchCV.scorer_" title="Permalink to this definition">¶</a></dt>
<dd><p>Scorer function used on the held out data to choose the best
parameters for the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>function or a dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingGridSearchCV.n_splits_">
<span class="sig-name descname"><span class="pre">n_splits_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingGridSearchCV.n_splits_" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of cross-validation splits (folds/iterations).</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingGridSearchCV.refit_time_">
<span class="sig-name descname"><span class="pre">refit_time_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingGridSearchCV.refit_time_" title="Permalink to this definition">¶</a></dt>
<dd><p>Seconds used for refitting the best model on the whole dataset.</p>
<p>This is present only if <code class="docutils literal notranslate"><span class="pre">refit</span></code> is not False.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.model_selection.HalvingRandomSearchCV" title="sklearn.model_selection.HalvingRandomSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">HalvingRandomSearchCV</span></code></a></dt><dd><p>Random search over a set of parameters using successive halving.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>The parameters selected are those that maximize the score of the held-out
data, according to the scoring parameter.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.experimental</span> <span class="kn">import</span> <span class="n">enable_halving_search_cv</span>  <span class="c1"># noqa</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">HalvingGridSearchCV</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
<span class="gp">... </span>              <span class="s2">&quot;min_samples_split&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">search</span> <span class="o">=</span> <span class="n">HalvingGridSearchCV</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">resource</span><span class="o">=</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">,</span>
<span class="gp">... </span>                             <span class="n">max_resources</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>                             <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">search</span><span class="o">.</span><span class="n">best_params_</span>  
<span class="go">{&#39;max_depth&#39;: None, &#39;min_samples_split&#39;: 10, &#39;n_estimators&#39;: 9}</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingRandomSearchCV">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">HalvingRandomSearchCV</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">estimator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_distributions</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_candidates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'exhaust'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resource</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'n_samples'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_resources</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_resources</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'smallest'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggressive_elimination</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">refit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">error_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">nan</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_train_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.HalvingRandomSearchCV" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.model_selection._search_successive_halving.BaseSuccessiveHalving</span></code></p>
<p>Randomized search on hyper parameters.</p>
<p>The search strategy starts evaluating all the candidates with a small
amount of resources and iteratively selects the best candidates, using more
and more resources.</p>
<p>The candidates are sampled at random from the parameter space and the
number of sampled candidates is determined by <code class="docutils literal notranslate"><span class="pre">n_candidates</span></code>.</p>
<p>Read more in the <span class="xref std std-ref">User guide</span>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This estimator is still <strong>experimental</strong> for now: the predictions
and the API might change without any deprecation cycle. To use it,
you need to explicitly import <code class="docutils literal notranslate"><span class="pre">enable_halving_search_cv</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># explicitly require this experimental feature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.experimental</span> <span class="kn">import</span> <span class="n">enable_halving_search_cv</span> <span class="c1"># noqa</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># now you can import normally from model_selection</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">HalvingRandomSearchCV</span>
</pre></div>
</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>estimator object.</em>) – This is assumed to implement the scikit-learn estimator interface.
Either estimator needs to provide a <code class="docutils literal notranslate"><span class="pre">score</span></code> function,
or <code class="docutils literal notranslate"><span class="pre">scoring</span></code> must be passed.</p></li>
<li><p><strong>param_distributions</strong> (<em>dict</em>) – Dictionary with parameters names (string) as keys and distributions
or lists of parameters to try. Distributions must provide a <code class="docutils literal notranslate"><span class="pre">rvs</span></code>
method for sampling (such as those from scipy.stats.distributions).
If a list is given, it is sampled uniformly.</p></li>
<li><p><strong>n_candidates</strong> (<em>int</em><em>, </em><em>default='exhaust'</em>) – The number of candidate parameters to sample, at the first
iteration. Using ‘exhaust’ will sample enough candidates so that the
last iteration uses as many resources as possible, based on
<cite>min_resources</cite>, <cite>max_resources</cite> and <cite>factor</cite>. In this case,
<cite>min_resources</cite> cannot be ‘exhaust’.</p></li>
<li><p><strong>factor</strong> (<em>int</em><em> or </em><em>float</em><em>, </em><em>default=3</em>) – The ‘halving’ parameter, which determines the proportion of candidates
that are selected for each subsequent iteration. For example,
<code class="docutils literal notranslate"><span class="pre">factor=3</span></code> means that only one third of the candidates are selected.</p></li>
<li><p><strong>resource</strong> (<code class="docutils literal notranslate"><span class="pre">'n_samples'</span></code> or str, default=’n_samples’) – Defines the resource that increases with each iteration. By default,
the resource is the number of samples. It can also be set to any
parameter of the base estimator that accepts positive integer
values, e.g. ‘n_iterations’ or ‘n_estimators’ for a gradient
boosting estimator. In this case <code class="docutils literal notranslate"><span class="pre">max_resources</span></code> cannot be ‘auto’
and must be set explicitly.</p></li>
<li><p><strong>max_resources</strong> (<em>int</em><em>, </em><em>default='auto'</em>) – The maximum number of resources that any candidate is allowed to use
for a given iteration. By default, this is set <code class="docutils literal notranslate"><span class="pre">n_samples</span></code> when
<code class="docutils literal notranslate"><span class="pre">resource='n_samples'</span></code> (default), else an error is raised.</p></li>
<li><p><strong>min_resources</strong> (<em>{'exhaust'</em><em>, </em><em>'smallest'}</em><em> or </em><em>int</em><em>, </em><em>default='smallest'</em>) – <p>The minimum amount of resource that any candidate is allowed to use
for a given iteration. Equivalently, this defines the amount of
resources <cite>r0</cite> that are allocated for each candidate at the first
iteration.</p>
<ul>
<li><dl class="simple">
<dt>’smallest’ is a heuristic that sets <cite>r0</cite> to a small value:</dt><dd><ul>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">n_splits</span> <span class="pre">*</span> <span class="pre">2</span></code> when <code class="docutils literal notranslate"><span class="pre">resource='n_samples'</span></code> for a regression</dt><dd><p>problem</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">n_classes</span> <span class="pre">*</span> <span class="pre">n_splits</span> <span class="pre">*</span> <span class="pre">2</span></code> when <code class="docutils literal notranslate"><span class="pre">resource='n_samples'</span></code> for a</dt><dd><p>classification problem</p>
</dd>
</dl>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">1</span></code> when <code class="docutils literal notranslate"><span class="pre">resource</span> <span class="pre">!=</span> <span class="pre">'n_samples'</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><p>’exhaust’ will set <cite>r0</cite> such that the <strong>last</strong> iteration uses as
much resources as possible. Namely, the last iteration will use the
highest value smaller than <code class="docutils literal notranslate"><span class="pre">max_resources</span></code> that is a multiple of
both <code class="docutils literal notranslate"><span class="pre">min_resources</span></code> and <code class="docutils literal notranslate"><span class="pre">factor</span></code>. In general, using ‘exhaust’
leads to a more accurate estimator, but is slightly more time
consuming. ‘exhaust’ isn’t available when <cite>n_candidates=’exhaust’</cite>.</p></li>
</ul>
<p>Note that the amount of resources used at each iteration is always a
multiple of <code class="docutils literal notranslate"><span class="pre">min_resources</span></code>.</p>
</p></li>
<li><p><strong>aggressive_elimination</strong> (<em>bool</em><em>, </em><em>default=False</em>) – This is only relevant in cases where there isn’t enough resources to
reduce the remaining candidates to at most <cite>factor</cite> after the last
iteration. If <code class="docutils literal notranslate"><span class="pre">True</span></code>, then the search process will ‘replay’ the
first iteration for as long as needed until the number of candidates
is small enough. This is <code class="docutils literal notranslate"><span class="pre">False</span></code> by default, which means that the
last iteration may evaluate more than <code class="docutils literal notranslate"><span class="pre">factor</span></code> candidates. See
<span class="xref std std-ref">aggressive_elimination</span> for more details.</p></li>
<li><p><strong>cv</strong> (<em>int</em><em>, </em><em>cross-validation generator</em><em> or </em><em>an iterable</em><em>, </em><em>default=5</em>) – <p>Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul>
<li><p>integer, to specify the number of folds in a <cite>(Stratified)KFold</cite>,</p></li>
<li><p><span class="xref std std-term">CV splitter</span>,</p></li>
<li><p>An iterable yielding (train, test) splits as arrays of indices.</p></li>
</ul>
<p>For integer/None inputs, if the estimator is a classifier and <code class="docutils literal notranslate"><span class="pre">y</span></code> is
either binary or multiclass, <a class="reference internal" href="#sklearn.model_selection.StratifiedKFold" title="sklearn.model_selection.StratifiedKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">StratifiedKFold</span></code></a> is used. In all
other cases, <a class="reference internal" href="#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> is used. These splitters are instantiated
with <cite>shuffle=False</cite> so the splits will be the same across calls.</p>
<p>Refer <span class="xref std std-ref">User Guide</span> for the various
cross-validation strategies that can be used here.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Due to implementation details, the folds produced by <cite>cv</cite> must be
the same across multiple calls to <cite>cv.split()</cite>. For
built-in <cite>scikit-learn</cite> iterators, this can be achieved by
deactivating shuffling (<cite>shuffle=False</cite>), or by setting the
<cite>cv</cite>’s <cite>random_state</cite> parameter to an integer.</p>
</div>
</p></li>
<li><p><strong>scoring</strong> (<em>string</em><em>, </em><em>callable</em><em>, or </em><em>None</em><em>, </em><em>default=None</em>) – A single string (see <span class="xref std std-ref">scoring_parameter</span>) or a callable
(see <span class="xref std std-ref">scoring</span>) to evaluate the predictions on the test set.
If None, the estimator’s score method is used.</p></li>
<li><p><strong>refit</strong> (<em>bool</em><em>, </em><em>default=True</em>) – <p>If True, refit an estimator using the best found parameters on the
whole dataset.</p>
<p>The refitted estimator is made available at the <code class="docutils literal notranslate"><span class="pre">best_estimator_</span></code>
attribute and permits using <code class="docutils literal notranslate"><span class="pre">predict</span></code> directly on this
<code class="docutils literal notranslate"><span class="pre">HalvingRandomSearchCV</span></code> instance.</p>
</p></li>
<li><p><strong>error_score</strong> (<em>'raise'</em><em> or </em><em>numeric</em>) – Value to assign to the score if an error occurs in estimator fitting.
If set to ‘raise’, the error is raised. If a numeric value is given,
FitFailedWarning is raised. This parameter does not affect the refit
step, which will always raise the error. Default is <code class="docutils literal notranslate"><span class="pre">np.nan</span></code></p></li>
<li><p><strong>return_train_score</strong> (<em>bool</em><em>, </em><em>default=False</em>) – If <code class="docutils literal notranslate"><span class="pre">False</span></code>, the <code class="docutils literal notranslate"><span class="pre">cv_results_</span></code> attribute will not include training
scores.
Computing training scores is used to get insights on how different
parameter settings impact the overfitting/underfitting trade-off.
However computing the scores on the training set can be computationally
expensive and is not strictly required to select the parameters that
yield the best generalization performance.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Pseudo random number generator state used for subsampling the dataset
when <cite>resources != ‘n_samples’</cite>. Also used for random uniform
sampling from lists of possible values instead of scipy.stats
distributions.
Pass an int for reproducible output across multiple function calls.
See <span class="xref std std-term">Glossary</span>.</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Number of jobs to run in parallel.
<code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a <code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context.
<code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all processors. See <span class="xref std std-term">Glossary</span>
for more details.</p></li>
<li><p><strong>verbose</strong> (<em>int</em>) – Controls the verbosity: the higher, the more messages.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingRandomSearchCV.n_resources_">
<span class="sig-name descname"><span class="pre">n_resources_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingRandomSearchCV.n_resources_" title="Permalink to this definition">¶</a></dt>
<dd><p>The amount of resources used at each iteration.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>list of int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingRandomSearchCV.n_candidates_">
<span class="sig-name descname"><span class="pre">n_candidates_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingRandomSearchCV.n_candidates_" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of candidate parameters that were evaluated at each
iteration.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>list of int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingRandomSearchCV.n_remaining_candidates_">
<span class="sig-name descname"><span class="pre">n_remaining_candidates_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingRandomSearchCV.n_remaining_candidates_" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of candidate parameters that are left after the last
iteration. It corresponds to <cite>ceil(n_candidates[-1] / factor)</cite></p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingRandomSearchCV.max_resources_">
<span class="sig-name descname"><span class="pre">max_resources_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingRandomSearchCV.max_resources_" title="Permalink to this definition">¶</a></dt>
<dd><p>The maximum number of resources that any candidate is allowed to use
for a given iteration. Note that since the number of resources used at
each iteration must be a multiple of <code class="docutils literal notranslate"><span class="pre">min_resources_</span></code>, the actual
number of resources used at the last iteration may be smaller than
<code class="docutils literal notranslate"><span class="pre">max_resources_</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingRandomSearchCV.min_resources_">
<span class="sig-name descname"><span class="pre">min_resources_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingRandomSearchCV.min_resources_" title="Permalink to this definition">¶</a></dt>
<dd><p>The amount of resources that are allocated for each candidate at the
first iteration.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingRandomSearchCV.n_iterations_">
<span class="sig-name descname"><span class="pre">n_iterations_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingRandomSearchCV.n_iterations_" title="Permalink to this definition">¶</a></dt>
<dd><p>The actual number of iterations that were run. This is equal to
<code class="docutils literal notranslate"><span class="pre">n_required_iterations_</span></code> if <code class="docutils literal notranslate"><span class="pre">aggressive_elimination</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>.
Else, this is equal to <code class="docutils literal notranslate"><span class="pre">min(n_possible_iterations_,</span>
<span class="pre">n_required_iterations_)</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingRandomSearchCV.n_possible_iterations_">
<span class="sig-name descname"><span class="pre">n_possible_iterations_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingRandomSearchCV.n_possible_iterations_" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of iterations that are possible starting with
<code class="docutils literal notranslate"><span class="pre">min_resources_</span></code> resources and without exceeding
<code class="docutils literal notranslate"><span class="pre">max_resources_</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingRandomSearchCV.n_required_iterations_">
<span class="sig-name descname"><span class="pre">n_required_iterations_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingRandomSearchCV.n_required_iterations_" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of iterations that are required to end up with less than
<code class="docutils literal notranslate"><span class="pre">factor</span></code> candidates at the last iteration, starting with
<code class="docutils literal notranslate"><span class="pre">min_resources_</span></code> resources. This will be smaller than
<code class="docutils literal notranslate"><span class="pre">n_possible_iterations_</span></code> when there isn’t enough resources.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingRandomSearchCV.cv_results_">
<span class="sig-name descname"><span class="pre">cv_results_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingRandomSearchCV.cv_results_" title="Permalink to this definition">¶</a></dt>
<dd><p>A dict with keys as column headers and values as columns, that can be
imported into a pandas <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code>. It contains many informations for
analysing the results of a search.
Please refer to the <span class="xref std std-ref">User guide</span>
for details.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict of numpy (masked) ndarrays</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingRandomSearchCV.best_estimator_">
<span class="sig-name descname"><span class="pre">best_estimator_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingRandomSearchCV.best_estimator_" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimator that was chosen by the search, i.e. estimator
which gave highest score (or smallest loss if specified)
on the left out data. Not available if <code class="docutils literal notranslate"><span class="pre">refit=False</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>estimator or dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingRandomSearchCV.best_score_">
<span class="sig-name descname"><span class="pre">best_score_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingRandomSearchCV.best_score_" title="Permalink to this definition">¶</a></dt>
<dd><p>Mean cross-validated score of the best_estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingRandomSearchCV.best_params_">
<span class="sig-name descname"><span class="pre">best_params_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingRandomSearchCV.best_params_" title="Permalink to this definition">¶</a></dt>
<dd><p>Parameter setting that gave the best results on the hold out data.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingRandomSearchCV.best_index_">
<span class="sig-name descname"><span class="pre">best_index_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingRandomSearchCV.best_index_" title="Permalink to this definition">¶</a></dt>
<dd><p>The index (of the <code class="docutils literal notranslate"><span class="pre">cv_results_</span></code> arrays) which corresponds to the best
candidate parameter setting.</p>
<p>The dict at <code class="docutils literal notranslate"><span class="pre">search.cv_results_['params'][search.best_index_]</span></code> gives
the parameter setting for the best model, that gives the highest
mean score (<code class="docutils literal notranslate"><span class="pre">search.best_score_</span></code>).</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingRandomSearchCV.scorer_">
<span class="sig-name descname"><span class="pre">scorer_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingRandomSearchCV.scorer_" title="Permalink to this definition">¶</a></dt>
<dd><p>Scorer function used on the held out data to choose the best
parameters for the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>function or a dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingRandomSearchCV.n_splits_">
<span class="sig-name descname"><span class="pre">n_splits_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingRandomSearchCV.n_splits_" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of cross-validation splits (folds/iterations).</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.HalvingRandomSearchCV.refit_time_">
<span class="sig-name descname"><span class="pre">refit_time_</span></span><a class="headerlink" href="#sklearn.model_selection.HalvingRandomSearchCV.refit_time_" title="Permalink to this definition">¶</a></dt>
<dd><p>Seconds used for refitting the best model on the whole dataset.</p>
<p>This is present only if <code class="docutils literal notranslate"><span class="pre">refit</span></code> is not False.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.model_selection.HalvingGridSearchCV" title="sklearn.model_selection.HalvingGridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">HalvingGridSearchCV</span></code></a></dt><dd><p>Search over a grid of parameters using successive halving.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>The parameters selected are those that maximize the score of the held-out
data, according to the scoring parameter.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.experimental</span> <span class="kn">import</span> <span class="n">enable_halving_search_cv</span>  <span class="c1"># noqa</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">HalvingRandomSearchCV</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">randint</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_distributions</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
<span class="gp">... </span>                       <span class="s2">&quot;min_samples_split&quot;</span><span class="p">:</span> <span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">11</span><span class="p">)}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">search</span> <span class="o">=</span> <span class="n">HalvingRandomSearchCV</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">param_distributions</span><span class="p">,</span>
<span class="gp">... </span>                               <span class="n">resource</span><span class="o">=</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">,</span>
<span class="gp">... </span>                               <span class="n">max_resources</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>                               <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">search</span><span class="o">.</span><span class="n">best_params_</span>  
<span class="go">{&#39;max_depth&#39;: None, &#39;min_samples_split&#39;: 10, &#39;n_estimators&#39;: 9}</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.model_selection.KFold">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">KFold</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_splits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.KFold" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.model_selection._split._BaseKFold</span></code></p>
<p>K-Folds cross-validator</p>
<p>Provides train/test indices to split data in train/test sets. Split
dataset into k consecutive folds (without shuffling by default).</p>
<p>Each fold is then used once as a validation while the k - 1 remaining
folds form the training set.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_splits</strong> (<em>int</em><em>, </em><em>default=5</em>) – <p>Number of folds. Must be at least 2.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.22: </span><code class="docutils literal notranslate"><span class="pre">n_splits</span></code> default value changed from 3 to 5.</p>
</div>
</p></li>
<li><p><strong>shuffle</strong> (<em>bool</em><em>, </em><em>default=False</em>) – Whether to shuffle the data before splitting into batches.
Note that the samples within each split will not be shuffled.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – When <cite>shuffle</cite> is True, <cite>random_state</cite> affects the ordering of the
indices, which controls the randomness of each fold. Otherwise, this
parameter has no effect.
Pass an int for reproducible output across multiple function calls.
See <span class="xref std std-term">Glossary</span>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kf</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">kf</span><span class="p">)</span>
<span class="go">KFold(n_splits=2, random_state=None, shuffle=False)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TRAIN:&quot;</span><span class="p">,</span> <span class="n">train_index</span><span class="p">,</span> <span class="s2">&quot;TEST:&quot;</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="gp">... </span>    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="go">TRAIN: [2 3] TEST: [0 1]</span>
<span class="go">TRAIN: [0 1] TEST: [2 3]</span>
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>The first <code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">%</span> <span class="pre">n_splits</span></code> folds have size
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">//</span> <span class="pre">n_splits</span> <span class="pre">+</span> <span class="pre">1</span></code>, other folds have size
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">//</span> <span class="pre">n_splits</span></code>, where <code class="docutils literal notranslate"><span class="pre">n_samples</span></code> is the number of samples.</p>
<p>Randomized CV splitters may return different results for each call of
split. You can make the results identical by setting <cite>random_state</cite>
to an integer.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.model_selection.StratifiedKFold" title="sklearn.model_selection.StratifiedKFold"><code class="xref py py-obj docutils literal notranslate"><span class="pre">StratifiedKFold</span></code></a></dt><dd><p>Takes group information into account to avoid building folds with imbalanced class distributions (for binary or multiclass classification tasks).</p>
</dd>
<dt><a class="reference internal" href="#sklearn.model_selection.GroupKFold" title="sklearn.model_selection.GroupKFold"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GroupKFold</span></code></a></dt><dd><p>K-fold iterator variant with non-overlapping groups.</p>
</dd>
<dt><a class="reference internal" href="#sklearn.model_selection.RepeatedKFold" title="sklearn.model_selection.RepeatedKFold"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RepeatedKFold</span></code></a></dt><dd><p>Repeats K-Fold n times.</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.model_selection.LeaveOneGroupOut">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">LeaveOneGroupOut</span></span><a class="headerlink" href="#sklearn.model_selection.LeaveOneGroupOut" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#sklearn.model_selection.BaseCrossValidator" title="sklearn.model_selection._split.BaseCrossValidator"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.model_selection._split.BaseCrossValidator</span></code></a></p>
<p>Leave One Group Out cross-validator</p>
<p>Provides train/test indices to split data according to a third-party
provided group. This group information can be used to encode arbitrary
domain specific stratifications of the samples as integers.</p>
<p>For instance the groups could be the year of collection of the samples
and thus allow for cross-validation against time-based splits.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">LeaveOneGroupOut</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">groups</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logo</span> <span class="o">=</span> <span class="n">LeaveOneGroupOut</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logo</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logo</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">(</span><span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">)</span>  <span class="c1"># &#39;groups&#39; is always required</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">logo</span><span class="p">)</span>
<span class="go">LeaveOneGroupOut()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">logo</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TRAIN:&quot;</span><span class="p">,</span> <span class="n">train_index</span><span class="p">,</span> <span class="s2">&quot;TEST:&quot;</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="gp">... </span>    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="go">TRAIN: [2 3] TEST: [0 1]</span>
<span class="go">[[5 6]</span>
<span class="go"> [7 8]] [[1 2]</span>
<span class="go"> [3 4]] [1 2] [1 2]</span>
<span class="go">TRAIN: [0 1] TEST: [2 3]</span>
<span class="go">[[1 2]</span>
<span class="go"> [3 4]] [[5 6]</span>
<span class="go"> [7 8]] [1 2] [1 2]</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.model_selection.LeaveOneGroupOut.get_n_splits">
<span class="sig-name descname"><span class="pre">get_n_splits</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.LeaveOneGroupOut.get_n_splits" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the number of splitting iterations in the cross-validator</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>object</em>) – Always ignored, exists for compatibility.</p></li>
<li><p><strong>y</strong> (<em>object</em>) – Always ignored, exists for compatibility.</p></li>
<li><p><strong>groups</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Group labels for the samples used while splitting the dataset into
train/test set. This ‘groups’ parameter must always be specified to
calculate the number of splits, though the other parameters can be
omitted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>n_splits</strong> – Returns the number of splitting iterations in the cross-validator.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.model_selection.LeaveOneGroupOut.split">
<span class="sig-name descname"><span class="pre">split</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.LeaveOneGroupOut.split" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate indices to split data into training and test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Training data, where n_samples is the number of samples
and n_features is the number of features.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – The target variable for supervised learning problems.</p></li>
<li><p><strong>groups</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Group labels for the samples used while splitting the dataset into
train/test set.</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>train</strong> (<em>ndarray</em>) – The training set indices for that split.</p></li>
<li><p><strong>test</strong> (<em>ndarray</em>) – The testing set indices for that split.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.model_selection.LeaveOneOut">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">LeaveOneOut</span></span><a class="headerlink" href="#sklearn.model_selection.LeaveOneOut" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#sklearn.model_selection.BaseCrossValidator" title="sklearn.model_selection._split.BaseCrossValidator"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.model_selection._split.BaseCrossValidator</span></code></a></p>
<p>Leave-One-Out cross-validator</p>
<p>Provides train/test indices to split data in train/test sets. Each
sample is used once as a test set (singleton) while the remaining
samples form the training set.</p>
<p>Note: <code class="docutils literal notranslate"><span class="pre">LeaveOneOut()</span></code> is equivalent to <code class="docutils literal notranslate"><span class="pre">KFold(n_splits=n)</span></code> and
<code class="docutils literal notranslate"><span class="pre">LeavePOut(p=1)</span></code> where <code class="docutils literal notranslate"><span class="pre">n</span></code> is the number of samples.</p>
<p>Due to the high number of test sets (which is the same as the
number of samples) this cross-validation method can be very costly.
For large datasets one should favor <a class="reference internal" href="#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a>, <a class="reference internal" href="#sklearn.model_selection.ShuffleSplit" title="sklearn.model_selection.ShuffleSplit"><code class="xref py py-class docutils literal notranslate"><span class="pre">ShuffleSplit</span></code></a>
or <a class="reference internal" href="#sklearn.model_selection.StratifiedKFold" title="sklearn.model_selection.StratifiedKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">StratifiedKFold</span></code></a>.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">LeaveOneOut</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loo</span> <span class="o">=</span> <span class="n">LeaveOneOut</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loo</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">loo</span><span class="p">)</span>
<span class="go">LeaveOneOut()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">loo</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TRAIN:&quot;</span><span class="p">,</span> <span class="n">train_index</span><span class="p">,</span> <span class="s2">&quot;TEST:&quot;</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="gp">... </span>    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="go">TRAIN: [1] TEST: [0]</span>
<span class="go">[[3 4]] [[1 2]] [2] [1]</span>
<span class="go">TRAIN: [0] TEST: [1]</span>
<span class="go">[[1 2]] [[3 4]] [1] [2]</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.model_selection.LeaveOneGroupOut" title="sklearn.model_selection.LeaveOneGroupOut"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LeaveOneGroupOut</span></code></a></dt><dd><p>For splitting the data according to explicit, domain-specific stratification of the dataset.</p>
</dd>
<dt><a class="reference internal" href="#sklearn.model_selection.GroupKFold" title="sklearn.model_selection.GroupKFold"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GroupKFold</span></code></a></dt><dd><p>K-fold iterator variant with non-overlapping groups.</p>
</dd>
</dl>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.model_selection.LeaveOneOut.get_n_splits">
<span class="sig-name descname"><span class="pre">get_n_splits</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.LeaveOneOut.get_n_splits" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the number of splitting iterations in the cross-validator</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Training data, where n_samples is the number of samples
and n_features is the number of features.</p></li>
<li><p><strong>y</strong> (<em>object</em>) – Always ignored, exists for compatibility.</p></li>
<li><p><strong>groups</strong> (<em>object</em>) – Always ignored, exists for compatibility.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>n_splits</strong> – Returns the number of splitting iterations in the cross-validator.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.model_selection.LeavePGroupsOut">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">LeavePGroupsOut</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_groups</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.LeavePGroupsOut" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#sklearn.model_selection.BaseCrossValidator" title="sklearn.model_selection._split.BaseCrossValidator"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.model_selection._split.BaseCrossValidator</span></code></a></p>
<p>Leave P Group(s) Out cross-validator</p>
<p>Provides train/test indices to split data according to a third-party
provided group. This group information can be used to encode arbitrary
domain specific stratifications of the samples as integers.</p>
<p>For instance the groups could be the year of collection of the samples
and thus allow for cross-validation against time-based splits.</p>
<p>The difference between LeavePGroupsOut and LeaveOneGroupOut is that
the former builds the test sets with all the samples assigned to
<code class="docutils literal notranslate"><span class="pre">p</span></code> different values of the groups while the latter uses samples
all assigned the same groups.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>n_groups</strong> (<em>int</em>) – Number of groups (<code class="docutils literal notranslate"><span class="pre">p</span></code>) to leave out in the test split.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">LeavePGroupsOut</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">groups</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lpgo</span> <span class="o">=</span> <span class="n">LeavePGroupsOut</span><span class="p">(</span><span class="n">n_groups</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lpgo</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lpgo</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">(</span><span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">)</span>  <span class="c1"># &#39;groups&#39; is always required</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">lpgo</span><span class="p">)</span>
<span class="go">LeavePGroupsOut(n_groups=2)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">lpgo</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TRAIN:&quot;</span><span class="p">,</span> <span class="n">train_index</span><span class="p">,</span> <span class="s2">&quot;TEST:&quot;</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="gp">... </span>    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="go">TRAIN: [2] TEST: [0 1]</span>
<span class="go">[[5 6]] [[1 2]</span>
<span class="go"> [3 4]] [1] [1 2]</span>
<span class="go">TRAIN: [1] TEST: [0 2]</span>
<span class="go">[[3 4]] [[1 2]</span>
<span class="go"> [5 6]] [2] [1 1]</span>
<span class="go">TRAIN: [0] TEST: [1 2]</span>
<span class="go">[[1 2]] [[3 4]</span>
<span class="go"> [5 6]] [1] [2 1]</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.model_selection.GroupKFold" title="sklearn.model_selection.GroupKFold"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GroupKFold</span></code></a></dt><dd><p>K-fold iterator variant with non-overlapping groups.</p>
</dd>
</dl>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.model_selection.LeavePGroupsOut.get_n_splits">
<span class="sig-name descname"><span class="pre">get_n_splits</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.LeavePGroupsOut.get_n_splits" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the number of splitting iterations in the cross-validator</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>object</em>) – Always ignored, exists for compatibility.</p></li>
<li><p><strong>y</strong> (<em>object</em>) – Always ignored, exists for compatibility.</p></li>
<li><p><strong>groups</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Group labels for the samples used while splitting the dataset into
train/test set. This ‘groups’ parameter must always be specified to
calculate the number of splits, though the other parameters can be
omitted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>n_splits</strong> – Returns the number of splitting iterations in the cross-validator.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.model_selection.LeavePGroupsOut.split">
<span class="sig-name descname"><span class="pre">split</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.LeavePGroupsOut.split" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate indices to split data into training and test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Training data, where n_samples is the number of samples
and n_features is the number of features.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – The target variable for supervised learning problems.</p></li>
<li><p><strong>groups</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Group labels for the samples used while splitting the dataset into
train/test set.</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>train</strong> (<em>ndarray</em>) – The training set indices for that split.</p></li>
<li><p><strong>test</strong> (<em>ndarray</em>) – The testing set indices for that split.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.model_selection.LeavePOut">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">LeavePOut</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.LeavePOut" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#sklearn.model_selection.BaseCrossValidator" title="sklearn.model_selection._split.BaseCrossValidator"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.model_selection._split.BaseCrossValidator</span></code></a></p>
<p>Leave-P-Out cross-validator</p>
<p>Provides train/test indices to split data in train/test sets. This results
in testing on all distinct samples of size p, while the remaining n - p
samples form the training set in each iteration.</p>
<p>Note: <code class="docutils literal notranslate"><span class="pre">LeavePOut(p)</span></code> is NOT equivalent to
<code class="docutils literal notranslate"><span class="pre">KFold(n_splits=n_samples</span> <span class="pre">//</span> <span class="pre">p)</span></code> which creates non-overlapping test sets.</p>
<p>Due to the high number of iterations which grows combinatorically with the
number of samples this cross-validation method can be very costly. For
large datasets one should favor <a class="reference internal" href="#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a>, <a class="reference internal" href="#sklearn.model_selection.StratifiedKFold" title="sklearn.model_selection.StratifiedKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">StratifiedKFold</span></code></a>
or <a class="reference internal" href="#sklearn.model_selection.ShuffleSplit" title="sklearn.model_selection.ShuffleSplit"><code class="xref py py-class docutils literal notranslate"><span class="pre">ShuffleSplit</span></code></a>.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>p</strong> (<em>int</em>) – Size of the test sets. Must be strictly less than the number of
samples.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">LeavePOut</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lpo</span> <span class="o">=</span> <span class="n">LeavePOut</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lpo</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">6</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">lpo</span><span class="p">)</span>
<span class="go">LeavePOut(p=2)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">lpo</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TRAIN:&quot;</span><span class="p">,</span> <span class="n">train_index</span><span class="p">,</span> <span class="s2">&quot;TEST:&quot;</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="gp">... </span>    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="go">TRAIN: [2 3] TEST: [0 1]</span>
<span class="go">TRAIN: [1 3] TEST: [0 2]</span>
<span class="go">TRAIN: [1 2] TEST: [0 3]</span>
<span class="go">TRAIN: [0 3] TEST: [1 2]</span>
<span class="go">TRAIN: [0 2] TEST: [1 3]</span>
<span class="go">TRAIN: [0 1] TEST: [2 3]</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.model_selection.LeavePOut.get_n_splits">
<span class="sig-name descname"><span class="pre">get_n_splits</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.LeavePOut.get_n_splits" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the number of splitting iterations in the cross-validator</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Training data, where n_samples is the number of samples
and n_features is the number of features.</p></li>
<li><p><strong>y</strong> (<em>object</em>) – Always ignored, exists for compatibility.</p></li>
<li><p><strong>groups</strong> (<em>object</em>) – Always ignored, exists for compatibility.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.model_selection.ParameterGrid">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">ParameterGrid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">param_grid</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.ParameterGrid" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Grid of parameters with a discrete number of values for each.</p>
<p>Can be used to iterate over parameter value combinations with the
Python built-in function iter.
The order of the generated parameter combinations is deterministic.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>param_grid</strong> (<em>dict of str to sequence</em><em>, or </em><em>sequence of such</em>) – <p>The parameter grid to explore, as a dictionary mapping estimator
parameters to sequences of allowed values.</p>
<p>An empty dict signifies default parameters.</p>
<p>A sequence of dicts signifies a sequence of grids to search, and is
useful to avoid exploring parameter combinations that make no sense
or have no effect. See the examples below.</p>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">ParameterGrid</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">list</span><span class="p">(</span><span class="n">ParameterGrid</span><span class="p">(</span><span class="n">param_grid</span><span class="p">))</span> <span class="o">==</span> <span class="p">(</span>
<span class="gp">... </span>   <span class="p">[{</span><span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">},</span> <span class="p">{</span><span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">},</span>
<span class="gp">... </span>    <span class="p">{</span><span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">},</span> <span class="p">{</span><span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">}])</span>
<span class="go">True</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">grid</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">]},</span> <span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;rbf&#39;</span><span class="p">],</span> <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">]}]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">list</span><span class="p">(</span><span class="n">ParameterGrid</span><span class="p">(</span><span class="n">grid</span><span class="p">))</span> <span class="o">==</span> <span class="p">[{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="s1">&#39;linear&#39;</span><span class="p">},</span>
<span class="gp">... </span>                              <span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">},</span>
<span class="gp">... </span>                              <span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}]</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ParameterGrid</span><span class="p">(</span><span class="n">grid</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
<span class="go">True</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.model_selection.GridSearchCV" title="sklearn.model_selection.GridSearchCV"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GridSearchCV</span></code></a></dt><dd><p>Uses <a class="reference internal" href="#sklearn.model_selection.ParameterGrid" title="sklearn.model_selection.ParameterGrid"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParameterGrid</span></code></a> to perform a full parallelized parameter search.</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.model_selection.ParameterSampler">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">ParameterSampler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">param_distributions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_iter</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.ParameterSampler" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Generator on parameters sampled from given distributions.</p>
<p>Non-deterministic iterable over random candidate combinations for hyper-
parameter search. If all parameters are presented as a list,
sampling without replacement is performed. If at least one parameter
is given as a distribution, sampling with replacement is used.
It is highly recommended to use continuous distributions for continuous
parameters.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>param_distributions</strong> (<em>dict</em>) – Dictionary with parameters names (<cite>str</cite>) as keys and distributions
or lists of parameters to try. Distributions must provide a <code class="docutils literal notranslate"><span class="pre">rvs</span></code>
method for sampling (such as those from scipy.stats.distributions).
If a list is given, it is sampled uniformly.
If a list of dicts is given, first a dict is sampled uniformly, and
then a parameter is sampled using that dict as above.</p></li>
<li><p><strong>n_iter</strong> (<em>int</em>) – Number of parameter settings that are produced.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Pseudo random number generator state used for random uniform sampling
from lists of possible values instead of scipy.stats distributions.
Pass an int for reproducible output across multiple
function calls.
See <span class="xref std std-term">Glossary</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>params</strong> – <strong>Yields</strong> dictionaries mapping each estimator parameter to
as sampled value.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict of str to any</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">ParameterSampler</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">scipy.stats.distributions</span> <span class="kn">import</span> <span class="n">expon</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;a&#39;</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="n">expon</span><span class="p">()}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">ParameterSampler</span><span class="p">(</span><span class="n">param_grid</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<span class="gp">... </span>                                   <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rounded_list</span> <span class="o">=</span> <span class="p">[</span><span class="nb">dict</span><span class="p">((</span><span class="n">k</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span> <span class="k">for</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="ow">in</span> <span class="n">d</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
<span class="gp">... </span>                <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">param_list</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rounded_list</span> <span class="o">==</span> <span class="p">[{</span><span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="mf">0.89856</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">},</span>
<span class="gp">... </span>                 <span class="p">{</span><span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="mf">0.923223</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">},</span>
<span class="gp">... </span>                 <span class="p">{</span><span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="mf">1.878964</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">},</span>
<span class="gp">... </span>                 <span class="p">{</span><span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="mf">1.038159</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}]</span>
<span class="go">True</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.model_selection.PredefinedSplit">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">PredefinedSplit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">test_fold</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.PredefinedSplit" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#sklearn.model_selection.BaseCrossValidator" title="sklearn.model_selection._split.BaseCrossValidator"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.model_selection._split.BaseCrossValidator</span></code></a></p>
<p>Predefined split cross-validator</p>
<p>Provides train/test indices to split data into train/test sets using a
predefined scheme specified by the user with the <code class="docutils literal notranslate"><span class="pre">test_fold</span></code> parameter.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.16.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>test_fold</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The entry <code class="docutils literal notranslate"><span class="pre">test_fold[i]</span></code> represents the index of the test set that
sample <code class="docutils literal notranslate"><span class="pre">i</span></code> belongs to. It is possible to exclude sample <code class="docutils literal notranslate"><span class="pre">i</span></code> from
any test set (i.e. include sample <code class="docutils literal notranslate"><span class="pre">i</span></code> in every training set) by
setting <code class="docutils literal notranslate"><span class="pre">test_fold[i]</span></code> equal to -1.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">PredefinedSplit</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test_fold</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span> <span class="o">=</span> <span class="n">PredefinedSplit</span><span class="p">(</span><span class="n">test_fold</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">()</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">ps</span><span class="p">)</span>
<span class="go">PredefinedSplit(test_fold=array([ 0,  1, -1,  1]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">ps</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TRAIN:&quot;</span><span class="p">,</span> <span class="n">train_index</span><span class="p">,</span> <span class="s2">&quot;TEST:&quot;</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="gp">... </span>    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="go">TRAIN: [1 2 3] TEST: [0]</span>
<span class="go">TRAIN: [0 2] TEST: [1 3]</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.model_selection.PredefinedSplit.get_n_splits">
<span class="sig-name descname"><span class="pre">get_n_splits</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.PredefinedSplit.get_n_splits" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the number of splitting iterations in the cross-validator</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>object</em>) – Always ignored, exists for compatibility.</p></li>
<li><p><strong>y</strong> (<em>object</em>) – Always ignored, exists for compatibility.</p></li>
<li><p><strong>groups</strong> (<em>object</em>) – Always ignored, exists for compatibility.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>n_splits</strong> – Returns the number of splitting iterations in the cross-validator.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.model_selection.PredefinedSplit.split">
<span class="sig-name descname"><span class="pre">split</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.PredefinedSplit.split" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate indices to split data into training and test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>object</em>) – Always ignored, exists for compatibility.</p></li>
<li><p><strong>y</strong> (<em>object</em>) – Always ignored, exists for compatibility.</p></li>
<li><p><strong>groups</strong> (<em>object</em>) – Always ignored, exists for compatibility.</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>train</strong> (<em>ndarray</em>) – The training set indices for that split.</p></li>
<li><p><strong>test</strong> (<em>ndarray</em>) – The testing set indices for that split.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.model_selection.RandomizedSearchCV">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">RandomizedSearchCV</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">estimator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_distributions</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">refit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_dispatch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'2*n_jobs'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">error_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">nan</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_train_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.RandomizedSearchCV" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.model_selection._search.BaseSearchCV</span></code></p>
<p>Randomized search on hyper parameters.</p>
<p>RandomizedSearchCV implements a “fit” and a “score” method.
It also implements “score_samples”, “predict”, “predict_proba”,
“decision_function”, “transform” and “inverse_transform” if they are
implemented in the estimator used.</p>
<p>The parameters of the estimator used to apply these methods are optimized
by cross-validated search over parameter settings.</p>
<p>In contrast to GridSearchCV, not all parameter values are tried out, but
rather a fixed number of parameter settings is sampled from the specified
distributions. The number of parameter settings that are tried is
given by n_iter.</p>
<p>If all parameters are presented as a list,
sampling without replacement is performed. If at least one parameter
is given as a distribution, sampling with replacement is used.
It is highly recommended to use continuous distributions for continuous
parameters.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.14.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>estimator object.</em>) – A object of that type is instantiated for each grid point.
This is assumed to implement the scikit-learn estimator interface.
Either estimator needs to provide a <code class="docutils literal notranslate"><span class="pre">score</span></code> function,
or <code class="docutils literal notranslate"><span class="pre">scoring</span></code> must be passed.</p></li>
<li><p><strong>param_distributions</strong> (<em>dict</em><em> or </em><em>list of dicts</em>) – Dictionary with parameters names (<cite>str</cite>) as keys and distributions
or lists of parameters to try. Distributions must provide a <code class="docutils literal notranslate"><span class="pre">rvs</span></code>
method for sampling (such as those from scipy.stats.distributions).
If a list is given, it is sampled uniformly.
If a list of dicts is given, first a dict is sampled uniformly, and
then a parameter is sampled using that dict as above.</p></li>
<li><p><strong>n_iter</strong> (<em>int</em><em>, </em><em>default=10</em>) – Number of parameter settings that are sampled. n_iter trades
off runtime vs quality of the solution.</p></li>
<li><p><strong>scoring</strong> (<em>str</em><em>, </em><em>callable</em><em>, </em><em>list</em><em>, </em><em>tuple</em><em> or </em><em>dict</em><em>, </em><em>default=None</em>) – <p>Strategy to evaluate the performance of the cross-validated model on
the test set.</p>
<p>If <cite>scoring</cite> represents a single score, one can use:</p>
<ul>
<li><p>a single string (see <span class="xref std std-ref">scoring_parameter</span>);</p></li>
<li><p>a callable (see <span class="xref std std-ref">scoring</span>) that returns a single value.</p></li>
</ul>
<p>If <cite>scoring</cite> represents multiple scores, one can use:</p>
<ul>
<li><p>a list or tuple of unique strings;</p></li>
<li><p>a callable returning a dictionary where the keys are the metric
names and the values are the metric scores;</p></li>
<li><p>a dictionary with metric names as keys and callables a values.</p></li>
</ul>
<p>See <span class="xref std std-ref">multimetric_grid_search</span> for an example.</p>
<p>If None, the estimator’s score method is used.</p>
</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default=None</em>) – <p>Number of jobs to run in parallel.
<code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a <code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context.
<code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all processors. See <span class="xref std std-term">Glossary</span>
for more details.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version v0.20: </span><cite>n_jobs</cite> default changed from 1 to None</p>
</div>
</p></li>
<li><p><strong>refit</strong> (<em>bool</em><em>, </em><em>str</em><em>, or </em><em>callable</em><em>, </em><em>default=True</em>) – <p>Refit an estimator using the best found parameters on the whole
dataset.</p>
<p>For multiple metric evaluation, this needs to be a <cite>str</cite> denoting the
scorer that would be used to find the best parameters for refitting
the estimator at the end.</p>
<p>Where there are considerations other than maximum score in
choosing a best estimator, <code class="docutils literal notranslate"><span class="pre">refit</span></code> can be set to a function which
returns the selected <code class="docutils literal notranslate"><span class="pre">best_index_</span></code> given the <code class="docutils literal notranslate"><span class="pre">cv_results</span></code>. In that
case, the <code class="docutils literal notranslate"><span class="pre">best_estimator_</span></code> and <code class="docutils literal notranslate"><span class="pre">best_params_</span></code> will be set
according to the returned <code class="docutils literal notranslate"><span class="pre">best_index_</span></code> while the <code class="docutils literal notranslate"><span class="pre">best_score_</span></code>
attribute will not be available.</p>
<p>The refitted estimator is made available at the <code class="docutils literal notranslate"><span class="pre">best_estimator_</span></code>
attribute and permits using <code class="docutils literal notranslate"><span class="pre">predict</span></code> directly on this
<code class="docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code> instance.</p>
<p>Also for multiple metric evaluation, the attributes <code class="docutils literal notranslate"><span class="pre">best_index_</span></code>,
<code class="docutils literal notranslate"><span class="pre">best_score_</span></code> and <code class="docutils literal notranslate"><span class="pre">best_params_</span></code> will only be available if
<code class="docutils literal notranslate"><span class="pre">refit</span></code> is set and all of them will be determined w.r.t this specific
scorer.</p>
<p>See <code class="docutils literal notranslate"><span class="pre">scoring</span></code> parameter to know more about multiple metric
evaluation.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.20: </span>Support for callable added.</p>
</div>
</p></li>
<li><p><strong>cv</strong> (<em>int</em><em>, </em><em>cross-validation generator</em><em> or </em><em>an iterable</em><em>, </em><em>default=None</em>) – <p>Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul>
<li><p>None, to use the default 5-fold cross validation,</p></li>
<li><p>integer, to specify the number of folds in a <cite>(Stratified)KFold</cite>,</p></li>
<li><p><span class="xref std std-term">CV splitter</span>,</p></li>
<li><p>An iterable yielding (train, test) splits as arrays of indices.</p></li>
</ul>
<p>For integer/None inputs, if the estimator is a classifier and <code class="docutils literal notranslate"><span class="pre">y</span></code> is
either binary or multiclass, <a class="reference internal" href="#sklearn.model_selection.StratifiedKFold" title="sklearn.model_selection.StratifiedKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">StratifiedKFold</span></code></a> is used. In all
other cases, <a class="reference internal" href="#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> is used. These splitters are instantiated
with <cite>shuffle=False</cite> so the splits will be the same across calls.</p>
<p>Refer <span class="xref std std-ref">User Guide</span> for the various
cross-validation strategies that can be used here.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.22: </span><code class="docutils literal notranslate"><span class="pre">cv</span></code> default value if None changed from 3-fold to 5-fold.</p>
</div>
</p></li>
<li><p><strong>verbose</strong> (<em>int</em>) – Controls the verbosity: the higher, the more messages.</p></li>
<li><p><strong>pre_dispatch</strong> (<em>int</em><em>, or </em><em>str</em><em>, </em><em>default=None</em>) – <p>Controls the number of jobs that get dispatched during parallel
execution. Reducing this number can be useful to avoid an
explosion of memory consumption when more jobs get dispatched
than CPUs can process. This parameter can be:</p>
<blockquote>
<div><ul>
<li><p>None, in which case all the jobs are immediately
created and spawned. Use this for lightweight and
fast-running jobs, to avoid delays due to on-demand
spawning of the jobs</p></li>
<li><p>An int, giving the exact number of total jobs that are
spawned</p></li>
<li><p>A str, giving an expression as a function of n_jobs,
as in ‘2*n_jobs’</p></li>
</ul>
</div></blockquote>
</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Pseudo random number generator state used for random uniform sampling
from lists of possible values instead of scipy.stats distributions.
Pass an int for reproducible output across multiple
function calls.
See <span class="xref std std-term">Glossary</span>.</p></li>
<li><p><strong>error_score</strong> (<em>'raise'</em><em> or </em><em>numeric</em><em>, </em><em>default=np.nan</em>) – Value to assign to the score if an error occurs in estimator fitting.
If set to ‘raise’, the error is raised. If a numeric value is given,
FitFailedWarning is raised. This parameter does not affect the refit
step, which will always raise the error.</p></li>
<li><p><strong>return_train_score</strong> (<em>bool</em><em>, </em><em>default=False</em>) – <p>If <code class="docutils literal notranslate"><span class="pre">False</span></code>, the <code class="docutils literal notranslate"><span class="pre">cv_results_</span></code> attribute will not include training
scores.
Computing training scores is used to get insights on how different
parameter settings impact the overfitting/underfitting trade-off.
However computing the scores on the training set can be computationally
expensive and is not strictly required to select the parameters that
yield the best generalization performance.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.19.</span></p>
</div>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.21: </span>Default value was changed from <code class="docutils literal notranslate"><span class="pre">True</span></code> to <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
</div>
</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.RandomizedSearchCV.cv_results_">
<span class="sig-name descname"><span class="pre">cv_results_</span></span><a class="headerlink" href="#sklearn.model_selection.RandomizedSearchCV.cv_results_" title="Permalink to this definition">¶</a></dt>
<dd><p>A dict with keys as column headers and values as columns, that can be
imported into a pandas <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code>.</p>
<p>For instance the below given table</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 22%" />
<col style="width: 20%" />
<col style="width: 30%" />
<col style="width: 5%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>param_kernel</p></th>
<th class="head"><p>param_gamma</p></th>
<th class="head"><p>split0_test_score</p></th>
<th class="head"><p>…</p></th>
<th class="head"><p>rank_test_score</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>‘rbf’</p></td>
<td><p>0.1</p></td>
<td><p>0.80</p></td>
<td><p>…</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd"><td><p>‘rbf’</p></td>
<td><p>0.2</p></td>
<td><p>0.84</p></td>
<td><p>…</p></td>
<td><p>3</p></td>
</tr>
<tr class="row-even"><td><p>‘rbf’</p></td>
<td><p>0.3</p></td>
<td><p>0.70</p></td>
<td><p>…</p></td>
<td><p>2</p></td>
</tr>
</tbody>
</table>
<p>will be represented by a <code class="docutils literal notranslate"><span class="pre">cv_results_</span></code> dict of:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="s1">&#39;param_kernel&#39;</span> <span class="p">:</span> <span class="n">masked_array</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">],</span>
                              <span class="n">mask</span> <span class="o">=</span> <span class="kc">False</span><span class="p">),</span>
<span class="s1">&#39;param_gamma&#39;</span>  <span class="p">:</span> <span class="n">masked_array</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span> <span class="mf">0.2</span> <span class="mf">0.3</span><span class="p">],</span> <span class="n">mask</span> <span class="o">=</span> <span class="kc">False</span><span class="p">),</span>
<span class="s1">&#39;split0_test_score&#39;</span>  <span class="p">:</span> <span class="p">[</span><span class="mf">0.80</span><span class="p">,</span> <span class="mf">0.84</span><span class="p">,</span> <span class="mf">0.70</span><span class="p">],</span>
<span class="s1">&#39;split1_test_score&#39;</span>  <span class="p">:</span> <span class="p">[</span><span class="mf">0.82</span><span class="p">,</span> <span class="mf">0.50</span><span class="p">,</span> <span class="mf">0.70</span><span class="p">],</span>
<span class="s1">&#39;mean_test_score&#39;</span>    <span class="p">:</span> <span class="p">[</span><span class="mf">0.81</span><span class="p">,</span> <span class="mf">0.67</span><span class="p">,</span> <span class="mf">0.70</span><span class="p">],</span>
<span class="s1">&#39;std_test_score&#39;</span>     <span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.24</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">],</span>
<span class="s1">&#39;rank_test_score&#39;</span>    <span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
<span class="s1">&#39;split0_train_score&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mf">0.80</span><span class="p">,</span> <span class="mf">0.92</span><span class="p">,</span> <span class="mf">0.70</span><span class="p">],</span>
<span class="s1">&#39;split1_train_score&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mf">0.82</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.70</span><span class="p">],</span>
<span class="s1">&#39;mean_train_score&#39;</span>   <span class="p">:</span> <span class="p">[</span><span class="mf">0.81</span><span class="p">,</span> <span class="mf">0.74</span><span class="p">,</span> <span class="mf">0.70</span><span class="p">],</span>
<span class="s1">&#39;std_train_score&#39;</span>    <span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.19</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">],</span>
<span class="s1">&#39;mean_fit_time&#39;</span>      <span class="p">:</span> <span class="p">[</span><span class="mf">0.73</span><span class="p">,</span> <span class="mf">0.63</span><span class="p">,</span> <span class="mf">0.43</span><span class="p">],</span>
<span class="s1">&#39;std_fit_time&#39;</span>       <span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">],</span>
<span class="s1">&#39;mean_score_time&#39;</span>    <span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.06</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">],</span>
<span class="s1">&#39;std_score_time&#39;</span>     <span class="p">:</span> <span class="p">[</span><span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">],</span>
<span class="s1">&#39;params&#39;</span>             <span class="p">:</span> <span class="p">[{</span><span class="s1">&#39;kernel&#39;</span> <span class="p">:</span> <span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;gamma&#39;</span> <span class="p">:</span> <span class="mf">0.1</span><span class="p">},</span> <span class="o">...</span><span class="p">],</span>
<span class="p">}</span>
</pre></div>
</div>
<p>NOTE</p>
<p>The key <code class="docutils literal notranslate"><span class="pre">'params'</span></code> is used to store a list of parameter
settings dicts for all the parameter candidates.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">mean_fit_time</span></code>, <code class="docutils literal notranslate"><span class="pre">std_fit_time</span></code>, <code class="docutils literal notranslate"><span class="pre">mean_score_time</span></code> and
<code class="docutils literal notranslate"><span class="pre">std_score_time</span></code> are all in seconds.</p>
<p>For multi-metric evaluation, the scores for all the scorers are
available in the <code class="docutils literal notranslate"><span class="pre">cv_results_</span></code> dict at the keys ending with that
scorer’s name (<code class="docutils literal notranslate"><span class="pre">'_&lt;scorer_name&gt;'</span></code>) instead of <code class="docutils literal notranslate"><span class="pre">'_score'</span></code> shown
above. (‘split0_test_precision’, ‘mean_train_precision’ etc.)</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict of numpy (masked) ndarrays</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.RandomizedSearchCV.best_estimator_">
<span class="sig-name descname"><span class="pre">best_estimator_</span></span><a class="headerlink" href="#sklearn.model_selection.RandomizedSearchCV.best_estimator_" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimator that was chosen by the search, i.e. estimator
which gave highest score (or smallest loss if specified)
on the left out data. Not available if <code class="docutils literal notranslate"><span class="pre">refit=False</span></code>.</p>
<p>For multi-metric evaluation, this attribute is present only if
<code class="docutils literal notranslate"><span class="pre">refit</span></code> is specified.</p>
<p>See <code class="docutils literal notranslate"><span class="pre">refit</span></code> parameter for more information on allowed values.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>estimator</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.RandomizedSearchCV.best_score_">
<span class="sig-name descname"><span class="pre">best_score_</span></span><a class="headerlink" href="#sklearn.model_selection.RandomizedSearchCV.best_score_" title="Permalink to this definition">¶</a></dt>
<dd><p>Mean cross-validated score of the best_estimator.</p>
<p>For multi-metric evaluation, this is not available if <code class="docutils literal notranslate"><span class="pre">refit</span></code> is
<code class="docutils literal notranslate"><span class="pre">False</span></code>. See <code class="docutils literal notranslate"><span class="pre">refit</span></code> parameter for more information.</p>
<p>This attribute is not available if <code class="docutils literal notranslate"><span class="pre">refit</span></code> is a function.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.RandomizedSearchCV.best_params_">
<span class="sig-name descname"><span class="pre">best_params_</span></span><a class="headerlink" href="#sklearn.model_selection.RandomizedSearchCV.best_params_" title="Permalink to this definition">¶</a></dt>
<dd><p>Parameter setting that gave the best results on the hold out data.</p>
<p>For multi-metric evaluation, this is not available if <code class="docutils literal notranslate"><span class="pre">refit</span></code> is
<code class="docutils literal notranslate"><span class="pre">False</span></code>. See <code class="docutils literal notranslate"><span class="pre">refit</span></code> parameter for more information.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.RandomizedSearchCV.best_index_">
<span class="sig-name descname"><span class="pre">best_index_</span></span><a class="headerlink" href="#sklearn.model_selection.RandomizedSearchCV.best_index_" title="Permalink to this definition">¶</a></dt>
<dd><p>The index (of the <code class="docutils literal notranslate"><span class="pre">cv_results_</span></code> arrays) which corresponds to the best
candidate parameter setting.</p>
<p>The dict at <code class="docutils literal notranslate"><span class="pre">search.cv_results_['params'][search.best_index_]</span></code> gives
the parameter setting for the best model, that gives the highest
mean score (<code class="docutils literal notranslate"><span class="pre">search.best_score_</span></code>).</p>
<p>For multi-metric evaluation, this is not available if <code class="docutils literal notranslate"><span class="pre">refit</span></code> is
<code class="docutils literal notranslate"><span class="pre">False</span></code>. See <code class="docutils literal notranslate"><span class="pre">refit</span></code> parameter for more information.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.RandomizedSearchCV.scorer_">
<span class="sig-name descname"><span class="pre">scorer_</span></span><a class="headerlink" href="#sklearn.model_selection.RandomizedSearchCV.scorer_" title="Permalink to this definition">¶</a></dt>
<dd><p>Scorer function used on the held out data to choose the best
parameters for the model.</p>
<p>For multi-metric evaluation, this attribute holds the validated
<code class="docutils literal notranslate"><span class="pre">scoring</span></code> dict which maps the scorer key to the scorer callable.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>function or a dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.RandomizedSearchCV.n_splits_">
<span class="sig-name descname"><span class="pre">n_splits_</span></span><a class="headerlink" href="#sklearn.model_selection.RandomizedSearchCV.n_splits_" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of cross-validation splits (folds/iterations).</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.RandomizedSearchCV.refit_time_">
<span class="sig-name descname"><span class="pre">refit_time_</span></span><a class="headerlink" href="#sklearn.model_selection.RandomizedSearchCV.refit_time_" title="Permalink to this definition">¶</a></dt>
<dd><p>Seconds used for refitting the best model on the whole dataset.</p>
<p>This is present only if <code class="docutils literal notranslate"><span class="pre">refit</span></code> is not False.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.20.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.model_selection.RandomizedSearchCV.multimetric_">
<span class="sig-name descname"><span class="pre">multimetric_</span></span><a class="headerlink" href="#sklearn.model_selection.RandomizedSearchCV.multimetric_" title="Permalink to this definition">¶</a></dt>
<dd><p>Whether or not the scorers compute several metrics.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Notes</p>
<p>The parameters selected are those that maximize the score of the held-out
data, according to the scoring parameter.</p>
<p>If <cite>n_jobs</cite> was set to a value higher than one, the data is copied for each
parameter setting(and not <cite>n_jobs</cite> times). This is done for efficiency
reasons if individual jobs take very little time, but may raise errors if
the dataset is large and not enough memory is available.  A workaround in
this case is to set <cite>pre_dispatch</cite>. Then, the memory is copied only
<cite>pre_dispatch</cite> many times. A reasonable value for <cite>pre_dispatch</cite> is <cite>2 *
n_jobs</cite>.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.model_selection.GridSearchCV" title="sklearn.model_selection.GridSearchCV"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GridSearchCV</span></code></a></dt><dd><p>Does exhaustive search over a grid of parameters.</p>
</dd>
<dt><a class="reference internal" href="#sklearn.model_selection.ParameterSampler" title="sklearn.model_selection.ParameterSampler"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ParameterSampler</span></code></a></dt><dd><p>A generator over parameter settings, constructed from param_distributions.</p>
</dd>
</dl>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">RandomizedSearchCV</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">uniform</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logistic</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;saga&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
<span class="gp">... </span>                              <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">distributions</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="n">uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>
<span class="gp">... </span>                     <span class="n">penalty</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;l2&#39;</span><span class="p">,</span> <span class="s1">&#39;l1&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">logistic</span><span class="p">,</span> <span class="n">distributions</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">search</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">search</span><span class="o">.</span><span class="n">best_params_</span>
<span class="go">{&#39;C&#39;: 2..., &#39;penalty&#39;: &#39;l1&#39;}</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.model_selection.RepeatedKFold">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">RepeatedKFold</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_splits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_repeats</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.RepeatedKFold" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.model_selection._split._RepeatedSplits</span></code></p>
<p>Repeated K-Fold cross validator.</p>
<p>Repeats K-Fold n times with different randomization in each repetition.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_splits</strong> (<em>int</em><em>, </em><em>default=5</em>) – Number of folds. Must be at least 2.</p></li>
<li><p><strong>n_repeats</strong> (<em>int</em><em>, </em><em>default=10</em>) – Number of times cross-validator needs to be repeated.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Controls the randomness of each repeated cross-validation instance.
Pass an int for reproducible output across multiple function calls.
See <span class="xref std std-term">Glossary</span>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">RepeatedKFold</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rkf</span> <span class="o">=</span> <span class="n">RepeatedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">2652124</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">rkf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TRAIN:&quot;</span><span class="p">,</span> <span class="n">train_index</span><span class="p">,</span> <span class="s2">&quot;TEST:&quot;</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="gp">... </span>    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="gp">...</span>
<span class="go">TRAIN: [0 1] TEST: [2 3]</span>
<span class="go">TRAIN: [2 3] TEST: [0 1]</span>
<span class="go">TRAIN: [1 2] TEST: [0 3]</span>
<span class="go">TRAIN: [0 3] TEST: [1 2]</span>
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Randomized CV splitters may return different results for each call of
split. You can make the results identical by setting <cite>random_state</cite>
to an integer.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.model_selection.RepeatedStratifiedKFold" title="sklearn.model_selection.RepeatedStratifiedKFold"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RepeatedStratifiedKFold</span></code></a></dt><dd><p>Repeats Stratified K-Fold n times.</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.model_selection.RepeatedStratifiedKFold">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">RepeatedStratifiedKFold</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_splits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_repeats</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.RepeatedStratifiedKFold" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.model_selection._split._RepeatedSplits</span></code></p>
<p>Repeated Stratified K-Fold cross validator.</p>
<p>Repeats Stratified K-Fold n times with different randomization in each
repetition.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_splits</strong> (<em>int</em><em>, </em><em>default=5</em>) – Number of folds. Must be at least 2.</p></li>
<li><p><strong>n_repeats</strong> (<em>int</em><em>, </em><em>default=10</em>) – Number of times cross-validator needs to be repeated.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Controls the generation of the random states for each repetition.
Pass an int for reproducible output across multiple function calls.
See <span class="xref std std-term">Glossary</span>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">RepeatedStratifiedKFold</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rskf</span> <span class="o">=</span> <span class="n">RepeatedStratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">random_state</span><span class="o">=</span><span class="mi">36851234</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">rskf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TRAIN:&quot;</span><span class="p">,</span> <span class="n">train_index</span><span class="p">,</span> <span class="s2">&quot;TEST:&quot;</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="gp">... </span>    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="gp">...</span>
<span class="go">TRAIN: [1 2] TEST: [0 3]</span>
<span class="go">TRAIN: [0 3] TEST: [1 2]</span>
<span class="go">TRAIN: [1 3] TEST: [0 2]</span>
<span class="go">TRAIN: [0 2] TEST: [1 3]</span>
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Randomized CV splitters may return different results for each call of
split. You can make the results identical by setting <cite>random_state</cite>
to an integer.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.model_selection.RepeatedKFold" title="sklearn.model_selection.RepeatedKFold"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RepeatedKFold</span></code></a></dt><dd><p>Repeats K-Fold n times.</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.model_selection.ShuffleSplit">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">ShuffleSplit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_splits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.ShuffleSplit" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.model_selection._split.BaseShuffleSplit</span></code></p>
<p>Random permutation cross-validator</p>
<p>Yields indices to split data into training and test sets.</p>
<p>Note: contrary to other cross-validation strategies, random splits
do not guarantee that all folds will be different, although this is
still very likely for sizeable datasets.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_splits</strong> (<em>int</em><em>, </em><em>default=10</em>) – Number of re-shuffling &amp; splitting iterations.</p></li>
<li><p><strong>test_size</strong> (<em>float</em><em> or </em><em>int</em><em>, </em><em>default=None</em>) – If float, should be between 0.0 and 1.0 and represent the proportion
of the dataset to include in the test split. If int, represents the
absolute number of test samples. If None, the value is set to the
complement of the train size. If <code class="docutils literal notranslate"><span class="pre">train_size</span></code> is also None, it will
be set to 0.1.</p></li>
<li><p><strong>train_size</strong> (<em>float</em><em> or </em><em>int</em><em>, </em><em>default=None</em>) – If float, should be between 0.0 and 1.0 and represent the
proportion of the dataset to include in the train split. If
int, represents the absolute number of train samples. If None,
the value is automatically set to the complement of the test size.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Controls the randomness of the training and testing indices produced.
Pass an int for reproducible output across multiple function calls.
See <span class="xref std std-term">Glossary</span>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">ShuffleSplit</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rs</span> <span class="o">=</span> <span class="n">ShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">.25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rs</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">rs</span><span class="p">)</span>
<span class="go">ShuffleSplit(n_splits=5, random_state=0, test_size=0.25, train_size=None)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">rs</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TRAIN:&quot;</span><span class="p">,</span> <span class="n">train_index</span><span class="p">,</span> <span class="s2">&quot;TEST:&quot;</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span>
<span class="go">TRAIN: [1 3 0 4] TEST: [5 2]</span>
<span class="go">TRAIN: [4 0 2 5] TEST: [1 3]</span>
<span class="go">TRAIN: [1 2 4 0] TEST: [3 5]</span>
<span class="go">TRAIN: [3 4 1 0] TEST: [5 2]</span>
<span class="go">TRAIN: [3 5 1 0] TEST: [2 4]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rs</span> <span class="o">=</span> <span class="n">ShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">.25</span><span class="p">,</span>
<span class="gp">... </span>                  <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">rs</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TRAIN:&quot;</span><span class="p">,</span> <span class="n">train_index</span><span class="p">,</span> <span class="s2">&quot;TEST:&quot;</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span>
<span class="go">TRAIN: [1 3 0] TEST: [5 2]</span>
<span class="go">TRAIN: [4 0 2] TEST: [1 3]</span>
<span class="go">TRAIN: [1 2 4] TEST: [3 5]</span>
<span class="go">TRAIN: [3 4 1] TEST: [5 2]</span>
<span class="go">TRAIN: [3 5 1] TEST: [2 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.model_selection.StratifiedGroupKFold">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">StratifiedGroupKFold</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_splits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.StratifiedGroupKFold" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.model_selection._split._BaseKFold</span></code></p>
<p>Stratified K-Folds iterator variant with non-overlapping groups.</p>
<p>This cross-validation object is a variation of StratifiedKFold attempts to
return stratified folds with non-overlapping groups. The folds are made by
preserving the percentage of samples for each class.</p>
<p>The same group will not appear in two different folds (the number of
distinct groups has to be at least equal to the number of folds).</p>
<p>The difference between GroupKFold and StratifiedGroupKFold is that
the former attempts to create balanced folds such that the number of
distinct groups is approximately the same in each fold, whereas
StratifiedGroupKFold attempts to create folds which preserve the
percentage of samples for each class as much as possible given the
constraint of non-overlapping groups between splits.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_splits</strong> (<em>int</em><em>, </em><em>default=5</em>) – Number of folds. Must be at least 2.</p></li>
<li><p><strong>shuffle</strong> (<em>bool</em><em>, </em><em>default=False</em>) – Whether to shuffle each class’s samples before splitting into batches.
Note that the samples within each split will not be shuffled.
This implementation can only shuffle groups that have approximately the
same y distribution, no global shuffle will be performed.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em> or </em><em>RandomState instance</em><em>, </em><em>default=None</em>) – When <cite>shuffle</cite> is True, <cite>random_state</cite> affects the ordering of the
indices, which controls the randomness of each fold for each class.
Otherwise, leave <cite>random_state</cite> as <cite>None</cite>.
Pass an int for reproducible output across multiple function calls.
See <span class="xref std std-term">Glossary</span>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedGroupKFold</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">17</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">groups</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cv</span> <span class="o">=</span> <span class="n">StratifiedGroupKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train_idxs</span><span class="p">,</span> <span class="n">test_idxs</span> <span class="ow">in</span> <span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TRAIN:&quot;</span><span class="p">,</span> <span class="n">groups</span><span class="p">[</span><span class="n">train_idxs</span><span class="p">])</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;      &quot;</span><span class="p">,</span> <span class="n">y</span><span class="p">[</span><span class="n">train_idxs</span><span class="p">])</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; TEST:&quot;</span><span class="p">,</span> <span class="n">groups</span><span class="p">[</span><span class="n">test_idxs</span><span class="p">])</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;      &quot;</span><span class="p">,</span> <span class="n">y</span><span class="p">[</span><span class="n">test_idxs</span><span class="p">])</span>
<span class="go">TRAIN: [1 1 2 2 4 5 5 5 5 8 8]</span>
<span class="go">       [0 0 1 1 1 0 0 0 0 0 0]</span>
<span class="go"> TEST: [3 3 3 6 6 7]</span>
<span class="go">       [1 1 1 0 0 0]</span>
<span class="go">TRAIN: [3 3 3 4 5 5 5 5 6 6 7]</span>
<span class="go">       [1 1 1 1 0 0 0 0 0 0 0]</span>
<span class="go"> TEST: [1 1 2 2 8 8]</span>
<span class="go">       [0 0 1 1 0 0]</span>
<span class="go">TRAIN: [1 1 2 2 3 3 3 6 6 7 8 8]</span>
<span class="go">       [0 0 1 1 1 1 1 0 0 0 0 0]</span>
<span class="go"> TEST: [4 5 5 5 5]</span>
<span class="go">       [1 0 0 0 0]</span>
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>The implementation is designed to:</p>
<ul class="simple">
<li><p>Mimic the behavior of StratifiedKFold as much as possible for trivial
groups (e.g. when each group contains only one sample).</p></li>
<li><p>Be invariant to class label: relabelling <code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">[&quot;Happy&quot;,</span> <span class="pre">&quot;Sad&quot;]</span></code> to
<code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">[1,</span> <span class="pre">0]</span></code> should not change the indices generated.</p></li>
<li><p>Stratify based on samples as much as possible while keeping
non-overlapping groups constraint. That means that in some cases when
there is a small number of groups containing a large number of samples
the stratification will not be possible and the behavior will be close
to GroupKFold.</p></li>
</ul>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.model_selection.StratifiedKFold" title="sklearn.model_selection.StratifiedKFold"><code class="xref py py-obj docutils literal notranslate"><span class="pre">StratifiedKFold</span></code></a></dt><dd><p>Takes class information into account to build folds which retain class distributions (for binary or multiclass classification tasks).</p>
</dd>
<dt><a class="reference internal" href="#sklearn.model_selection.GroupKFold" title="sklearn.model_selection.GroupKFold"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GroupKFold</span></code></a></dt><dd><p>K-fold iterator variant with non-overlapping groups.</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.model_selection.StratifiedKFold">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">StratifiedKFold</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_splits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.StratifiedKFold" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.model_selection._split._BaseKFold</span></code></p>
<p>Stratified K-Folds cross-validator.</p>
<p>Provides train/test indices to split data in train/test sets.</p>
<p>This cross-validation object is a variation of KFold that returns
stratified folds. The folds are made by preserving the percentage of
samples for each class.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_splits</strong> (<em>int</em><em>, </em><em>default=5</em>) – <p>Number of folds. Must be at least 2.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.22: </span><code class="docutils literal notranslate"><span class="pre">n_splits</span></code> default value changed from 3 to 5.</p>
</div>
</p></li>
<li><p><strong>shuffle</strong> (<em>bool</em><em>, </em><em>default=False</em>) – Whether to shuffle each class’s samples before splitting into batches.
Note that the samples within each split will not be shuffled.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – When <cite>shuffle</cite> is True, <cite>random_state</cite> affects the ordering of the
indices, which controls the randomness of each fold for each class.
Otherwise, leave <cite>random_state</cite> as <cite>None</cite>.
Pass an int for reproducible output across multiple function calls.
See <span class="xref std std-term">Glossary</span>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">skf</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">skf</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">skf</span><span class="p">)</span>
<span class="go">StratifiedKFold(n_splits=2, random_state=None, shuffle=False)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">skf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TRAIN:&quot;</span><span class="p">,</span> <span class="n">train_index</span><span class="p">,</span> <span class="s2">&quot;TEST:&quot;</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="gp">... </span>    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="go">TRAIN: [1 3] TEST: [0 2]</span>
<span class="go">TRAIN: [0 2] TEST: [1 3]</span>
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>The implementation is designed to:</p>
<ul class="simple">
<li><p>Generate test sets such that all contain the same distribution of
classes, or as close as possible.</p></li>
<li><p>Be invariant to class label: relabelling <code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">[&quot;Happy&quot;,</span> <span class="pre">&quot;Sad&quot;]</span></code> to
<code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">[1,</span> <span class="pre">0]</span></code> should not change the indices generated.</p></li>
<li><p>Preserve order dependencies in the dataset ordering, when
<code class="docutils literal notranslate"><span class="pre">shuffle=False</span></code>: all samples from class k in some test set were
contiguous in y, or separated in y by samples from classes other than k.</p></li>
<li><p>Generate test sets where the smallest and largest differ by at most one
sample.</p></li>
</ul>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.22: </span>The previous implementation did not follow the last constraint.</p>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.model_selection.RepeatedStratifiedKFold" title="sklearn.model_selection.RepeatedStratifiedKFold"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RepeatedStratifiedKFold</span></code></a></dt><dd><p>Repeats Stratified K-Fold n times.</p>
</dd>
</dl>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.model_selection.StratifiedKFold.split">
<span class="sig-name descname"><span class="pre">split</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.StratifiedKFold.split" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate indices to split data into training and test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – <p>Training data, where n_samples is the number of samples
and n_features is the number of features.</p>
<p>Note that providing <code class="docutils literal notranslate"><span class="pre">y</span></code> is sufficient to generate the splits and
hence <code class="docutils literal notranslate"><span class="pre">np.zeros(n_samples)</span></code> may be used as a placeholder for
<code class="docutils literal notranslate"><span class="pre">X</span></code> instead of actual training data.</p>
</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The target variable for supervised learning problems.
Stratification is done based on the y labels.</p></li>
<li><p><strong>groups</strong> (<em>object</em>) – Always ignored, exists for compatibility.</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>train</strong> (<em>ndarray</em>) – The training set indices for that split.</p></li>
<li><p><strong>test</strong> (<em>ndarray</em>) – The testing set indices for that split.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Randomized CV splitters may return different results for each call of
split. You can make the results identical by setting <cite>random_state</cite>
to an integer.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.model_selection.StratifiedShuffleSplit">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">StratifiedShuffleSplit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_splits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.StratifiedShuffleSplit" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.model_selection._split.BaseShuffleSplit</span></code></p>
<p>Stratified ShuffleSplit cross-validator</p>
<p>Provides train/test indices to split data in train/test sets.</p>
<p>This cross-validation object is a merge of StratifiedKFold and
ShuffleSplit, which returns stratified randomized folds. The folds
are made by preserving the percentage of samples for each class.</p>
<p>Note: like the ShuffleSplit strategy, stratified random splits
do not guarantee that all folds will be different, although this is
still very likely for sizeable datasets.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_splits</strong> (<em>int</em><em>, </em><em>default=10</em>) – Number of re-shuffling &amp; splitting iterations.</p></li>
<li><p><strong>test_size</strong> (<em>float</em><em> or </em><em>int</em><em>, </em><em>default=None</em>) – If float, should be between 0.0 and 1.0 and represent the proportion
of the dataset to include in the test split. If int, represents the
absolute number of test samples. If None, the value is set to the
complement of the train size. If <code class="docutils literal notranslate"><span class="pre">train_size</span></code> is also None, it will
be set to 0.1.</p></li>
<li><p><strong>train_size</strong> (<em>float</em><em> or </em><em>int</em><em>, </em><em>default=None</em>) – If float, should be between 0.0 and 1.0 and represent the
proportion of the dataset to include in the train split. If
int, represents the absolute number of train samples. If None,
the value is automatically set to the complement of the test size.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Controls the randomness of the training and testing indices produced.
Pass an int for reproducible output across multiple function calls.
See <span class="xref std std-term">Glossary</span>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedShuffleSplit</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sss</span> <span class="o">=</span> <span class="n">StratifiedShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sss</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">sss</span><span class="p">)</span>
<span class="go">StratifiedShuffleSplit(n_splits=5, random_state=0, ...)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">sss</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TRAIN:&quot;</span><span class="p">,</span> <span class="n">train_index</span><span class="p">,</span> <span class="s2">&quot;TEST:&quot;</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="gp">... </span>    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="go">TRAIN: [5 2 3] TEST: [4 1 0]</span>
<span class="go">TRAIN: [5 1 4] TEST: [0 2 3]</span>
<span class="go">TRAIN: [5 0 2] TEST: [4 3 1]</span>
<span class="go">TRAIN: [4 1 0] TEST: [2 3 5]</span>
<span class="go">TRAIN: [0 5 1] TEST: [3 4 2]</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.model_selection.StratifiedShuffleSplit.split">
<span class="sig-name descname"><span class="pre">split</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.StratifiedShuffleSplit.split" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate indices to split data into training and test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – <p>Training data, where n_samples is the number of samples
and n_features is the number of features.</p>
<p>Note that providing <code class="docutils literal notranslate"><span class="pre">y</span></code> is sufficient to generate the splits and
hence <code class="docutils literal notranslate"><span class="pre">np.zeros(n_samples)</span></code> may be used as a placeholder for
<code class="docutils literal notranslate"><span class="pre">X</span></code> instead of actual training data.</p>
</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or </em><em>(</em><em>n_samples</em><em>, </em><em>n_labels</em><em>)</em>) – The target variable for supervised learning problems.
Stratification is done based on the y labels.</p></li>
<li><p><strong>groups</strong> (<em>object</em>) – Always ignored, exists for compatibility.</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>train</strong> (<em>ndarray</em>) – The training set indices for that split.</p></li>
<li><p><strong>test</strong> (<em>ndarray</em>) – The testing set indices for that split.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Randomized CV splitters may return different results for each call of
split. You can make the results identical by setting <cite>random_state</cite>
to an integer.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.model_selection.TimeSeriesSplit">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">TimeSeriesSplit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_splits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_train_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.TimeSeriesSplit" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.model_selection._split._BaseKFold</span></code></p>
<p>Time Series cross-validator</p>
<p>Provides train/test indices to split time series data samples
that are observed at fixed time intervals, in train/test sets.
In each split, test indices must be higher than before, and thus shuffling
in cross validator is inappropriate.</p>
<p>This cross-validation object is a variation of <a class="reference internal" href="#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a>.
In the kth split, it returns first k folds as train set and the
(k+1)th fold as test set.</p>
<p>Note that unlike standard cross-validation methods, successive
training sets are supersets of those that come before them.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.18.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_splits</strong> (<em>int</em><em>, </em><em>default=5</em>) – <p>Number of splits. Must be at least 2.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.22: </span><code class="docutils literal notranslate"><span class="pre">n_splits</span></code> default value changed from 3 to 5.</p>
</div>
</p></li>
<li><p><strong>max_train_size</strong> (<em>int</em><em>, </em><em>default=None</em>) – Maximum size for a single training set.</p></li>
<li><p><strong>test_size</strong> (<em>int</em><em>, </em><em>default=None</em>) – <p>Used to limit the size of the test set. Defaults to
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">//</span> <span class="pre">(n_splits</span> <span class="pre">+</span> <span class="pre">1)</span></code>, which is the maximum allowed value
with <code class="docutils literal notranslate"><span class="pre">gap=0</span></code>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
</p></li>
<li><p><strong>gap</strong> (<em>int</em><em>, </em><em>default=0</em>) – <p>Number of samples to exclude from the end of each train set before
the test set.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">TimeSeriesSplit</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tscv</span> <span class="o">=</span> <span class="n">TimeSeriesSplit</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">tscv</span><span class="p">)</span>
<span class="go">TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">tscv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TRAIN:&quot;</span><span class="p">,</span> <span class="n">train_index</span><span class="p">,</span> <span class="s2">&quot;TEST:&quot;</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="gp">... </span>    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="go">TRAIN: [0] TEST: [1]</span>
<span class="go">TRAIN: [0 1] TEST: [2]</span>
<span class="go">TRAIN: [0 1 2] TEST: [3]</span>
<span class="go">TRAIN: [0 1 2 3] TEST: [4]</span>
<span class="go">TRAIN: [0 1 2 3 4] TEST: [5]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Fix test_size to 2 with 12 samples</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tscv</span> <span class="o">=</span> <span class="n">TimeSeriesSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">tscv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>   <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TRAIN:&quot;</span><span class="p">,</span> <span class="n">train_index</span><span class="p">,</span> <span class="s2">&quot;TEST:&quot;</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span>
<span class="gp">... </span>   <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="gp">... </span>   <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="go">TRAIN: [0 1 2 3 4 5] TEST: [6 7]</span>
<span class="go">TRAIN: [0 1 2 3 4 5 6 7] TEST: [8 9]</span>
<span class="go">TRAIN: [0 1 2 3 4 5 6 7 8 9] TEST: [10 11]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Add in a 2 period gap</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tscv</span> <span class="o">=</span> <span class="n">TimeSeriesSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">gap</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">tscv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>   <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TRAIN:&quot;</span><span class="p">,</span> <span class="n">train_index</span><span class="p">,</span> <span class="s2">&quot;TEST:&quot;</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span>
<span class="gp">... </span>   <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="gp">... </span>   <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="go">TRAIN: [0 1 2 3] TEST: [6 7]</span>
<span class="go">TRAIN: [0 1 2 3 4 5] TEST: [8 9]</span>
<span class="go">TRAIN: [0 1 2 3 4 5 6 7] TEST: [10 11]</span>
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>The training set has size <code class="docutils literal notranslate"><span class="pre">i</span> <span class="pre">*</span> <span class="pre">n_samples</span> <span class="pre">//</span> <span class="pre">(n_splits</span> <span class="pre">+</span> <span class="pre">1)</span>
<span class="pre">+</span> <span class="pre">n_samples</span> <span class="pre">%</span> <span class="pre">(n_splits</span> <span class="pre">+</span> <span class="pre">1)</span></code> in the <code class="docutils literal notranslate"><span class="pre">i</span></code> th split,
with a test set of size <code class="docutils literal notranslate"><span class="pre">n_samples//(n_splits</span> <span class="pre">+</span> <span class="pre">1)</span></code> by default,
where <code class="docutils literal notranslate"><span class="pre">n_samples</span></code> is the number of samples.</p>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.model_selection.TimeSeriesSplit.split">
<span class="sig-name descname"><span class="pre">split</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.TimeSeriesSplit.split" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate indices to split data into training and test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Training data, where n_samples is the number of samples
and n_features is the number of features.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Always ignored, exists for compatibility.</p></li>
<li><p><strong>groups</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Always ignored, exists for compatibility.</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>train</strong> (<em>ndarray</em>) – The training set indices for that split.</p></li>
<li><p><strong>test</strong> (<em>ndarray</em>) – The testing set indices for that split.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sklearn.model_selection.check_cv">
<span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">check_cv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">classifier</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.check_cv" title="Permalink to this definition">¶</a></dt>
<dd><p>Input checker utility for building a cross-validator</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cv</strong> (<em>int</em><em>, </em><em>cross-validation generator</em><em> or </em><em>an iterable</em><em>, </em><em>default=None</em>) – <p>Determines the cross-validation splitting strategy.
Possible inputs for cv are:
- None, to use the default 5-fold cross validation,
- integer, to specify the number of folds.
- <span class="xref std std-term">CV splitter</span>,
- An iterable yielding (train, test) splits as arrays of indices.</p>
<p>For integer/None inputs, if classifier is True and <code class="docutils literal notranslate"><span class="pre">y</span></code> is either
binary or multiclass, <a class="reference internal" href="#sklearn.model_selection.StratifiedKFold" title="sklearn.model_selection.StratifiedKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">StratifiedKFold</span></code></a> is used. In all other
cases, <a class="reference internal" href="#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> is used.</p>
<p>Refer <span class="xref std std-ref">User Guide</span> for the various
cross-validation strategies that can be used here.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.22: </span><code class="docutils literal notranslate"><span class="pre">cv</span></code> default value changed from 3-fold to 5-fold.</p>
</div>
</p></li>
<li><p><strong>y</strong> (<em>array-like</em><em>, </em><em>default=None</em>) – The target variable for supervised learning problems.</p></li>
<li><p><strong>classifier</strong> (<em>bool</em><em>, </em><em>default=False</em>) – Whether the task is a classification task, in which case
stratified KFold will be used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>checked_cv</strong> – The return value is a cross-validator which generates the train/test
splits via the <code class="docutils literal notranslate"><span class="pre">split</span></code> method.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>a cross-validator instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sklearn.model_selection.cross_val_predict">
<span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">cross_val_predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">estimator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fit_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_dispatch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'2*n_jobs'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'predict'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.cross_val_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate cross-validated estimates for each input data point</p>
<p>The data is split according to the cv parameter. Each sample belongs
to exactly one test set, and its prediction is computed with an
estimator fitted on the corresponding training set.</p>
<p>Passing these predictions into an evaluation metric may not be a valid
way to measure generalization performance. Results can differ from
<a class="reference internal" href="#sklearn.model_selection.cross_validate" title="sklearn.model_selection.cross_validate"><code class="xref py py-func docutils literal notranslate"><span class="pre">cross_validate()</span></code></a> and <a class="reference internal" href="#sklearn.model_selection.cross_val_score" title="sklearn.model_selection.cross_val_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">cross_val_score()</span></code></a> unless all tests sets
have equal size and the metric decomposes over samples.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>estimator object implementing 'fit' and 'predict'</em>) – The object to use to fit the data.</p></li>
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data to fit. Can be, for example a list, or an array at least 2d.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or </em><em>(</em><em>n_samples</em><em>, </em><em>n_outputs</em><em>)</em><em>,             </em><em>default=None</em>) – The target variable to try to predict in the case of
supervised learning.</p></li>
<li><p><strong>groups</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – Group labels for the samples used while splitting the dataset into
train/test set. Only used in conjunction with a “Group” <span class="xref std std-term">cv</span>
instance (e.g., <a class="reference internal" href="#sklearn.model_selection.GroupKFold" title="sklearn.model_selection.GroupKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">GroupKFold</span></code></a>).</p></li>
<li><p><strong>cv</strong> (<em>int</em><em>, </em><em>cross-validation generator</em><em> or </em><em>an iterable</em><em>, </em><em>default=None</em>) – <p>Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul>
<li><p>None, to use the default 5-fold cross validation,</p></li>
<li><p>int, to specify the number of folds in a <cite>(Stratified)KFold</cite>,</p></li>
<li><p><span class="xref std std-term">CV splitter</span>,</p></li>
<li><p>An iterable yielding (train, test) splits as arrays of indices.</p></li>
</ul>
<p>For int/None inputs, if the estimator is a classifier and <code class="docutils literal notranslate"><span class="pre">y</span></code> is
either binary or multiclass, <a class="reference internal" href="#sklearn.model_selection.StratifiedKFold" title="sklearn.model_selection.StratifiedKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">StratifiedKFold</span></code></a> is used. In all
other cases, <a class="reference internal" href="#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> is used. These splitters are instantiated
with <cite>shuffle=False</cite> so the splits will be the same across calls.</p>
<p>Refer <span class="xref std std-ref">User Guide</span> for the various
cross-validation strategies that can be used here.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.22: </span><code class="docutils literal notranslate"><span class="pre">cv</span></code> default value if None changed from 3-fold to 5-fold.</p>
</div>
</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default=None</em>) – Number of jobs to run in parallel. Training the estimator and
predicting are parallelized over the cross-validation splits.
<code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a <code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context.
<code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all processors. See <span class="xref std std-term">Glossary</span>
for more details.</p></li>
<li><p><strong>verbose</strong> (<em>int</em><em>, </em><em>default=0</em>) – The verbosity level.</p></li>
<li><p><strong>fit_params</strong> (<em>dict</em><em>, </em><em>default=None</em>) – Parameters to pass to the fit method of the estimator.</p></li>
<li><p><strong>pre_dispatch</strong> (<em>int</em><em> or </em><em>str</em><em>, </em><em>default='2*n_jobs'</em>) – <p>Controls the number of jobs that get dispatched during parallel
execution. Reducing this number can be useful to avoid an
explosion of memory consumption when more jobs get dispatched
than CPUs can process. This parameter can be:</p>
<blockquote>
<div><ul>
<li><p>None, in which case all the jobs are immediately
created and spawned. Use this for lightweight and
fast-running jobs, to avoid delays due to on-demand
spawning of the jobs</p></li>
<li><p>An int, giving the exact number of total jobs that are
spawned</p></li>
<li><p>A str, giving an expression as a function of n_jobs,
as in ‘2*n_jobs’</p></li>
</ul>
</div></blockquote>
</p></li>
<li><p><strong>method</strong> (<em>{'predict'</em><em>, </em><em>'predict_proba'</em><em>, </em><em>'predict_log_proba'</em><em>,               </em><em>'decision_function'}</em><em>, </em><em>default='predict'</em>) – The method to be invoked by <cite>estimator</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p><strong>predictions</strong> –</p>
<p>This is the result of calling <cite>method</cite>. Shape:</p>
<blockquote>
<div><ul class="simple">
<li><p>When <cite>method</cite> is ‘predict’ and in special case where <cite>method</cite> is
‘decision_function’ and the target is binary: (n_samples,)</p></li>
<li><p>When <cite>method</cite> is one of {‘predict_proba’, ‘predict_log_proba’,
‘decision_function’} (unless special case above):
(n_samples, n_classes)</p></li>
<li><p>If <cite>estimator</cite> is <span class="xref std std-term">multioutput</span>, an extra dimension
‘n_outputs’ is added to the end of each shape above.</p></li>
</ul>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.model_selection.cross_val_score" title="sklearn.model_selection.cross_val_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cross_val_score</span></code></a></dt><dd><p>Calculate score for each CV split.</p>
</dd>
<dt><a class="reference internal" href="#sklearn.model_selection.cross_validate" title="sklearn.model_selection.cross_validate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cross_validate</span></code></a></dt><dd><p>Calculate one or more scores and timings for each CV split.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>In the case that one or more classes are absent in a training portion, a
default score needs to be assigned to all instances for that class if
<code class="docutils literal notranslate"><span class="pre">method</span></code> produces columns per class, as in {‘decision_function’,
‘predict_proba’, ‘predict_log_proba’}.  For <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> this value is
0.  In order to ensure finite output, we approximate negative infinity by
the minimum finite float value for the dtype in other cases.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">linear_model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_predict</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">diabetes</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_diabetes</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">diabetes</span><span class="o">.</span><span class="n">data</span><span class="p">[:</span><span class="mi">150</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">diabetes</span><span class="o">.</span><span class="n">target</span><span class="p">[:</span><span class="mi">150</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lasso</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">Lasso</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span><span class="n">lasso</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sklearn.model_selection.cross_val_score">
<span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">cross_val_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">estimator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fit_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_dispatch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'2*n_jobs'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">error_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">nan</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.cross_val_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate a score by cross-validation</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>estimator object implementing 'fit'</em>) – The object to use to fit the data.</p></li>
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data to fit. Can be for example a list, or an array.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or </em><em>(</em><em>n_samples</em><em>, </em><em>n_outputs</em><em>)</em><em>,             </em><em>default=None</em>) – The target variable to try to predict in the case of
supervised learning.</p></li>
<li><p><strong>groups</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – Group labels for the samples used while splitting the dataset into
train/test set. Only used in conjunction with a “Group” <span class="xref std std-term">cv</span>
instance (e.g., <a class="reference internal" href="#sklearn.model_selection.GroupKFold" title="sklearn.model_selection.GroupKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">GroupKFold</span></code></a>).</p></li>
<li><p><strong>scoring</strong> (<em>str</em><em> or </em><em>callable</em><em>, </em><em>default=None</em>) – <p>A str (see model evaluation documentation) or
a scorer callable object / function with signature
<code class="docutils literal notranslate"><span class="pre">scorer(estimator,</span> <span class="pre">X,</span> <span class="pre">y)</span></code> which should return only
a single value.</p>
<p>Similar to <a class="reference internal" href="#sklearn.model_selection.cross_validate" title="sklearn.model_selection.cross_validate"><code class="xref py py-func docutils literal notranslate"><span class="pre">cross_validate()</span></code></a>
but only a single metric is permitted.</p>
<p>If None, the estimator’s default scorer (if available) is used.</p>
</p></li>
<li><p><strong>cv</strong> (<em>int</em><em>, </em><em>cross-validation generator</em><em> or </em><em>an iterable</em><em>, </em><em>default=None</em>) – <p>Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul>
<li><p>None, to use the default 5-fold cross validation,</p></li>
<li><p>int, to specify the number of folds in a <cite>(Stratified)KFold</cite>,</p></li>
<li><p><span class="xref std std-term">CV splitter</span>,</p></li>
<li><p>An iterable yielding (train, test) splits as arrays of indices.</p></li>
</ul>
<p>For int/None inputs, if the estimator is a classifier and <code class="docutils literal notranslate"><span class="pre">y</span></code> is
either binary or multiclass, <a class="reference internal" href="#sklearn.model_selection.StratifiedKFold" title="sklearn.model_selection.StratifiedKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">StratifiedKFold</span></code></a> is used. In all
other cases, <a class="reference internal" href="#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> is used. These splitters are instantiated
with <cite>shuffle=False</cite> so the splits will be the same across calls.</p>
<p>Refer <span class="xref std std-ref">User Guide</span> for the various
cross-validation strategies that can be used here.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.22: </span><code class="docutils literal notranslate"><span class="pre">cv</span></code> default value if None changed from 3-fold to 5-fold.</p>
</div>
</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default=None</em>) – Number of jobs to run in parallel. Training the estimator and computing
the score are parallelized over the cross-validation splits.
<code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a <code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context.
<code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all processors. See <span class="xref std std-term">Glossary</span>
for more details.</p></li>
<li><p><strong>verbose</strong> (<em>int</em><em>, </em><em>default=0</em>) – The verbosity level.</p></li>
<li><p><strong>fit_params</strong> (<em>dict</em><em>, </em><em>default=None</em>) – Parameters to pass to the fit method of the estimator.</p></li>
<li><p><strong>pre_dispatch</strong> (<em>int</em><em> or </em><em>str</em><em>, </em><em>default='2*n_jobs'</em>) – <p>Controls the number of jobs that get dispatched during parallel
execution. Reducing this number can be useful to avoid an
explosion of memory consumption when more jobs get dispatched
than CPUs can process. This parameter can be:</p>
<blockquote>
<div><ul>
<li><p>None, in which case all the jobs are immediately
created and spawned. Use this for lightweight and
fast-running jobs, to avoid delays due to on-demand
spawning of the jobs</p></li>
<li><p>An int, giving the exact number of total jobs that are
spawned</p></li>
<li><p>A str, giving an expression as a function of n_jobs,
as in ‘2*n_jobs’</p></li>
</ul>
</div></blockquote>
</p></li>
<li><p><strong>error_score</strong> (<em>'raise'</em><em> or </em><em>numeric</em><em>, </em><em>default=np.nan</em>) – <p>Value to assign to the score if an error occurs in estimator fitting.
If set to ‘raise’, the error is raised.
If a numeric value is given, FitFailedWarning is raised.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.20.</span></p>
</div>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>scores</strong> – Array of scores of the estimator for each run of the cross validation.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray of float of shape=(len(list(cv)),)</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">linear_model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">diabetes</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_diabetes</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">diabetes</span><span class="o">.</span><span class="n">data</span><span class="p">[:</span><span class="mi">150</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">diabetes</span><span class="o">.</span><span class="n">target</span><span class="p">[:</span><span class="mi">150</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lasso</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">Lasso</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">lasso</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">))</span>
<span class="go">[0.33150734 0.08022311 0.03531764]</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.model_selection.cross_validate" title="sklearn.model_selection.cross_validate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cross_validate</span></code></a></dt><dd><p>To run cross-validation on multiple metrics and also to return train scores, fit times and score times.</p>
</dd>
<dt><a class="reference internal" href="#sklearn.model_selection.cross_val_predict" title="sklearn.model_selection.cross_val_predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cross_val_predict</span></code></a></dt><dd><p>Get predictions from each split of cross-validation for diagnostic purposes.</p>
</dd>
<dt><a class="reference internal" href="sklearn.metrics.html#sklearn.metrics.make_scorer" title="sklearn.metrics.make_scorer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sklearn.metrics.make_scorer</span></code></a></dt><dd><p>Make a scorer from a performance metric or loss function.</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sklearn.model_selection.cross_validate">
<span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">cross_validate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">estimator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fit_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_dispatch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'2*n_jobs'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_train_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_estimator</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">error_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">nan</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.cross_validate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate metric(s) by cross-validation and also record fit/score times.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>estimator object implementing 'fit'</em>) – The object to use to fit the data.</p></li>
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data to fit. Can be for example a list, or an array.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or </em><em>(</em><em>n_samples</em><em>, </em><em>n_outputs</em><em>)</em><em>,             </em><em>default=None</em>) – The target variable to try to predict in the case of
supervised learning.</p></li>
<li><p><strong>groups</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – Group labels for the samples used while splitting the dataset into
train/test set. Only used in conjunction with a “Group” <span class="xref std std-term">cv</span>
instance (e.g., <a class="reference internal" href="#sklearn.model_selection.GroupKFold" title="sklearn.model_selection.GroupKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">GroupKFold</span></code></a>).</p></li>
<li><p><strong>scoring</strong> (<em>str</em><em>, </em><em>callable</em><em>, </em><em>list</em><em>, </em><em>tuple</em><em>, or </em><em>dict</em><em>, </em><em>default=None</em>) – <p>Strategy to evaluate the performance of the cross-validated model on
the test set.</p>
<p>If <cite>scoring</cite> represents a single score, one can use:</p>
<ul>
<li><p>a single string (see <span class="xref std std-ref">scoring_parameter</span>);</p></li>
<li><p>a callable (see <span class="xref std std-ref">scoring</span>) that returns a single value.</p></li>
</ul>
<p>If <cite>scoring</cite> represents multiple scores, one can use:</p>
<ul>
<li><p>a list or tuple of unique strings;</p></li>
<li><p>a callable returning a dictionary where the keys are the metric
names and the values are the metric scores;</p></li>
<li><p>a dictionary with metric names as keys and callables a values.</p></li>
</ul>
<p>See <span class="xref std std-ref">multimetric_grid_search</span> for an example.</p>
</p></li>
<li><p><strong>cv</strong> (<em>int</em><em>, </em><em>cross-validation generator</em><em> or </em><em>an iterable</em><em>, </em><em>default=None</em>) – <p>Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul>
<li><p>None, to use the default 5-fold cross validation,</p></li>
<li><p>int, to specify the number of folds in a <cite>(Stratified)KFold</cite>,</p></li>
<li><p><span class="xref std std-term">CV splitter</span>,</p></li>
<li><p>An iterable yielding (train, test) splits as arrays of indices.</p></li>
</ul>
<p>For int/None inputs, if the estimator is a classifier and <code class="docutils literal notranslate"><span class="pre">y</span></code> is
either binary or multiclass, <a class="reference internal" href="#sklearn.model_selection.StratifiedKFold" title="sklearn.model_selection.StratifiedKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">StratifiedKFold</span></code></a> is used. In all
other cases, <code class="xref py py-class docutils literal notranslate"><span class="pre">Fold</span></code> is used. These splitters are instantiated
with <cite>shuffle=False</cite> so the splits will be the same across calls.</p>
<p>Refer <span class="xref std std-ref">User Guide</span> for the various
cross-validation strategies that can be used here.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.22: </span><code class="docutils literal notranslate"><span class="pre">cv</span></code> default value if None changed from 3-fold to 5-fold.</p>
</div>
</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default=None</em>) – Number of jobs to run in parallel. Training the estimator and computing
the score are parallelized over the cross-validation splits.
<code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a <code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context.
<code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all processors. See <span class="xref std std-term">Glossary</span>
for more details.</p></li>
<li><p><strong>verbose</strong> (<em>int</em><em>, </em><em>default=0</em>) – The verbosity level.</p></li>
<li><p><strong>fit_params</strong> (<em>dict</em><em>, </em><em>default=None</em>) – Parameters to pass to the fit method of the estimator.</p></li>
<li><p><strong>pre_dispatch</strong> (<em>int</em><em> or </em><em>str</em><em>, </em><em>default='2*n_jobs'</em>) – <p>Controls the number of jobs that get dispatched during parallel
execution. Reducing this number can be useful to avoid an
explosion of memory consumption when more jobs get dispatched
than CPUs can process. This parameter can be:</p>
<blockquote>
<div><ul>
<li><p>None, in which case all the jobs are immediately
created and spawned. Use this for lightweight and
fast-running jobs, to avoid delays due to on-demand
spawning of the jobs</p></li>
<li><p>An int, giving the exact number of total jobs that are
spawned</p></li>
<li><p>A str, giving an expression as a function of n_jobs,
as in ‘2*n_jobs’</p></li>
</ul>
</div></blockquote>
</p></li>
<li><p><strong>return_train_score</strong> (<em>bool</em><em>, </em><em>default=False</em>) – <p>Whether to include train scores.
Computing training scores is used to get insights on how different
parameter settings impact the overfitting/underfitting trade-off.
However computing the scores on the training set can be computationally
expensive and is not strictly required to select the parameters that
yield the best generalization performance.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.19.</span></p>
</div>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.21: </span>Default value was changed from <code class="docutils literal notranslate"><span class="pre">True</span></code> to <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
</div>
</p></li>
<li><p><strong>return_estimator</strong> (<em>bool</em><em>, </em><em>default=False</em>) – <p>Whether to return the estimators fitted on each split.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.20.</span></p>
</div>
</p></li>
<li><p><strong>error_score</strong> (<em>'raise'</em><em> or </em><em>numeric</em><em>, </em><em>default=np.nan</em>) – <p>Value to assign to the score if an error occurs in estimator fitting.
If set to ‘raise’, the error is raised.
If a numeric value is given, FitFailedWarning is raised.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.20.</span></p>
</div>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p><strong>scores</strong> – Array of scores of the estimator for each run of the cross validation.</p>
<p>A dict of arrays containing the score/time arrays for each scorer is
returned. The possible keys for this <code class="docutils literal notranslate"><span class="pre">dict</span></code> are:</p>
<blockquote>
<div><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">test_score</span></code></dt><dd><p>The score array for test scores on each cv split.
Suffix <code class="docutils literal notranslate"><span class="pre">_score</span></code> in <code class="docutils literal notranslate"><span class="pre">test_score</span></code> changes to a specific
metric like <code class="docutils literal notranslate"><span class="pre">test_r2</span></code> or <code class="docutils literal notranslate"><span class="pre">test_auc</span></code> if there are
multiple scoring metrics in the scoring parameter.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">train_score</span></code></dt><dd><p>The score array for train scores on each cv split.
Suffix <code class="docutils literal notranslate"><span class="pre">_score</span></code> in <code class="docutils literal notranslate"><span class="pre">train_score</span></code> changes to a specific
metric like <code class="docutils literal notranslate"><span class="pre">train_r2</span></code> or <code class="docutils literal notranslate"><span class="pre">train_auc</span></code> if there are
multiple scoring metrics in the scoring parameter.
This is available only if <code class="docutils literal notranslate"><span class="pre">return_train_score</span></code> parameter
is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">fit_time</span></code></dt><dd><p>The time for fitting the estimator on the train
set for each cv split.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">score_time</span></code></dt><dd><p>The time for scoring the estimator on the test set for each
cv split. (Note time for scoring on the train set is not
included even if <code class="docutils literal notranslate"><span class="pre">return_train_score</span></code> is set to <code class="docutils literal notranslate"><span class="pre">True</span></code></p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">estimator</span></code></dt><dd><p>The estimator objects for each cv split.
This is available only if <code class="docutils literal notranslate"><span class="pre">return_estimator</span></code> parameter
is set to <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
</dl>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict of float arrays of shape (n_splits,)</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">linear_model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_validate</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">make_scorer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVC</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">diabetes</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_diabetes</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">diabetes</span><span class="o">.</span><span class="n">data</span><span class="p">[:</span><span class="mi">150</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">diabetes</span><span class="o">.</span><span class="n">target</span><span class="p">[:</span><span class="mi">150</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lasso</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">Lasso</span><span class="p">()</span>
</pre></div>
</div>
<p>Single metric evaluation using <code class="docutils literal notranslate"><span class="pre">cross_validate</span></code></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">cv_results</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">lasso</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">sorted</span><span class="p">(</span><span class="n">cv_results</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="go">[&#39;fit_time&#39;, &#39;score_time&#39;, &#39;test_score&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cv_results</span><span class="p">[</span><span class="s1">&#39;test_score&#39;</span><span class="p">]</span>
<span class="go">array([0.33150734, 0.08022311, 0.03531764])</span>
</pre></div>
</div>
<p>Multiple metric evaluation using <code class="docutils literal notranslate"><span class="pre">cross_validate</span></code>
(please refer the <code class="docutils literal notranslate"><span class="pre">scoring</span></code> parameter doc for more information)</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">lasso</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
<span class="gp">... </span>                        <span class="n">scoring</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;r2&#39;</span><span class="p">,</span> <span class="s1">&#39;neg_mean_squared_error&#39;</span><span class="p">),</span>
<span class="gp">... </span>                        <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="s1">&#39;test_neg_mean_squared_error&#39;</span><span class="p">])</span>
<span class="go">[-3635.5... -3573.3... -6114.7...]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="s1">&#39;train_r2&#39;</span><span class="p">])</span>
<span class="go">[0.28010158 0.39088426 0.22784852]</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.model_selection.cross_val_score" title="sklearn.model_selection.cross_val_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cross_val_score</span></code></a></dt><dd><p>Run cross-validation for single metric evaluation.</p>
</dd>
<dt><a class="reference internal" href="#sklearn.model_selection.cross_val_predict" title="sklearn.model_selection.cross_val_predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cross_val_predict</span></code></a></dt><dd><p>Get predictions from each split of cross-validation for diagnostic purposes.</p>
</dd>
<dt><a class="reference internal" href="sklearn.metrics.html#sklearn.metrics.make_scorer" title="sklearn.metrics.make_scorer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sklearn.metrics.make_scorer</span></code></a></dt><dd><p>Make a scorer from a performance metric or loss function.</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sklearn.model_selection.fit_grid_point">
<span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">fit_grid_point</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">estimator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scorer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">error_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">nan</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">fit_params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.fit_grid_point" title="Permalink to this definition">¶</a></dt>
<dd><p>DEPRECATED: fit_grid_point is deprecated in version 0.23 and will be removed in version 1.0 (renaming of 0.25)</p>
<p>Run fit on one set of parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like</em><em>, </em><em>sparse matrix</em><em> or </em><em>list</em>) – Input data.</p></li>
<li><p><strong>y</strong> (<em>array-like</em><em> or </em><em>None</em>) – Targets for input data.</p></li>
<li><p><strong>estimator</strong> (<em>estimator object</em>) – A object of that type is instantiated for each grid point.
This is assumed to implement the scikit-learn estimator interface.
Either estimator needs to provide a <code class="docutils literal notranslate"><span class="pre">score</span></code> function,
or <code class="docutils literal notranslate"><span class="pre">scoring</span></code> must be passed.</p></li>
<li><p><strong>parameters</strong> (<em>dict</em>) – Parameters to be set on estimator for this grid point.</p></li>
<li><p><strong>train</strong> (<em>ndarray</em><em>, </em><em>dtype int</em><em> or </em><em>bool</em>) – Boolean mask or indices for training set.</p></li>
<li><p><strong>test</strong> (<em>ndarray</em><em>, </em><em>dtype int</em><em> or </em><em>bool</em>) – Boolean mask or indices for test set.</p></li>
<li><p><strong>scorer</strong> (<em>callable</em><em> or </em><em>None</em>) – <p>The scorer callable object / function must have its signature as
<code class="docutils literal notranslate"><span class="pre">scorer(estimator,</span> <span class="pre">X,</span> <span class="pre">y)</span></code>.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">None</span></code> the estimator’s score method is used.</p>
</p></li>
<li><p><strong>verbose</strong> (<em>int</em>) – Verbosity level.</p></li>
<li><p><strong>**fit_params</strong> (<em>kwargs</em>) – Additional parameter passed to the fit function of the estimator.</p></li>
<li><p><strong>error_score</strong> (<em>'raise'</em><em> or </em><em>numeric</em><em>, </em><em>default=np.nan</em>) – Value to assign to the score if an error occurs in estimator fitting.
If set to ‘raise’, the error is raised. If a numeric value is given,
FitFailedWarning is raised. This parameter does not affect the refit
step, which will always raise the error.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>score</strong> (<em>float</em>) – Score of this parameter setting on given test split.</p></li>
<li><p><strong>parameters</strong> (<em>dict</em>) – The parameters that have been evaluated.</p></li>
<li><p><strong>n_samples_test</strong> (<em>int</em>) – Number of test samples in this split.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sklearn.model_selection.learning_curve">
<span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">learning_curve</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">estimator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_sizes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">array([0.1,</span> <span class="pre">0.325,</span> <span class="pre">0.55,</span> <span class="pre">0.775,</span> <span class="pre">1.0])</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exploit_incremental_learning</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_dispatch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'all'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">error_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">nan</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_times</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fit_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.learning_curve" title="Permalink to this definition">¶</a></dt>
<dd><p>Learning curve.</p>
<p>Determines cross-validated training and test scores for different training
set sizes.</p>
<p>A cross-validation generator splits the whole dataset k times in training
and test data. Subsets of the training set with varying sizes will be used
to train the estimator and a score for each training subset size and the
test set will be computed. Afterwards, the scores will be averaged over
all k runs for each training subset size.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>object type that implements the &quot;fit&quot; and &quot;predict&quot; methods</em>) – An object of that type which is cloned for each validation.</p></li>
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Training vector, where n_samples is the number of samples and
n_features is the number of features.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or </em><em>(</em><em>n_samples</em><em>, </em><em>n_outputs</em><em>)</em>) – Target relative to X for classification or regression;
None for unsupervised learning.</p></li>
<li><p><strong>groups</strong> (<em>array-like of  shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – Group labels for the samples used while splitting the dataset into
train/test set. Only used in conjunction with a “Group” <span class="xref std std-term">cv</span>
instance (e.g., <a class="reference internal" href="#sklearn.model_selection.GroupKFold" title="sklearn.model_selection.GroupKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">GroupKFold</span></code></a>).</p></li>
<li><p><strong>train_sizes</strong> (<em>array-like of shape</em><em> (</em><em>n_ticks</em><em>,</em><em>)</em><em>,             </em><em>default=np.linspace</em><em>(</em><em>0.1</em><em>, </em><em>1.0</em><em>, </em><em>5</em><em>)</em>) – Relative or absolute numbers of training examples that will be used to
generate the learning curve. If the dtype is float, it is regarded as a
fraction of the maximum size of the training set (that is determined
by the selected validation method), i.e. it has to be within (0, 1].
Otherwise it is interpreted as absolute sizes of the training sets.
Note that for classification the number of samples usually have to
be big enough to contain at least one sample from each class.</p></li>
<li><p><strong>cv</strong> (<em>int</em><em>, </em><em>cross-validation generator</em><em> or </em><em>an iterable</em><em>, </em><em>default=None</em>) – <p>Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul>
<li><p>None, to use the default 5-fold cross validation,</p></li>
<li><p>int, to specify the number of folds in a <cite>(Stratified)KFold</cite>,</p></li>
<li><p><span class="xref std std-term">CV splitter</span>,</p></li>
<li><p>An iterable yielding (train, test) splits as arrays of indices.</p></li>
</ul>
<p>For int/None inputs, if the estimator is a classifier and <code class="docutils literal notranslate"><span class="pre">y</span></code> is
either binary or multiclass, <a class="reference internal" href="#sklearn.model_selection.StratifiedKFold" title="sklearn.model_selection.StratifiedKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">StratifiedKFold</span></code></a> is used. In all
other cases, <a class="reference internal" href="#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> is used. These splitters are instantiated
with <cite>shuffle=False</cite> so the splits will be the same across calls.</p>
<p>Refer <span class="xref std std-ref">User Guide</span> for the various
cross-validation strategies that can be used here.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.22: </span><code class="docutils literal notranslate"><span class="pre">cv</span></code> default value if None changed from 3-fold to 5-fold.</p>
</div>
</p></li>
<li><p><strong>scoring</strong> (<em>str</em><em> or </em><em>callable</em><em>, </em><em>default=None</em>) – A str (see model evaluation documentation) or
a scorer callable object / function with signature
<code class="docutils literal notranslate"><span class="pre">scorer(estimator,</span> <span class="pre">X,</span> <span class="pre">y)</span></code>.</p></li>
<li><p><strong>exploit_incremental_learning</strong> (<em>bool</em><em>, </em><em>default=False</em>) – If the estimator supports incremental learning, this will be
used to speed up fitting for different training set sizes.</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default=None</em>) – Number of jobs to run in parallel. Training the estimator and computing
the score are parallelized over the different training and test sets.
<code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a <code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context.
<code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all processors. See <span class="xref std std-term">Glossary</span>
for more details.</p></li>
<li><p><strong>pre_dispatch</strong> (<em>int</em><em> or </em><em>str</em><em>, </em><em>default='all'</em>) – Number of predispatched jobs for parallel execution (default is
all). The option can reduce the allocated memory. The str can
be an expression like ‘2*n_jobs’.</p></li>
<li><p><strong>verbose</strong> (<em>int</em><em>, </em><em>default=0</em>) – Controls the verbosity: the higher, the more messages.</p></li>
<li><p><strong>shuffle</strong> (<em>bool</em><em>, </em><em>default=False</em>) – Whether to shuffle training data before taking prefixes of it
based on``train_sizes``.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Used when <code class="docutils literal notranslate"><span class="pre">shuffle</span></code> is True. Pass an int for reproducible
output across multiple function calls.
See <span class="xref std std-term">Glossary</span>.</p></li>
<li><p><strong>error_score</strong> (<em>'raise'</em><em> or </em><em>numeric</em><em>, </em><em>default=np.nan</em>) – <p>Value to assign to the score if an error occurs in estimator fitting.
If set to ‘raise’, the error is raised.
If a numeric value is given, FitFailedWarning is raised.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.20.</span></p>
</div>
</p></li>
<li><p><strong>return_times</strong> (<em>bool</em><em>, </em><em>default=False</em>) – Whether to return the fit and score times.</p></li>
<li><p><strong>fit_params</strong> (<em>dict</em><em>, </em><em>default=None</em>) – <p>Parameters to pass to the fit method of the estimator.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>train_sizes_abs</strong> (<em>array of shape (n_unique_ticks,)</em>) – Numbers of training examples that has been used to generate the
learning curve. Note that the number of ticks might be less
than n_ticks because duplicate entries will be removed.</p></li>
<li><p><strong>train_scores</strong> (<em>array of shape (n_ticks, n_cv_folds)</em>) – Scores on training sets.</p></li>
<li><p><strong>test_scores</strong> (<em>array of shape (n_ticks, n_cv_folds)</em>) – Scores on test set.</p></li>
<li><p><strong>fit_times</strong> (<em>array of shape (n_ticks, n_cv_folds)</em>) – Times spent for fitting in seconds. Only present if <code class="docutils literal notranslate"><span class="pre">return_times</span></code>
is True.</p></li>
<li><p><strong>score_times</strong> (<em>array of shape (n_ticks, n_cv_folds)</em>) – Times spent for scoring in seconds. Only present if <code class="docutils literal notranslate"><span class="pre">return_times</span></code>
is True.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>See <span class="xref std std-ref">examples/model_selection/plot_learning_curve.py</span></p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sklearn.model_selection.permutation_test_score">
<span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">permutation_test_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">estimator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_permutations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fit_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.permutation_test_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the significance of a cross-validated score with permutations</p>
<p>Permutes targets to generate ‘randomized data’ and compute the empirical
p-value against the null hypothesis that features and targets are
independent.</p>
<p>The p-value represents the fraction of randomized data sets where the
estimator performed as well or better than in the original data. A small
p-value suggests that there is a real dependency between features and
targets which has been used by the estimator to give good predictions.
A large p-value may be due to lack of real dependency between features
and targets or the estimator was not able to use the dependency to
give good predictions.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>estimator object implementing 'fit'</em>) – The object to use to fit the data.</p></li>
<li><p><strong>X</strong> (<em>array-like of shape at least 2D</em>) – The data to fit.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or </em><em>(</em><em>n_samples</em><em>, </em><em>n_outputs</em><em>) or </em><em>None</em>) – The target variable to try to predict in the case of
supervised learning.</p></li>
<li><p><strong>groups</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – <p>Labels to constrain permutation within groups, i.e. <code class="docutils literal notranslate"><span class="pre">y</span></code> values
are permuted among samples with the same group identifier.
When not specified, <code class="docutils literal notranslate"><span class="pre">y</span></code> values are permuted among all samples.</p>
<p>When a grouped cross-validator is used, the group labels are
also passed on to the <code class="docutils literal notranslate"><span class="pre">split</span></code> method of the cross-validator. The
cross-validator uses them for grouping the samples  while splitting
the dataset into train/test set.</p>
</p></li>
<li><p><strong>scoring</strong> (<em>str</em><em> or </em><em>callable</em><em>, </em><em>default=None</em>) – <p>A single str (see <span class="xref std std-ref">scoring_parameter</span>) or a callable
(see <span class="xref std std-ref">scoring</span>) to evaluate the predictions on the test set.</p>
<p>If None the estimator’s score method is used.</p>
</p></li>
<li><p><strong>cv</strong> (<em>int</em><em>, </em><em>cross-validation generator</em><em> or </em><em>an iterable</em><em>, </em><em>default=None</em>) – <p>Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul>
<li><p>None, to use the default 5-fold cross validation,</p></li>
<li><p>int, to specify the number of folds in a <cite>(Stratified)KFold</cite>,</p></li>
<li><p><span class="xref std std-term">CV splitter</span>,</p></li>
<li><p>An iterable yielding (train, test) splits as arrays of indices.</p></li>
</ul>
<p>For int/None inputs, if the estimator is a classifier and <code class="docutils literal notranslate"><span class="pre">y</span></code> is
either binary or multiclass, <a class="reference internal" href="#sklearn.model_selection.StratifiedKFold" title="sklearn.model_selection.StratifiedKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">StratifiedKFold</span></code></a> is used. In all
other cases, <a class="reference internal" href="#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> is used. These splitters are instantiated
with <cite>shuffle=False</cite> so the splits will be the same across calls.</p>
<p>Refer <span class="xref std std-ref">User Guide</span> for the various
cross-validation strategies that can be used here.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.22: </span><code class="docutils literal notranslate"><span class="pre">cv</span></code> default value if None changed from 3-fold to 5-fold.</p>
</div>
</p></li>
<li><p><strong>n_permutations</strong> (<em>int</em><em>, </em><em>default=100</em>) – Number of times to permute <code class="docutils literal notranslate"><span class="pre">y</span></code>.</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default=None</em>) – Number of jobs to run in parallel. Training the estimator and computing
the cross-validated score are parallelized over the permutations.
<code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a <code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context.
<code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all processors. See <span class="xref std std-term">Glossary</span>
for more details.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=0</em>) – Pass an int for reproducible output for permutation of
<code class="docutils literal notranslate"><span class="pre">y</span></code> values among samples. See <span class="xref std std-term">Glossary</span>.</p></li>
<li><p><strong>verbose</strong> (<em>int</em><em>, </em><em>default=0</em>) – The verbosity level.</p></li>
<li><p><strong>fit_params</strong> (<em>dict</em><em>, </em><em>default=None</em>) – <p>Parameters to pass to the fit method of the estimator.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul>
<li><p><strong>score</strong> (<em>float</em>) – The true score without permuting targets.</p></li>
<li><p><strong>permutation_scores</strong> (<em>array of shape (n_permutations,)</em>) – The scores obtained for each permutations.</p></li>
<li><p><strong>pvalue</strong> (<em>float</em>) – The p-value, which approximates the probability that the score would
be obtained by chance. This is calculated as:</p>
<p><cite>(C + 1) / (n_permutations + 1)</cite></p>
<p>Where C is the number of permutations whose score &gt;= the true score.</p>
<p>The best possible p-value is 1/(n_permutations + 1), the worst is 1.0.</p>
</li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This function implements Test 1 in:</p>
<blockquote>
<div><p>Ojala and Garriga. <a class="reference external" href="http://www.jmlr.org/papers/volume11/ojala10a/ojala10a.pdf">Permutation Tests for Studying Classifier
Performance</a>. The
Journal of Machine Learning Research (2010) vol. 11</p>
</div></blockquote>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sklearn.model_selection.train_test_split">
<span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">train_test_split</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">arrays</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stratify</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.train_test_split" title="Permalink to this definition">¶</a></dt>
<dd><p>Split arrays or matrices into random train and test subsets</p>
<p>Quick utility that wraps input validation and
<code class="docutils literal notranslate"><span class="pre">next(ShuffleSplit().split(X,</span> <span class="pre">y))</span></code> and application to input data
into a single call for splitting (and optionally subsampling) data in a
oneliner.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*arrays</strong> (<em>sequence of indexables with same length / shape</em><em>[</em><em>0</em><em>]</em>) – Allowed inputs are lists, numpy arrays, scipy-sparse
matrices or pandas dataframes.</p></li>
<li><p><strong>test_size</strong> (<em>float</em><em> or </em><em>int</em><em>, </em><em>default=None</em>) – If float, should be between 0.0 and 1.0 and represent the proportion
of the dataset to include in the test split. If int, represents the
absolute number of test samples. If None, the value is set to the
complement of the train size. If <code class="docutils literal notranslate"><span class="pre">train_size</span></code> is also None, it will
be set to 0.25.</p></li>
<li><p><strong>train_size</strong> (<em>float</em><em> or </em><em>int</em><em>, </em><em>default=None</em>) – If float, should be between 0.0 and 1.0 and represent the
proportion of the dataset to include in the train split. If
int, represents the absolute number of train samples. If None,
the value is automatically set to the complement of the test size.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Controls the shuffling applied to the data before applying the split.
Pass an int for reproducible output across multiple function calls.
See <span class="xref std std-term">Glossary</span>.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>shuffle<span class="classifier">bool, default=True</span></dt><dd><p>Whether or not to shuffle the data before splitting. If shuffle=False
then stratify must be None.</p>
</dd>
<dt>stratify<span class="classifier">array-like, default=None</span></dt><dd><p>If not None, data is split in a stratified fashion, using this as
the class labels.
Read more in the <span class="xref std std-ref">User Guide</span>.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><p><strong>splitting</strong> – List containing train-test split of inputs.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.16: </span>If the input is sparse, the output will be a
<code class="docutils literal notranslate"><span class="pre">scipy.sparse.csr_matrix</span></code>. Else, output type is the same as the
input type.</p>
</div>
</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>list, length=2 * len(arrays)</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span>
<span class="go">array([[0, 1],</span>
<span class="go">       [2, 3],</span>
<span class="go">       [4, 5],</span>
<span class="go">       [6, 7],</span>
<span class="go">       [8, 9]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">list</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="go">[0, 1, 2, 3, 4]</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.33</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span>
<span class="go">array([[4, 5],</span>
<span class="go">       [0, 1],</span>
<span class="go">       [6, 7]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_train</span>
<span class="go">[2, 0, 3]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_test</span>
<span class="go">array([[2, 3],</span>
<span class="go">       [8, 9]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_test</span>
<span class="go">[1, 4]</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_test_split</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">[[0, 1, 2], [3, 4]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sklearn.model_selection.validation_curve">
<span class="sig-prename descclassname"><span class="pre">sklearn.model_selection.</span></span><span class="sig-name descname"><span class="pre">validation_curve</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">estimator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_range</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_dispatch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'all'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">error_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">nan</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fit_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.model_selection.validation_curve" title="Permalink to this definition">¶</a></dt>
<dd><p>Validation curve.</p>
<p>Determine training and test scores for varying parameter values.</p>
<p>Compute scores for an estimator with different values of a specified
parameter. This is similar to grid search with one parameter. However, this
will also compute training scores and is merely a utility for plotting the
results.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>object type that implements the &quot;fit&quot; and &quot;predict&quot; methods</em>) – An object of that type which is cloned for each validation.</p></li>
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Training vector, where n_samples is the number of samples and
n_features is the number of features.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or </em><em>(</em><em>n_samples</em><em>, </em><em>n_outputs</em><em>) or </em><em>None</em>) – Target relative to X for classification or regression;
None for unsupervised learning.</p></li>
<li><p><strong>param_name</strong> (<em>str</em>) – Name of the parameter that will be varied.</p></li>
<li><p><strong>param_range</strong> (<em>array-like of shape</em><em> (</em><em>n_values</em><em>,</em><em>)</em>) – The values of the parameter that will be evaluated.</p></li>
<li><p><strong>groups</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – Group labels for the samples used while splitting the dataset into
train/test set. Only used in conjunction with a “Group” <span class="xref std std-term">cv</span>
instance (e.g., <a class="reference internal" href="#sklearn.model_selection.GroupKFold" title="sklearn.model_selection.GroupKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">GroupKFold</span></code></a>).</p></li>
<li><p><strong>cv</strong> (<em>int</em><em>, </em><em>cross-validation generator</em><em> or </em><em>an iterable</em><em>, </em><em>default=None</em>) – <p>Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul>
<li><p>None, to use the default 5-fold cross validation,</p></li>
<li><p>int, to specify the number of folds in a <cite>(Stratified)KFold</cite>,</p></li>
<li><p><span class="xref std std-term">CV splitter</span>,</p></li>
<li><p>An iterable yielding (train, test) splits as arrays of indices.</p></li>
</ul>
<p>For int/None inputs, if the estimator is a classifier and <code class="docutils literal notranslate"><span class="pre">y</span></code> is
either binary or multiclass, <a class="reference internal" href="#sklearn.model_selection.StratifiedKFold" title="sklearn.model_selection.StratifiedKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">StratifiedKFold</span></code></a> is used. In all
other cases, <a class="reference internal" href="#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> is used. These splitters are instantiated
with <cite>shuffle=False</cite> so the splits will be the same across calls.</p>
<p>Refer <span class="xref std std-ref">User Guide</span> for the various
cross-validation strategies that can be used here.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.22: </span><code class="docutils literal notranslate"><span class="pre">cv</span></code> default value if None changed from 3-fold to 5-fold.</p>
</div>
</p></li>
<li><p><strong>scoring</strong> (<em>str</em><em> or </em><em>callable</em><em>, </em><em>default=None</em>) – A str (see model evaluation documentation) or
a scorer callable object / function with signature
<code class="docutils literal notranslate"><span class="pre">scorer(estimator,</span> <span class="pre">X,</span> <span class="pre">y)</span></code>.</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default=None</em>) – Number of jobs to run in parallel. Training the estimator and computing
the score are parallelized over the combinations of each parameter
value and each cross-validation split.
<code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a <code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context.
<code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all processors. See <span class="xref std std-term">Glossary</span>
for more details.</p></li>
<li><p><strong>pre_dispatch</strong> (<em>int</em><em> or </em><em>str</em><em>, </em><em>default='all'</em>) – Number of predispatched jobs for parallel execution (default is
all). The option can reduce the allocated memory. The str can
be an expression like ‘2*n_jobs’.</p></li>
<li><p><strong>verbose</strong> (<em>int</em><em>, </em><em>default=0</em>) – Controls the verbosity: the higher, the more messages.</p></li>
<li><p><strong>fit_params</strong> (<em>dict</em><em>, </em><em>default=None</em>) – <p>Parameters to pass to the fit method of the estimator.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
</p></li>
<li><p><strong>error_score</strong> (<em>'raise'</em><em> or </em><em>numeric</em><em>, </em><em>default=np.nan</em>) – <p>Value to assign to the score if an error occurs in estimator fitting.
If set to ‘raise’, the error is raised.
If a numeric value is given, FitFailedWarning is raised.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.20.</span></p>
</div>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>train_scores</strong> (<em>array of shape (n_ticks, n_cv_folds)</em>) – Scores on training sets.</p></li>
<li><p><strong>test_scores</strong> (<em>array of shape (n_ticks, n_cv_folds)</em>) – Scores on test set.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>See <span class="xref std std-ref">sphx_glr_auto_examples_model_selection_plot_validation_curve.py</span></p>
</dd></dl>

</section>
</section>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, Tommaso Fioravanti

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>