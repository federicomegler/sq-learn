

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>sklearn.preprocessing package &mdash; sqlearn  documentation</title>
  

  
  
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> sqlearn
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="modules.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="modules.html#requirements">Requirements</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">sqlearn</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>sklearn.preprocessing package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/tommasofioravanti/SafeStreet/blob/sklearn.preprocessing.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="sklearn-preprocessing-package">
<h1>sklearn.preprocessing package<a class="headerlink" href="#sklearn-preprocessing-package" title="Permalink to this headline">¶</a></h1>
<section id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="sklearn.preprocessing.tests.html">sklearn.preprocessing.tests package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="sklearn.preprocessing.tests.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.preprocessing.tests.html#sklearn-preprocessing-tests-test-common-module">sklearn.preprocessing.tests.test_common module</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.preprocessing.tests.html#sklearn-preprocessing-tests-test-data-module">sklearn.preprocessing.tests.test_data module</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.preprocessing.tests.html#sklearn-preprocessing-tests-test-discretization-module">sklearn.preprocessing.tests.test_discretization module</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.preprocessing.tests.html#sklearn-preprocessing-tests-test-encoders-module">sklearn.preprocessing.tests.test_encoders module</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.preprocessing.tests.html#sklearn-preprocessing-tests-test-function-transformer-module">sklearn.preprocessing.tests.test_function_transformer module</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.preprocessing.tests.html#sklearn-preprocessing-tests-test-label-module">sklearn.preprocessing.tests.test_label module</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.preprocessing.tests.html#sklearn-preprocessing-tests-test-polynomial-module">sklearn.preprocessing.tests.test_polynomial module</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.preprocessing.tests.html#module-sklearn.preprocessing.tests">Module contents</a></li>
</ul>
</li>
</ul>
</div>
</section>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</section>
<section id="module-sklearn.preprocessing.setup">
<span id="sklearn-preprocessing-setup-module"></span><h2>sklearn.preprocessing.setup module<a class="headerlink" href="#module-sklearn.preprocessing.setup" title="Permalink to this headline">¶</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="sklearn.preprocessing.setup.configuration">
<span class="sig-name descname"><span class="pre">configuration</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parent_package</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.setup.configuration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</section>
<section id="module-sklearn.preprocessing">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-sklearn.preprocessing" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-sklearn.preprocessing" title="sklearn.preprocessing"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.preprocessing</span></code></a> module includes scaling, centering,
normalization, binarization methods.</p>
<dl class="py class">
<dt class="sig sig-object py" id="sklearn.preprocessing.Binarizer">
<em class="property"><span class="pre">class</span> </em><span class="sig-name descname"><span class="pre">Binarizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.Binarizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.TransformerMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.BaseEstimator</span></code></p>
<p>Binarize data (set feature values to 0 or 1) according to a threshold.</p>
<p>Values greater than the threshold map to 1, while values less than
or equal to the threshold map to 0. With the default threshold of 0,
only positive values map to 1.</p>
<p>Binarization is a common operation on text count data where the
analyst can decide to only consider the presence or absence of a
feature rather than a quantified number of occurrences for instance.</p>
<p>It can also be used as a pre-processing step for estimators that
consider boolean random variables (e.g. modelled using the Bernoulli
distribution in a Bayesian setting).</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>threshold</strong> (<em>float</em><em>, </em><em>default=0.0</em>) – Feature values below or equal to this are replaced by 0, above it by 1.
Threshold may not be less than 0 for operations on sparse matrices.</p></li>
<li><p><strong>copy</strong> (<em>bool</em><em>, </em><em>default=True</em>) – set to False to perform inplace binarization and avoid a copy (if
the input is already a numpy array or a scipy.sparse CSR matrix).</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">Binarizer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
<span class="gp">... </span>     <span class="p">[</span> <span class="mf">2.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>     <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transformer</span> <span class="o">=</span> <span class="n">Binarizer</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>  <span class="c1"># fit does nothing.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transformer</span>
<span class="go">Binarizer()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transformer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([[1., 0., 1.],</span>
<span class="go">       [1., 0., 0.],</span>
<span class="go">       [0., 1., 0.]])</span>
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>If the input is a sparse matrix, only the non-zero values are subject
to update by the Binarizer class.</p>
<p>This estimator is stateless (besides constructor parameters), the
fit method does nothing but is useful when used in a pipeline.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.preprocessing.binarize" title="sklearn.preprocessing.binarize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">binarize</span></code></a></dt><dd><p>Equivalent function without the estimator API.</p>
</dd>
</dl>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.Binarizer.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.Binarizer.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Do nothing and return the estimator unchanged.</p>
<p>This method is just there to implement the usual API and hence
work in pipelines.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data.</p></li>
<li><p><strong>y</strong> (<em>None</em>) – Ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – Fitted transformer.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.Binarizer.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.Binarizer.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Binarize each element of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data to binarize, element by element.
scipy.sparse matrices should be in CSR format to avoid an
un-necessary copy.</p></li>
<li><p><strong>copy</strong> (<em>bool</em>) – Copy the input X or not.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_tr</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>{ndarray, sparse matrix} of shape (n_samples, n_features)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.preprocessing.FunctionTransformer">
<em class="property"><span class="pre">class</span> </em><span class="sig-name descname"><span class="pre">FunctionTransformer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inverse_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">accept_sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_inverse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kw_args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inv_kw_args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.FunctionTransformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.TransformerMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.BaseEstimator</span></code></p>
<p>Constructs a transformer from an arbitrary callable.</p>
<p>A FunctionTransformer forwards its X (and optionally y) arguments to a
user-defined function or function object and returns the result of this
function. This is useful for stateless transformations such as taking the
log of frequencies, doing custom scaling, etc.</p>
<p>Note: If a lambda is used as the function, then the resulting
transformer will not be pickleable.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.17.</span></p>
</div>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>func</strong> (<em>callable</em><em>, </em><em>default=None</em>) – The callable to use for the transformation. This will be passed
the same arguments as transform, with args and kwargs forwarded.
If func is None, then func will be the identity function.</p></li>
<li><p><strong>inverse_func</strong> (<em>callable</em><em>, </em><em>default=None</em>) – The callable to use for the inverse transformation. This will be
passed the same arguments as inverse transform, with args and
kwargs forwarded. If inverse_func is None, then inverse_func
will be the identity function.</p></li>
<li><p><strong>validate</strong> (<em>bool</em><em>, </em><em>default=False</em>) – <p>Indicate that the input X array should be checked before calling
<code class="docutils literal notranslate"><span class="pre">func</span></code>. The possibilities are:</p>
<ul>
<li><p>If False, there is no input validation.</p></li>
<li><p>If True, then X will be converted to a 2-dimensional NumPy array or
sparse matrix. If the conversion is not possible an exception is
raised.</p></li>
</ul>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.22: </span>The default of <code class="docutils literal notranslate"><span class="pre">validate</span></code> changed from True to False.</p>
</div>
</p></li>
<li><p><strong>accept_sparse</strong> (<em>bool</em><em>, </em><em>default=False</em>) – Indicate that func accepts a sparse matrix as input. If validate is
False, this has no effect. Otherwise, if accept_sparse is false,
sparse matrix inputs will cause an exception to be raised.</p></li>
<li><p><strong>check_inverse</strong> (<em>bool</em><em>, </em><em>default=True</em>) – <p>Whether to check that or <code class="docutils literal notranslate"><span class="pre">func</span></code> followed by <code class="docutils literal notranslate"><span class="pre">inverse_func</span></code> leads to
the original inputs. It can be used for a sanity check, raising a
warning when the condition is not fulfilled.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.20.</span></p>
</div>
</p></li>
<li><p><strong>kw_args</strong> (<em>dict</em><em>, </em><em>default=None</em>) – <p>Dictionary of additional keyword arguments to pass to func.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.18.</span></p>
</div>
</p></li>
<li><p><strong>inv_kw_args</strong> (<em>dict</em><em>, </em><em>default=None</em>) – <p>Dictionary of additional keyword arguments to pass to inverse_func.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.18.</span></p>
</div>
</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">FunctionTransformer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transformer</span> <span class="o">=</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log1p</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transformer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([[0.       , 0.6931...],</span>
<span class="go">       [1.0986..., 1.3862...]])</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.FunctionTransformer.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.FunctionTransformer.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit transformer by checking X.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">validate</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, <code class="docutils literal notranslate"><span class="pre">X</span></code> will be checked.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Input array.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>self</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.FunctionTransformer.inverse_transform">
<span class="sig-name descname"><span class="pre">inverse_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.FunctionTransformer.inverse_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform X using the inverse function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Input array.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_out</strong> – Transformed input.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array-like, shape (n_samples, n_features)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.FunctionTransformer.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.FunctionTransformer.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform X using the forward function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Input array.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_out</strong> – Transformed input.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array-like, shape (n_samples, n_features)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.preprocessing.KBinsDiscretizer">
<em class="property"><span class="pre">class</span> </em><span class="sig-name descname"><span class="pre">KBinsDiscretizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_bins</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'onehot'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'quantile'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.KBinsDiscretizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.TransformerMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.BaseEstimator</span></code></p>
<p>Bin continuous data into intervals.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.20.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_bins</strong> (<em>int</em><em> or </em><em>array-like of shape</em><em> (</em><em>n_features</em><em>,</em><em>)</em><em>, </em><em>default=5</em>) – The number of bins to produce. Raises ValueError if <code class="docutils literal notranslate"><span class="pre">n_bins</span> <span class="pre">&lt;</span> <span class="pre">2</span></code>.</p></li>
<li><p><strong>encode</strong> (<em>{'onehot'</em><em>, </em><em>'onehot-dense'</em><em>, </em><em>'ordinal'}</em><em>, </em><em>default='onehot'</em>) – <p>Method used to encode the transformed result.</p>
<dl class="simple">
<dt>onehot</dt><dd><p>Encode the transformed result with one-hot encoding
and return a sparse matrix. Ignored features are always
stacked to the right.</p>
</dd>
<dt>onehot-dense</dt><dd><p>Encode the transformed result with one-hot encoding
and return a dense array. Ignored features are always
stacked to the right.</p>
</dd>
<dt>ordinal</dt><dd><p>Return the bin identifier encoded as an integer value.</p>
</dd>
</dl>
</p></li>
<li><p><strong>strategy</strong> (<em>{'uniform'</em><em>, </em><em>'quantile'</em><em>, </em><em>'kmeans'}</em><em>, </em><em>default='quantile'</em>) – <p>Strategy used to define the widths of the bins.</p>
<dl class="simple">
<dt>uniform</dt><dd><p>All bins in each feature have identical widths.</p>
</dd>
<dt>quantile</dt><dd><p>All bins in each feature have the same number of points.</p>
</dd>
<dt>kmeans</dt><dd><p>Values in each bin have the same nearest center of a 1D k-means
cluster.</p>
</dd>
</dl>
</p></li>
<li><p><strong>dtype</strong> (<em>{np.float32</em><em>, </em><em>np.float64}</em><em>, </em><em>default=None</em>) – <p>The desired data-type for the output. If None, output dtype is
consistent with input dtype. Only np.float32 and np.float64 are
supported.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.KBinsDiscretizer.n_bins_">
<span class="sig-name descname"><span class="pre">n_bins_</span></span><a class="headerlink" href="#sklearn.preprocessing.KBinsDiscretizer.n_bins_" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of bins per feature. Bins whose width are too small
(i.e., &lt;= 1e-8) are removed with a warning.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray of shape (n_features,), dtype=np.int_</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.KBinsDiscretizer.bin_edges_">
<span class="sig-name descname"><span class="pre">bin_edges_</span></span><a class="headerlink" href="#sklearn.preprocessing.KBinsDiscretizer.bin_edges_" title="Permalink to this definition">¶</a></dt>
<dd><p>The edges of each bin. Contain arrays of varying shapes <code class="docutils literal notranslate"><span class="pre">(n_bins_,</span> <span class="pre">)</span></code>
Ignored features will have empty arrays.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray of ndarray of shape (n_features,)</p>
</dd>
</dl>
</dd></dl>

<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.preprocessing.Binarizer" title="sklearn.preprocessing.Binarizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Binarizer</span></code></a></dt><dd><p>Class used to bin values as <code class="docutils literal notranslate"><span class="pre">0</span></code> or <code class="docutils literal notranslate"><span class="pre">1</span></code> based on a parameter <code class="docutils literal notranslate"><span class="pre">threshold</span></code>.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>In bin edges for feature <code class="docutils literal notranslate"><span class="pre">i</span></code>, the first and last values are used only for
<code class="docutils literal notranslate"><span class="pre">inverse_transform</span></code>. During transform, bin edges are extended to:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">bin_edges_</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">])</span>
</pre></div>
</div>
<p>You can combine <code class="docutils literal notranslate"><span class="pre">KBinsDiscretizer</span></code> with
<a class="reference internal" href="sklearn.compose.html#sklearn.compose.ColumnTransformer" title="sklearn.compose.ColumnTransformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">ColumnTransformer</span></code></a> if you only want to preprocess
part of the features.</p>
<p><code class="docutils literal notranslate"><span class="pre">KBinsDiscretizer</span></code> might produce constant features (e.g., when
<code class="docutils literal notranslate"><span class="pre">encode</span> <span class="pre">=</span> <span class="pre">'onehot'</span></code> and certain bins do not contain any data).
These features can be removed with feature selection algorithms
(e.g., <a class="reference internal" href="sklearn.feature_selection.html#sklearn.feature_selection.VarianceThreshold" title="sklearn.feature_selection.VarianceThreshold"><code class="xref py py-class docutils literal notranslate"><span class="pre">VarianceThreshold</span></code></a>).</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">4</span><span class="p">,</span>   <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>     <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">],</span>
<span class="gp">... </span>     <span class="p">[</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span>  <span class="mf">0.5</span><span class="p">],</span>
<span class="gp">... </span>     <span class="p">[</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>    <span class="mi">2</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">est</span> <span class="o">=</span> <span class="n">KBinsDiscretizer</span><span class="p">(</span><span class="n">n_bins</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">encode</span><span class="o">=</span><span class="s1">&#39;ordinal&#39;</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">est</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">KBinsDiscretizer(...)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xt</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xt</span>  
<span class="go">array([[ 0., 0., 0., 0.],</span>
<span class="go">       [ 1., 1., 1., 0.],</span>
<span class="go">       [ 2., 2., 2., 1.],</span>
<span class="go">       [ 2., 2., 2., 2.]])</span>
</pre></div>
</div>
<p>Sometimes it may be useful to convert the data back into the original
feature space. The <code class="docutils literal notranslate"><span class="pre">inverse_transform</span></code> function converts the binned
data into the original feature space. Each value will be equal to the mean
of the two bin edges.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">est</span><span class="o">.</span><span class="n">bin_edges_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">array([-2., -1.,  0.,  1.])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">est</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">Xt</span><span class="p">)</span>
<span class="go">array([[-1.5,  1.5, -3.5, -0.5],</span>
<span class="go">       [-0.5,  2.5, -2.5, -0.5],</span>
<span class="go">       [ 0.5,  3.5, -1.5,  0.5],</span>
<span class="go">       [ 0.5,  3.5, -1.5,  1.5]])</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.KBinsDiscretizer.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.KBinsDiscretizer.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Data to be discretized.</p></li>
<li><p><strong>y</strong> (<em>None</em>) – Ignored. This parameter exists only for compatibility with
<code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>self</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.KBinsDiscretizer.inverse_transform">
<span class="sig-name descname"><span class="pre">inverse_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Xt</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.KBinsDiscretizer.inverse_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform discretized data back to original feature space.</p>
<p>Note that this function does not regenerate the original data
due to discretization rounding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>Xt</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Transformed data in the binned space.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Xinv</strong> – Data in the original feature space.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray, dtype={np.float32, np.float64}</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.KBinsDiscretizer.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.KBinsDiscretizer.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Discretize the data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Data to be discretized.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Xt</strong> – Data in the binned space. Will be a sparse matrix if
<cite>self.encode=’onehot’</cite> and ndarray otherwise.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>{ndarray, sparse matrix}, dtype={np.float32, np.float64}</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.preprocessing.KernelCenterer">
<em class="property"><span class="pre">class</span> </em><span class="sig-name descname"><span class="pre">KernelCenterer</span></span><a class="headerlink" href="#sklearn.preprocessing.KernelCenterer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.TransformerMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.BaseEstimator</span></code></p>
<p>Center a kernel matrix.</p>
<p>Let K(x, z) be a kernel defined by phi(x)^T phi(z), where phi is a
function mapping x to a Hilbert space. KernelCenterer centers (i.e.,
normalize to have zero mean) the data without explicitly computing phi(x).
It is equivalent to centering phi(x) with
sklearn.preprocessing.StandardScaler(with_std=False).</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.KernelCenterer.K_fit_rows_">
<span class="sig-name descname"><span class="pre">K_fit_rows_</span></span><a class="headerlink" href="#sklearn.preprocessing.KernelCenterer.K_fit_rows_" title="Permalink to this definition">¶</a></dt>
<dd><p>Average of each column of kernel matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array of shape (n_samples,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.KernelCenterer.K_fit_all_">
<span class="sig-name descname"><span class="pre">K_fit_all_</span></span><a class="headerlink" href="#sklearn.preprocessing.KernelCenterer.K_fit_all_" title="Permalink to this definition">¶</a></dt>
<dd><p>Average of kernel matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">KernelCenterer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">pairwise_kernels</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
<span class="gp">... </span>     <span class="p">[</span> <span class="o">-</span><span class="mf">2.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">],</span>
<span class="gp">... </span>     <span class="p">[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">K</span> <span class="o">=</span> <span class="n">pairwise_kernels</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">K</span>
<span class="go">array([[  9.,   2.,  -2.],</span>
<span class="go">       [  2.,  14., -13.],</span>
<span class="go">       [ -2., -13.,  21.]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transformer</span> <span class="o">=</span> <span class="n">KernelCenterer</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">K</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transformer</span>
<span class="go">KernelCenterer()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transformer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">K</span><span class="p">)</span>
<span class="go">array([[  5.,   0.,  -5.],</span>
<span class="go">       [  0.,  14., -14.],</span>
<span class="go">       [ -5., -14.,  19.]])</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.KernelCenterer.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">K</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.KernelCenterer.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit KernelCenterer</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>K</strong> (<em>ndarray of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_samples</em><em>)</em>) – Kernel matrix.</p></li>
<li><p><strong>y</strong> (<em>None</em>) – Ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – Fitted transformer.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.KernelCenterer.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">K</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.KernelCenterer.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Center kernel matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>K</strong> (<em>ndarray of shape</em><em> (</em><em>n_samples1</em><em>, </em><em>n_samples2</em><em>)</em>) – Kernel matrix.</p></li>
<li><p><strong>copy</strong> (<em>bool</em><em>, </em><em>default=True</em>) – Set to False to perform inplace computation.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>K_new</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray of shape (n_samples1, n_samples2)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.preprocessing.LabelBinarizer">
<em class="property"><span class="pre">class</span> </em><span class="sig-name descname"><span class="pre">LabelBinarizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neg_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pos_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse_output</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.LabelBinarizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.TransformerMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.BaseEstimator</span></code></p>
<p>Binarize labels in a one-vs-all fashion.</p>
<p>Several regression and binary classification algorithms are
available in scikit-learn. A simple way to extend these algorithms
to the multi-class classification case is to use the so-called
one-vs-all scheme.</p>
<p>At learning time, this simply consists in learning one regressor
or binary classifier per class. In doing so, one needs to convert
multi-class labels to binary labels (belong or does not belong
to the class). LabelBinarizer makes this process easy with the
transform method.</p>
<p>At prediction time, one assigns the class for which the corresponding
model gave the greatest confidence. LabelBinarizer makes this easy
with the inverse_transform method.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neg_label</strong> (<em>int</em><em>, </em><em>default=0</em>) – Value with which negative labels must be encoded.</p></li>
<li><p><strong>pos_label</strong> (<em>int</em><em>, </em><em>default=1</em>) – Value with which positive labels must be encoded.</p></li>
<li><p><strong>sparse_output</strong> (<em>bool</em><em>, </em><em>default=False</em>) – True if the returned array from transform is desired to be in sparse
CSR format.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.LabelBinarizer.classes_">
<span class="sig-name descname"><span class="pre">classes_</span></span><a class="headerlink" href="#sklearn.preprocessing.LabelBinarizer.classes_" title="Permalink to this definition">¶</a></dt>
<dd><p>Holds the label for each class.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray of shape (n_classes,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.LabelBinarizer.y_type_">
<span class="sig-name descname"><span class="pre">y_type_</span></span><a class="headerlink" href="#sklearn.preprocessing.LabelBinarizer.y_type_" title="Permalink to this definition">¶</a></dt>
<dd><p>Represents the type of the target data as evaluated by
utils.multiclass.type_of_target. Possible type are ‘continuous’,
‘continuous-multioutput’, ‘binary’, ‘multiclass’,
‘multiclass-multioutput’, ‘multilabel-indicator’, and ‘unknown’.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.LabelBinarizer.sparse_input_">
<span class="sig-name descname"><span class="pre">sparse_input_</span></span><a class="headerlink" href="#sklearn.preprocessing.LabelBinarizer.sparse_input_" title="Permalink to this definition">¶</a></dt>
<dd><p>True if the input data to transform is given as a sparse matrix, False
otherwise.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lb</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">LabelBinarizer</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lb</span><span class="o">.</span><span class="n">fit</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="go">LabelBinarizer()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lb</span><span class="o">.</span><span class="n">classes_</span>
<span class="go">array([1, 2, 4, 6])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lb</span><span class="o">.</span><span class="n">transform</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="go">array([[1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1]])</span>
</pre></div>
</div>
<p>Binary targets transform to a column vector</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">lb</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">LabelBinarizer</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lb</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">([</span><span class="s1">&#39;yes&#39;</span><span class="p">,</span> <span class="s1">&#39;no&#39;</span><span class="p">,</span> <span class="s1">&#39;no&#39;</span><span class="p">,</span> <span class="s1">&#39;yes&#39;</span><span class="p">])</span>
<span class="go">array([[1],</span>
<span class="go">       [0],</span>
<span class="go">       [0],</span>
<span class="go">       [1]])</span>
</pre></div>
</div>
<p>Passing a 2D matrix for multilabel classification</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]))</span>
<span class="go">LabelBinarizer()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lb</span><span class="o">.</span><span class="n">classes_</span>
<span class="go">array([0, 1, 2])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lb</span><span class="o">.</span><span class="n">transform</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="go">array([[1, 0, 0],</span>
<span class="go">       [0, 1, 0],</span>
<span class="go">       [0, 0, 1],</span>
<span class="go">       [0, 1, 0]])</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.preprocessing.label_binarize" title="sklearn.preprocessing.label_binarize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">label_binarize</span></code></a></dt><dd><p>Function to perform the transform operation of LabelBinarizer with fixed classes.</p>
</dd>
<dt><a class="reference internal" href="#sklearn.preprocessing.OneHotEncoder" title="sklearn.preprocessing.OneHotEncoder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">OneHotEncoder</span></code></a></dt><dd><p>Encode categorical features using a one-hot aka one-of-K scheme.</p>
</dd>
</dl>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.LabelBinarizer.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.LabelBinarizer.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit label binarizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>y</strong> (<em>ndarray of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or </em><em>(</em><em>n_samples</em><em>, </em><em>n_classes</em><em>)</em>) – Target values. The 2-d matrix should only contain 0 and 1,
represents multilabel classification.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>returns an instance of self.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.LabelBinarizer.fit_transform">
<span class="sig-name descname"><span class="pre">fit_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.LabelBinarizer.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit label binarizer and transform multi-class labels to binary
labels.</p>
<p>The output of transform is sometimes referred to as
the 1-of-K coding scheme.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>y</strong> (<em>{ndarray</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or                 </em><em>(</em><em>n_samples</em><em>, </em><em>n_classes</em><em>)</em>) – Target values. The 2-d matrix should only contain 0 and 1,
represents multilabel classification. Sparse matrix can be
CSR, CSC, COO, DOK, or LIL.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Y</strong> – Shape will be (n_samples, 1) for binary problems. Sparse matrix
will be of CSR format.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>{ndarray, sparse matrix} of shape (n_samples, n_classes)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.LabelBinarizer.inverse_transform">
<span class="sig-name descname"><span class="pre">inverse_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.LabelBinarizer.inverse_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform binary labels back to multi-class labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>{ndarray</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_classes</em><em>)</em>) – Target values. All sparse matrices are converted to CSR before
inverse transformation.</p></li>
<li><p><strong>threshold</strong> (<em>float</em><em>, </em><em>default=None</em>) – <p>Threshold used in the binary and multi-label cases.</p>
<p>Use 0 when <code class="docutils literal notranslate"><span class="pre">Y</span></code> contains the output of decision_function
(classifier).
Use 0.5 when <code class="docutils literal notranslate"><span class="pre">Y</span></code> contains the output of predict_proba.</p>
<p>If None, the threshold is assumed to be half way between
neg_label and pos_label.</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> – Target values. Sparse matrix will be of CSR format.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>{ndarray, sparse matrix} of shape (n_samples,)</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>In the case when the binary labels are fractional
(probabilistic), inverse_transform chooses the class with the
greatest value. Typically, this allows to use the output of a
linear model’s decision_function method directly as the input
of inverse_transform.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.LabelBinarizer.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.LabelBinarizer.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform multi-class labels to binary labels.</p>
<p>The output of transform is sometimes referred to by some authors as
the 1-of-K coding scheme.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>y</strong> (<em>{array</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or                 </em><em>(</em><em>n_samples</em><em>, </em><em>n_classes</em><em>)</em>) – Target values. The 2-d matrix should only contain 0 and 1,
represents multilabel classification. Sparse matrix can be
CSR, CSC, COO, DOK, or LIL.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Y</strong> – Shape will be (n_samples, 1) for binary problems. Sparse matrix
will be of CSR format.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>{ndarray, sparse matrix} of shape (n_samples, n_classes)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.preprocessing.LabelEncoder">
<em class="property"><span class="pre">class</span> </em><span class="sig-name descname"><span class="pre">LabelEncoder</span></span><a class="headerlink" href="#sklearn.preprocessing.LabelEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.TransformerMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.BaseEstimator</span></code></p>
<p>Encode target labels with value between 0 and n_classes-1.</p>
<p>This transformer should be used to encode target values, <em>i.e.</em> <cite>y</cite>, and
not the input <cite>X</cite>.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.12.</span></p>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.LabelEncoder.classes_">
<span class="sig-name descname"><span class="pre">classes_</span></span><a class="headerlink" href="#sklearn.preprocessing.LabelEncoder.classes_" title="Permalink to this definition">¶</a></dt>
<dd><p>Holds the label for each class.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray of shape (n_classes,)</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<p><cite>LabelEncoder</cite> can be used to normalize labels.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">le</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">LabelEncoder</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">le</span><span class="o">.</span><span class="n">fit</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="go">LabelEncoder()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span>
<span class="go">array([1, 2, 6])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">le</span><span class="o">.</span><span class="n">transform</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="go">array([0, 0, 1, 2]...)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">le</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="go">array([1, 1, 2, 6])</span>
</pre></div>
</div>
<p>It can also be used to transform non-numerical labels (as long as they are
hashable and comparable) to numerical labels.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">le</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">LabelEncoder</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">le</span><span class="o">.</span><span class="n">fit</span><span class="p">([</span><span class="s2">&quot;paris&quot;</span><span class="p">,</span> <span class="s2">&quot;paris&quot;</span><span class="p">,</span> <span class="s2">&quot;tokyo&quot;</span><span class="p">,</span> <span class="s2">&quot;amsterdam&quot;</span><span class="p">])</span>
<span class="go">LabelEncoder()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">list</span><span class="p">(</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>
<span class="go">[&#39;amsterdam&#39;, &#39;paris&#39;, &#39;tokyo&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">le</span><span class="o">.</span><span class="n">transform</span><span class="p">([</span><span class="s2">&quot;tokyo&quot;</span><span class="p">,</span> <span class="s2">&quot;tokyo&quot;</span><span class="p">,</span> <span class="s2">&quot;paris&quot;</span><span class="p">])</span>
<span class="go">array([2, 2, 1]...)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">list</span><span class="p">(</span><span class="n">le</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>
<span class="go">[&#39;tokyo&#39;, &#39;tokyo&#39;, &#39;paris&#39;]</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.preprocessing.OrdinalEncoder" title="sklearn.preprocessing.OrdinalEncoder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">OrdinalEncoder</span></code></a></dt><dd><p>Encode categorical features using an ordinal encoding scheme.</p>
</dd>
<dt><a class="reference internal" href="#sklearn.preprocessing.OneHotEncoder" title="sklearn.preprocessing.OneHotEncoder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">OneHotEncoder</span></code></a></dt><dd><p>Encode categorical features as a one-hot numeric array.</p>
</dd>
</dl>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.LabelEncoder.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.LabelEncoder.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit label encoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Target values.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>returns an instance of self.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.LabelEncoder.fit_transform">
<span class="sig-name descname"><span class="pre">fit_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.LabelEncoder.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit label encoder and return encoded labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Target values.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array-like of shape (n_samples,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.LabelEncoder.inverse_transform">
<span class="sig-name descname"><span class="pre">inverse_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.LabelEncoder.inverse_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform labels back to original encoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>y</strong> (<em>ndarray of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Target values.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray of shape (n_samples,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.LabelEncoder.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.LabelEncoder.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform labels to normalized encoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – Target values.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array-like of shape (n_samples,)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.preprocessing.MaxAbsScaler">
<em class="property"><span class="pre">class</span> </em><span class="sig-name descname"><span class="pre">MaxAbsScaler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.MaxAbsScaler" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.TransformerMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.BaseEstimator</span></code></p>
<p>Scale each feature by its maximum absolute value.</p>
<p>This estimator scales and translates each feature individually such
that the maximal absolute value of each feature in the
training set will be 1.0. It does not shift/center the data, and
thus does not destroy any sparsity.</p>
<p>This scaler can also be applied to sparse CSR or CSC matrices.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.17.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>copy</strong> (<em>bool</em><em>, </em><em>default=True</em>) – Set to False to perform inplace scaling and avoid a copy (if the input
is already a numpy array).</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.MaxAbsScaler.scale_">
<span class="sig-name descname"><span class="pre">scale_</span></span><a class="headerlink" href="#sklearn.preprocessing.MaxAbsScaler.scale_" title="Permalink to this definition">¶</a></dt>
<dd><p>Per feature relative scaling of the data.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.17: </span><em>scale_</em> attribute.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray of shape (n_features,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.MaxAbsScaler.max_abs_">
<span class="sig-name descname"><span class="pre">max_abs_</span></span><a class="headerlink" href="#sklearn.preprocessing.MaxAbsScaler.max_abs_" title="Permalink to this definition">¶</a></dt>
<dd><p>Per feature maximum absolute value.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray of shape (n_features,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.MaxAbsScaler.n_samples_seen_">
<span class="sig-name descname"><span class="pre">n_samples_seen_</span></span><a class="headerlink" href="#sklearn.preprocessing.MaxAbsScaler.n_samples_seen_" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of samples processed by the estimator. Will be reset on
new calls to fit, but increments across <code class="docutils literal notranslate"><span class="pre">partial_fit</span></code> calls.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MaxAbsScaler</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
<span class="gp">... </span>     <span class="p">[</span> <span class="mf">2.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>     <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transformer</span> <span class="o">=</span> <span class="n">MaxAbsScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transformer</span>
<span class="go">MaxAbsScaler()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transformer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([[ 0.5, -1. ,  1. ],</span>
<span class="go">       [ 1. ,  0. ,  0. ],</span>
<span class="go">       [ 0. ,  1. , -0.5]])</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.preprocessing.maxabs_scale" title="sklearn.preprocessing.maxabs_scale"><code class="xref py py-obj docutils literal notranslate"><span class="pre">maxabs_scale</span></code></a></dt><dd><p>Equivalent function without the estimator API.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>NaNs are treated as missing values: disregarded in fit, and maintained in
transform.</p>
<p>For a comparison of the different scalers, transformers, and normalizers,
see <span class="xref std std-ref">examples/preprocessing/plot_all_scaling.py</span>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.MaxAbsScaler.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.MaxAbsScaler.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the maximum absolute value to be used for later scaling.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data used to compute the per-feature minimum and maximum
used for later scaling along the features axis.</p></li>
<li><p><strong>y</strong> (<em>None</em>) – Ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – Fitted scaler.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.MaxAbsScaler.inverse_transform">
<span class="sig-name descname"><span class="pre">inverse_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.MaxAbsScaler.inverse_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Scale back the data to the original representation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data that should be transformed back.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_tr</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>{ndarray, sparse matrix} of shape (n_samples, n_features)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.MaxAbsScaler.partial_fit">
<span class="sig-name descname"><span class="pre">partial_fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.MaxAbsScaler.partial_fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Online computation of max absolute value of X for later scaling.</p>
<p>All of X is processed as a single batch. This is intended for cases
when <a class="reference internal" href="#sklearn.preprocessing.MaxAbsScaler.fit" title="sklearn.preprocessing.MaxAbsScaler.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> is not feasible due to very large number of
<cite>n_samples</cite> or because X is read from a continuous stream.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data used to compute the mean and standard deviation
used for later scaling along the features axis.</p></li>
<li><p><strong>y</strong> (<em>None</em>) – Ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – Fitted scaler.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.MaxAbsScaler.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.MaxAbsScaler.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Scale the data</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data that should be scaled.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_tr</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>{ndarray, sparse matrix} of shape (n_samples, n_features)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.preprocessing.MinMaxScaler">
<em class="property"><span class="pre">class</span> </em><span class="sig-name descname"><span class="pre">MinMaxScaler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feature_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0,</span> <span class="pre">1)</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.MinMaxScaler" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.TransformerMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.BaseEstimator</span></code></p>
<p>Transform features by scaling each feature to a given range.</p>
<p>This estimator scales and translates each feature individually such
that it is in the given range on the training set, e.g. between
zero and one.</p>
<p>The transformation is given by:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X_std</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">X</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="n">X</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="n">X_scaled</span> <span class="o">=</span> <span class="n">X_std</span> <span class="o">*</span> <span class="p">(</span><span class="nb">max</span> <span class="o">-</span> <span class="nb">min</span><span class="p">)</span> <span class="o">+</span> <span class="nb">min</span>
</pre></div>
</div>
<p>where min, max = feature_range.</p>
<p>This transformation is often used as an alternative to zero mean,
unit variance scaling.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature_range</strong> (<em>tuple</em><em> (</em><em>min</em><em>, </em><em>max</em><em>)</em><em>, </em><em>default=</em><em>(</em><em>0</em><em>, </em><em>1</em><em>)</em>) – Desired range of transformed data.</p></li>
<li><p><strong>copy</strong> (<em>bool</em><em>, </em><em>default=True</em>) – Set to False to perform inplace row normalization and avoid a
copy (if the input is already a numpy array).</p></li>
<li><p><strong>clip</strong> (<em>bool</em><em>, </em><em>default=False</em>) – <p>Set to True to clip transformed values of held-out data to
provided <cite>feature range</cite>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.MinMaxScaler.min_">
<span class="sig-name descname"><span class="pre">min_</span></span><a class="headerlink" href="#sklearn.preprocessing.MinMaxScaler.min_" title="Permalink to this definition">¶</a></dt>
<dd><p>Per feature adjustment for minimum. Equivalent to
<code class="docutils literal notranslate"><span class="pre">min</span> <span class="pre">-</span> <span class="pre">X.min(axis=0)</span> <span class="pre">*</span> <span class="pre">self.scale_</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray of shape (n_features,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.MinMaxScaler.scale_">
<span class="sig-name descname"><span class="pre">scale_</span></span><a class="headerlink" href="#sklearn.preprocessing.MinMaxScaler.scale_" title="Permalink to this definition">¶</a></dt>
<dd><p>Per feature relative scaling of the data. Equivalent to
<code class="docutils literal notranslate"><span class="pre">(max</span> <span class="pre">-</span> <span class="pre">min)</span> <span class="pre">/</span> <span class="pre">(X.max(axis=0)</span> <span class="pre">-</span> <span class="pre">X.min(axis=0))</span></code></p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.17: </span><em>scale_</em> attribute.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray of shape (n_features,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.MinMaxScaler.data_min_">
<span class="sig-name descname"><span class="pre">data_min_</span></span><a class="headerlink" href="#sklearn.preprocessing.MinMaxScaler.data_min_" title="Permalink to this definition">¶</a></dt>
<dd><p>Per feature minimum seen in the data</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.17: </span><em>data_min_</em></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray of shape (n_features,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.MinMaxScaler.data_max_">
<span class="sig-name descname"><span class="pre">data_max_</span></span><a class="headerlink" href="#sklearn.preprocessing.MinMaxScaler.data_max_" title="Permalink to this definition">¶</a></dt>
<dd><p>Per feature maximum seen in the data</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.17: </span><em>data_max_</em></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray of shape (n_features,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.MinMaxScaler.data_range_">
<span class="sig-name descname"><span class="pre">data_range_</span></span><a class="headerlink" href="#sklearn.preprocessing.MinMaxScaler.data_range_" title="Permalink to this definition">¶</a></dt>
<dd><p>Per feature range <code class="docutils literal notranslate"><span class="pre">(data_max_</span> <span class="pre">-</span> <span class="pre">data_min_)</span></code> seen in the data</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.17: </span><em>data_range_</em></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray of shape (n_features,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.MinMaxScaler.n_samples_seen_">
<span class="sig-name descname"><span class="pre">n_samples_seen_</span></span><a class="headerlink" href="#sklearn.preprocessing.MinMaxScaler.n_samples_seen_" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of samples processed by the estimator.
It will be reset on new calls to fit, but increments across
<code class="docutils literal notranslate"><span class="pre">partial_fit</span></code> calls.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">18</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
<span class="go">MinMaxScaler()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">data_max_</span><span class="p">)</span>
<span class="go">[ 1. 18.]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
<span class="go">[[0.   0.  ]</span>
<span class="go"> [0.25 0.25]</span>
<span class="go"> [0.5  0.5 ]</span>
<span class="go"> [1.   1.  ]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]))</span>
<span class="go">[[1.5 0. ]]</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.preprocessing.minmax_scale" title="sklearn.preprocessing.minmax_scale"><code class="xref py py-obj docutils literal notranslate"><span class="pre">minmax_scale</span></code></a></dt><dd><p>Equivalent function without the estimator API.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>NaNs are treated as missing values: disregarded in fit, and maintained in
transform.</p>
<p>For a comparison of the different scalers, transformers, and normalizers,
see <span class="xref std std-ref">examples/preprocessing/plot_all_scaling.py</span>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.MinMaxScaler.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.MinMaxScaler.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the minimum and maximum to be used for later scaling.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data used to compute the per-feature minimum and maximum
used for later scaling along the features axis.</p></li>
<li><p><strong>y</strong> (<em>None</em>) – Ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – Fitted scaler.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.MinMaxScaler.inverse_transform">
<span class="sig-name descname"><span class="pre">inverse_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.MinMaxScaler.inverse_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Undo the scaling of X according to feature_range.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Input data that will be transformed. It cannot be sparse.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Xt</strong> – Transformed data.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray of shape (n_samples, n_features)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.MinMaxScaler.partial_fit">
<span class="sig-name descname"><span class="pre">partial_fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.MinMaxScaler.partial_fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Online computation of min and max on X for later scaling.</p>
<p>All of X is processed as a single batch. This is intended for cases
when <a class="reference internal" href="#sklearn.preprocessing.MinMaxScaler.fit" title="sklearn.preprocessing.MinMaxScaler.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> is not feasible due to very large number of
<cite>n_samples</cite> or because X is read from a continuous stream.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data used to compute the mean and standard deviation
used for later scaling along the features axis.</p></li>
<li><p><strong>y</strong> (<em>None</em>) – Ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – Fitted scaler.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.MinMaxScaler.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.MinMaxScaler.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Scale features of X according to feature_range.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Input data that will be transformed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Xt</strong> – Transformed data.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray of shape (n_samples, n_features)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.preprocessing.MultiLabelBinarizer">
<em class="property"><span class="pre">class</span> </em><span class="sig-name descname"><span class="pre">MultiLabelBinarizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse_output</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.MultiLabelBinarizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.TransformerMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.BaseEstimator</span></code></p>
<p>Transform between iterable of iterables and a multilabel format.</p>
<p>Although a list of sets or tuples is a very intuitive format for multilabel
data, it is unwieldy to process. This transformer converts between this
intuitive format and the supported multilabel format: a (samples x classes)
binary matrix indicating the presence of a class label.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classes</strong> (<em>array-like of shape</em><em> (</em><em>n_classes</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – Indicates an ordering for the class labels.
All entries should be unique (cannot contain duplicate classes).</p></li>
<li><p><strong>sparse_output</strong> (<em>bool</em><em>, </em><em>default=False</em>) – Set to True if output binary array is desired in CSR sparse format.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.MultiLabelBinarizer.classes_">
<span class="sig-name descname"><span class="pre">classes_</span></span><a class="headerlink" href="#sklearn.preprocessing.MultiLabelBinarizer.classes_" title="Permalink to this definition">¶</a></dt>
<dd><p>A copy of the <cite>classes</cite> parameter when provided.
Otherwise it corresponds to the sorted set of classes found
when fitting.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray of shape (n_classes,)</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MultiLabelBinarizer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlb</span> <span class="o">=</span> <span class="n">MultiLabelBinarizer</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlb</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">([(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,)])</span>
<span class="go">array([[1, 1, 0],</span>
<span class="go">       [0, 0, 1]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlb</span><span class="o">.</span><span class="n">classes_</span>
<span class="go">array([1, 2, 3])</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mlb</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">([{</span><span class="s1">&#39;sci-fi&#39;</span><span class="p">,</span> <span class="s1">&#39;thriller&#39;</span><span class="p">},</span> <span class="p">{</span><span class="s1">&#39;comedy&#39;</span><span class="p">}])</span>
<span class="go">array([[0, 1, 1],</span>
<span class="go">       [1, 0, 0]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">list</span><span class="p">(</span><span class="n">mlb</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>
<span class="go">[&#39;comedy&#39;, &#39;sci-fi&#39;, &#39;thriller&#39;]</span>
</pre></div>
</div>
<p>A common mistake is to pass in a list, which leads to the following issue:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mlb</span> <span class="o">=</span> <span class="n">MultiLabelBinarizer</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlb</span><span class="o">.</span><span class="n">fit</span><span class="p">([</span><span class="s1">&#39;sci-fi&#39;</span><span class="p">,</span> <span class="s1">&#39;thriller&#39;</span><span class="p">,</span> <span class="s1">&#39;comedy&#39;</span><span class="p">])</span>
<span class="go">MultiLabelBinarizer()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlb</span><span class="o">.</span><span class="n">classes_</span>
<span class="go">array([&#39;-&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;, &#39;h&#39;, &#39;i&#39;, &#39;l&#39;, &#39;m&#39;, &#39;o&#39;, &#39;r&#39;, &#39;s&#39;, &#39;t&#39;,</span>
<span class="go">    &#39;y&#39;], dtype=object)</span>
</pre></div>
</div>
<p>To correct this, the list of labels should be passed in as:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mlb</span> <span class="o">=</span> <span class="n">MultiLabelBinarizer</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlb</span><span class="o">.</span><span class="n">fit</span><span class="p">([[</span><span class="s1">&#39;sci-fi&#39;</span><span class="p">,</span> <span class="s1">&#39;thriller&#39;</span><span class="p">,</span> <span class="s1">&#39;comedy&#39;</span><span class="p">]])</span>
<span class="go">MultiLabelBinarizer()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlb</span><span class="o">.</span><span class="n">classes_</span>
<span class="go">array([&#39;comedy&#39;, &#39;sci-fi&#39;, &#39;thriller&#39;], dtype=object)</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.preprocessing.OneHotEncoder" title="sklearn.preprocessing.OneHotEncoder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">OneHotEncoder</span></code></a></dt><dd><p>Encode categorical features using a one-hot aka one-of-K scheme.</p>
</dd>
</dl>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.MultiLabelBinarizer.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.MultiLabelBinarizer.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the label sets binarizer, storing <span class="xref std std-term">classes_</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>y</strong> (<em>iterable of iterables</em>) – A set of labels (any orderable and hashable object) for each
sample. If the <cite>classes</cite> parameter is set, <cite>y</cite> will not be
iterated.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>returns this MultiLabelBinarizer instance</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.MultiLabelBinarizer.fit_transform">
<span class="sig-name descname"><span class="pre">fit_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.MultiLabelBinarizer.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the label sets binarizer and transform the given label sets.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>y</strong> (<em>iterable of iterables</em>) – A set of labels (any orderable and hashable object) for each
sample. If the <cite>classes</cite> parameter is set, <cite>y</cite> will not be
iterated.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y_indicator</strong> – A matrix such that <cite>y_indicator[i, j] = 1</cite> i.f.f. <cite>classes_[j]</cite>
is in <cite>y[i]</cite>, and 0 otherwise. Sparse matrix will be of CSR
format.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>{ndarray, sparse matrix} of shape (n_samples, n_classes)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.MultiLabelBinarizer.inverse_transform">
<span class="sig-name descname"><span class="pre">inverse_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">yt</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.MultiLabelBinarizer.inverse_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform the given indicator matrix into label sets.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>yt</strong> (<em>{ndarray</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_classes</em><em>)</em>) – A matrix containing only 1s ands 0s.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> – The set of labels for each sample such that <cite>y[i]</cite> consists of
<cite>classes_[j]</cite> for each <cite>yt[i, j] == 1</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list of tuples</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.MultiLabelBinarizer.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.MultiLabelBinarizer.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform the given label sets.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>y</strong> (<em>iterable of iterables</em>) – A set of labels (any orderable and hashable object) for each
sample. If the <cite>classes</cite> parameter is set, <cite>y</cite> will not be
iterated.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y_indicator</strong> – A matrix such that <cite>y_indicator[i, j] = 1</cite> iff <cite>classes_[j]</cite> is in
<cite>y[i]</cite>, and 0 otherwise.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array or CSR matrix, shape (n_samples, n_classes)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.preprocessing.Normalizer">
<em class="property"><span class="pre">class</span> </em><span class="sig-name descname"><span class="pre">Normalizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'l2'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.Normalizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.TransformerMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.BaseEstimator</span></code></p>
<p>Normalize samples individually to unit norm.</p>
<p>Each sample (i.e. each row of the data matrix) with at least one
non zero component is rescaled independently of other samples so
that its norm (l1, l2 or inf) equals one.</p>
<p>This transformer is able to work both with dense numpy arrays and
scipy.sparse matrix (use CSR format if you want to avoid the burden of
a copy / conversion).</p>
<p>Scaling inputs to unit norms is a common operation for text
classification or clustering for instance. For instance the dot
product of two l2-normalized TF-IDF vectors is the cosine similarity
of the vectors and is the base similarity metric for the Vector
Space Model commonly used by the Information Retrieval community.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>norm</strong> (<em>{'l1'</em><em>, </em><em>'l2'</em><em>, </em><em>'max'}</em><em>, </em><em>default='l2'</em>) – The norm to use to normalize each non zero sample. If norm=’max’
is used, values will be rescaled by the maximum of the absolute
values.</p></li>
<li><p><strong>copy</strong> (<em>bool</em><em>, </em><em>default=True</em>) – set to False to perform inplace row normalization and avoid a
copy (if the input is already a numpy array or a scipy.sparse
CSR matrix).</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">Normalizer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
<span class="gp">... </span>     <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
<span class="gp">... </span>     <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transformer</span> <span class="o">=</span> <span class="n">Normalizer</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>  <span class="c1"># fit does nothing.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transformer</span>
<span class="go">Normalizer()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transformer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([[0.8, 0.2, 0.4, 0.4],</span>
<span class="go">       [0.1, 0.3, 0.9, 0.3],</span>
<span class="go">       [0.5, 0.7, 0.5, 0.1]])</span>
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>This estimator is stateless (besides constructor parameters), the
fit method does nothing but is useful when used in a pipeline.</p>
<p>For a comparison of the different scalers, transformers, and normalizers,
see <span class="xref std std-ref">examples/preprocessing/plot_all_scaling.py</span>.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.preprocessing.normalize" title="sklearn.preprocessing.normalize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">normalize</span></code></a></dt><dd><p>Equivalent function without the estimator API.</p>
</dd>
</dl>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.Normalizer.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.Normalizer.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Do nothing and return the estimator unchanged</p>
<p>This method is just there to implement the usual API and hence
work in pipelines.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data to estimate the normalization parameters.</p></li>
<li><p><strong>y</strong> (<em>None</em>) – Ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – Fitted transformer.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.Normalizer.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.Normalizer.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Scale each non zero row of X to unit norm</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data to normalize, row by row. scipy.sparse matrices should be
in CSR format to avoid an un-necessary copy.</p></li>
<li><p><strong>copy</strong> (<em>bool</em><em>, </em><em>default=None</em>) – Copy the input X or not.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_tr</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>{ndarray, sparse matrix} of shape (n_samples, n_features)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.preprocessing.OneHotEncoder">
<em class="property"><span class="pre">class</span> </em><span class="sig-name descname"><span class="pre">OneHotEncoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">*</span></em>, <em class="sig-param"><span class="pre">categories='auto'</span></em>, <em class="sig-param"><span class="pre">drop=None</span></em>, <em class="sig-param"><span class="pre">sparse=True</span></em>, <em class="sig-param"><span class="pre">dtype=&lt;class</span> <span class="pre">'numpy.float64'&gt;</span></em>, <em class="sig-param"><span class="pre">handle_unknown='error'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.OneHotEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.preprocessing._encoders._BaseEncoder</span></code></p>
<p>Encode categorical features as a one-hot numeric array.</p>
<p>The input to this transformer should be an array-like of integers or
strings, denoting the values taken on by categorical (discrete) features.
The features are encoded using a one-hot (aka ‘one-of-K’ or ‘dummy’)
encoding scheme. This creates a binary column for each category and
returns a sparse matrix or dense array (depending on the <code class="docutils literal notranslate"><span class="pre">sparse</span></code>
parameter)</p>
<p>By default, the encoder derives the categories based on the unique values
in each feature. Alternatively, you can also specify the <cite>categories</cite>
manually.</p>
<p>This encoding is needed for feeding categorical data to many scikit-learn
estimators, notably linear models and SVMs with the standard kernels.</p>
<p>Note: a one-hot encoding of y labels should use a LabelBinarizer
instead.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>categories</strong> (<em>'auto'</em><em> or </em><em>a list of array-like</em><em>, </em><em>default='auto'</em>) – <p>Categories (unique values) per feature:</p>
<ul>
<li><p>’auto’ : Determine categories automatically from the training data.</p></li>
<li><p>list : <code class="docutils literal notranslate"><span class="pre">categories[i]</span></code> holds the categories expected in the ith
column. The passed categories should not mix strings and numeric
values within a single feature, and should be sorted in case of
numeric values.</p></li>
</ul>
<p>The used categories can be found in the <code class="docutils literal notranslate"><span class="pre">categories_</span></code> attribute.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.20.</span></p>
</div>
</p></li>
<li><p><strong>drop</strong> (<em>{'first'</em><em>, </em><em>'if_binary'}</em><em> or </em><em>a array-like of shape</em><em> (</em><em>n_features</em><em>,</em><em>)</em><em>,             </em><em>default=None</em>) – <p>Specifies a methodology to use to drop one of the categories per
feature. This is useful in situations where perfectly collinear
features cause problems, such as when feeding the resulting data
into a neural network or an unregularized regression.</p>
<p>However, dropping one category breaks the symmetry of the original
representation and can therefore induce a bias in downstream models,
for instance for penalized linear classification or regression models.</p>
<ul>
<li><p>None : retain all features (the default).</p></li>
<li><p>’first’ : drop the first category in each feature. If only one
category is present, the feature will be dropped entirely.</p></li>
<li><p>’if_binary’ : drop the first category in each feature with two
categories. Features with 1 or more than 2 categories are
left intact.</p></li>
<li><p>array : <code class="docutils literal notranslate"><span class="pre">drop[i]</span></code> is the category in feature <code class="docutils literal notranslate"><span class="pre">X[:,</span> <span class="pre">i]</span></code> that
should be dropped.</p></li>
</ul>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.21: </span>The parameter <cite>drop</cite> was added in 0.21.</p>
</div>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.23: </span>The option <cite>drop=’if_binary’</cite> was added in 0.23.</p>
</div>
</p></li>
<li><p><strong>sparse</strong> (<em>bool</em><em>, </em><em>default=True</em>) – Will return sparse matrix if set True else will return an array.</p></li>
<li><p><strong>dtype</strong> (<em>number type</em><em>, </em><em>default=float</em>) – Desired dtype of output.</p></li>
<li><p><strong>handle_unknown</strong> (<em>{'error'</em><em>, </em><em>'ignore'}</em><em>, </em><em>default='error'</em>) – Whether to raise an error or ignore if an unknown categorical feature
is present during transform (default is to raise). When this parameter
is set to ‘ignore’ and an unknown category is encountered during
transform, the resulting one-hot encoded columns for this feature
will be all zeros. In the inverse transform, an unknown category
will be denoted as None.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.OneHotEncoder.categories_">
<span class="sig-name descname"><span class="pre">categories_</span></span><a class="headerlink" href="#sklearn.preprocessing.OneHotEncoder.categories_" title="Permalink to this definition">¶</a></dt>
<dd><p>The categories of each feature determined during fitting
(in order of the features in X and corresponding with the output
of <code class="docutils literal notranslate"><span class="pre">transform</span></code>). This includes the category specified in <code class="docutils literal notranslate"><span class="pre">drop</span></code>
(if any).</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>list of arrays</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.OneHotEncoder.drop_idx_">
<span class="sig-name descname"><span class="pre">drop_idx_</span></span><a class="headerlink" href="#sklearn.preprocessing.OneHotEncoder.drop_idx_" title="Permalink to this definition">¶</a></dt>
<dd><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">drop_idx_[i]</span></code> is the index in <code class="docutils literal notranslate"><span class="pre">categories_[i]</span></code> of the category
to be dropped for each feature.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">drop_idx_[i]</span> <span class="pre">=</span> <span class="pre">None</span></code> if no category is to be dropped from the
feature with index <code class="docutils literal notranslate"><span class="pre">i</span></code>, e.g. when <cite>drop=’if_binary’</cite> and the
feature isn’t binary.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">drop_idx_</span> <span class="pre">=</span> <span class="pre">None</span></code> if all the transformed features will be
retained.</p></li>
</ul>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.23: </span>Added the possibility to contain <cite>None</cite> values.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array of shape (n_features,)</p>
</dd>
</dl>
</dd></dl>

<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.preprocessing.OrdinalEncoder" title="sklearn.preprocessing.OrdinalEncoder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">OrdinalEncoder</span></code></a></dt><dd><p>Performs an ordinal (integer) encoding of the categorical features.</p>
</dd>
<dt><a class="reference internal" href="sklearn.feature_extraction.html#sklearn.feature_extraction.DictVectorizer" title="sklearn.feature_extraction.DictVectorizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sklearn.feature_extraction.DictVectorizer</span></code></a></dt><dd><p>Performs a one-hot encoding of dictionary items (also handles string-valued features).</p>
</dd>
<dt><a class="reference internal" href="sklearn.feature_extraction.html#sklearn.feature_extraction.FeatureHasher" title="sklearn.feature_extraction.FeatureHasher"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sklearn.feature_extraction.FeatureHasher</span></code></a></dt><dd><p>Performs an approximate one-hot encoding of dictionary items or strings.</p>
</dd>
<dt><a class="reference internal" href="#sklearn.preprocessing.LabelBinarizer" title="sklearn.preprocessing.LabelBinarizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LabelBinarizer</span></code></a></dt><dd><p>Binarizes labels in a one-vs-all fashion.</p>
</dd>
<dt><a class="reference internal" href="#sklearn.preprocessing.MultiLabelBinarizer" title="sklearn.preprocessing.MultiLabelBinarizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MultiLabelBinarizer</span></code></a></dt><dd><p>Transforms between iterable of iterables and a multilabel format, e.g. a (samples x classes) binary matrix indicating the presence of a class label.</p>
</dd>
</dl>
</div>
<p class="rubric">Examples</p>
<p>Given a dataset with two features, we let the encoder find the unique
values per feature and transform the data to a binary one-hot encoding.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>
</pre></div>
</div>
<p>One can discard categories not seen during <cite>fit</cite>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">handle_unknown</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;Male&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Female&#39;</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Female&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">OneHotEncoder(handle_unknown=&#39;ignore&#39;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span><span class="o">.</span><span class="n">categories_</span>
<span class="go">[array([&#39;Female&#39;, &#39;Male&#39;], dtype=object), array([1, 2, 3], dtype=object)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span><span class="o">.</span><span class="n">transform</span><span class="p">([[</span><span class="s1">&#39;Female&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Male&#39;</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="go">array([[1., 0., 1., 0., 0.],</span>
<span class="go">       [0., 1., 0., 0., 0.]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="go">array([[&#39;Male&#39;, 1],</span>
<span class="go">       [None, 2]], dtype=object)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">([</span><span class="s1">&#39;gender&#39;</span><span class="p">,</span> <span class="s1">&#39;group&#39;</span><span class="p">])</span>
<span class="go">array([&#39;gender_Female&#39;, &#39;gender_Male&#39;, &#39;group_1&#39;, &#39;group_2&#39;, &#39;group_3&#39;],</span>
<span class="go">  dtype=object)</span>
</pre></div>
</div>
<p>One can always drop the first column for each feature:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">drop_enc</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">drop_enc</span><span class="o">.</span><span class="n">categories_</span>
<span class="go">[array([&#39;Female&#39;, &#39;Male&#39;], dtype=object), array([1, 2, 3], dtype=object)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">drop_enc</span><span class="o">.</span><span class="n">transform</span><span class="p">([[</span><span class="s1">&#39;Female&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Male&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="go">array([[0., 0., 0.],</span>
<span class="go">       [1., 1., 0.]])</span>
</pre></div>
</div>
<p>Or drop a column for feature only having 2 categories:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">drop_binary_enc</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="s1">&#39;if_binary&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">drop_binary_enc</span><span class="o">.</span><span class="n">transform</span><span class="p">([[</span><span class="s1">&#39;Female&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Male&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="go">array([[0., 1., 0., 0.],</span>
<span class="go">       [1., 0., 1., 0.]])</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.OneHotEncoder.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.OneHotEncoder.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit OneHotEncoder to X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data to determine the categories of each feature.</p></li>
<li><p><strong>y</strong> (<em>None</em>) – Ignored. This parameter exists only for compatibility with
<code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>self</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.OneHotEncoder.fit_transform">
<span class="sig-name descname"><span class="pre">fit_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.OneHotEncoder.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit OneHotEncoder to X, then transform X.</p>
<p>Equivalent to fit(X).transform(X) but more convenient.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data to encode.</p></li>
<li><p><strong>y</strong> (<em>None</em>) – Ignored. This parameter exists only for compatibility with
<code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_out</strong> – Transformed input. If <cite>sparse=True</cite>, a sparse matrix will be
returned.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>{ndarray, sparse matrix} of shape                 (n_samples, n_encoded_features)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.OneHotEncoder.get_feature_names">
<span class="sig-name descname"><span class="pre">get_feature_names</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.OneHotEncoder.get_feature_names" title="Permalink to this definition">¶</a></dt>
<dd><p>Return feature names for output features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_features</strong> (<em>list of str of shape</em><em> (</em><em>n_features</em><em>,</em><em>)</em>) – String names for input features if available. By default,
“x0”, “x1”, … “xn_features” is used.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output_feature_names</strong> – Array of feature names.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray of shape (n_output_features,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.OneHotEncoder.inverse_transform">
<span class="sig-name descname"><span class="pre">inverse_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.OneHotEncoder.inverse_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert the data back to the original representation.</p>
<p>When unknown categories are encountered (all zeros in the
one-hot encoding), <code class="docutils literal notranslate"><span class="pre">None</span></code> is used to represent this category. If the
feature with the unknown category has a dropped caregory, the dropped
category will be its inverse.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em>                 (</em><em>n_samples</em><em>, </em><em>n_encoded_features</em><em>)</em>) – The transformed data.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_tr</strong> – Inverse transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray of shape (n_samples, n_features)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.OneHotEncoder.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.OneHotEncoder.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform X using one-hot encoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data to encode.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_out</strong> – Transformed input. If <cite>sparse=True</cite>, a sparse matrix will be
returned.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>{ndarray, sparse matrix} of shape                 (n_samples, n_encoded_features)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.preprocessing.OrdinalEncoder">
<em class="property"><span class="pre">class</span> </em><span class="sig-name descname"><span class="pre">OrdinalEncoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">*</span></em>, <em class="sig-param"><span class="pre">categories='auto'</span></em>, <em class="sig-param"><span class="pre">dtype=&lt;class</span> <span class="pre">'numpy.float64'&gt;</span></em>, <em class="sig-param"><span class="pre">handle_unknown='error'</span></em>, <em class="sig-param"><span class="pre">unknown_value=None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.OrdinalEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.preprocessing._encoders._BaseEncoder</span></code></p>
<p>Encode categorical features as an integer array.</p>
<p>The input to this transformer should be an array-like of integers or
strings, denoting the values taken on by categorical (discrete) features.
The features are converted to ordinal integers. This results in
a single column of integers (0 to n_categories - 1) per feature.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.20.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>categories</strong> (<em>'auto'</em><em> or </em><em>a list of array-like</em><em>, </em><em>default='auto'</em>) – <p>Categories (unique values) per feature:</p>
<ul>
<li><p>’auto’ : Determine categories automatically from the training data.</p></li>
<li><p>list : <code class="docutils literal notranslate"><span class="pre">categories[i]</span></code> holds the categories expected in the ith
column. The passed categories should not mix strings and numeric
values, and should be sorted in case of numeric values.</p></li>
</ul>
<p>The used categories can be found in the <code class="docutils literal notranslate"><span class="pre">categories_</span></code> attribute.</p>
</p></li>
<li><p><strong>dtype</strong> (<em>number type</em><em>, </em><em>default np.float64</em>) – Desired dtype of output.</p></li>
<li><p><strong>handle_unknown</strong> (<em>{'error'</em><em>, </em><em>'use_encoded_value'}</em><em>, </em><em>default='error'</em>) – <p>When set to ‘error’ an error will be raised in case an unknown
categorical feature is present during transform. When set to
‘use_encoded_value’, the encoded value of unknown categories will be
set to the value given for the parameter <cite>unknown_value</cite>. In
<a class="reference internal" href="#sklearn.preprocessing.OrdinalEncoder.inverse_transform" title="sklearn.preprocessing.OrdinalEncoder.inverse_transform"><code class="xref py py-meth docutils literal notranslate"><span class="pre">inverse_transform()</span></code></a>, an unknown category will be denoted as None.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
</p></li>
<li><p><strong>unknown_value</strong> (<em>int</em><em> or </em><em>np.nan</em><em>, </em><em>default=None</em>) – <p>When the parameter handle_unknown is set to ‘use_encoded_value’, this
parameter is required and will set the encoded value of unknown
categories. It has to be distinct from the values used to encode any of
the categories in <cite>fit</cite>. If set to np.nan, the <cite>dtype</cite> parameter must
be a float dtype.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.OrdinalEncoder.categories_">
<span class="sig-name descname"><span class="pre">categories_</span></span><a class="headerlink" href="#sklearn.preprocessing.OrdinalEncoder.categories_" title="Permalink to this definition">¶</a></dt>
<dd><p>The categories of each feature determined during <code class="docutils literal notranslate"><span class="pre">fit</span></code> (in order of
the features in X and corresponding with the output of <code class="docutils literal notranslate"><span class="pre">transform</span></code>).
This does not include categories that weren’t seen during <code class="docutils literal notranslate"><span class="pre">fit</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>list of arrays</p>
</dd>
</dl>
</dd></dl>

<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.preprocessing.OneHotEncoder" title="sklearn.preprocessing.OneHotEncoder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">OneHotEncoder</span></code></a></dt><dd><p>Performs a one-hot encoding of categorical features.</p>
</dd>
<dt><a class="reference internal" href="#sklearn.preprocessing.LabelEncoder" title="sklearn.preprocessing.LabelEncoder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LabelEncoder</span></code></a></dt><dd><p>Encodes target labels with values between 0 and <code class="docutils literal notranslate"><span class="pre">n_classes-1</span></code>.</p>
</dd>
</dl>
</div>
<p class="rubric">Examples</p>
<p>Given a dataset with two features, we let the encoder find the unique
values per feature and transform the data to an ordinal encoding.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OrdinalEncoder</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span> <span class="o">=</span> <span class="n">OrdinalEncoder</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;Male&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Female&#39;</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Female&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">OrdinalEncoder()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span><span class="o">.</span><span class="n">categories_</span>
<span class="go">[array([&#39;Female&#39;, &#39;Male&#39;], dtype=object), array([1, 2, 3], dtype=object)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span><span class="o">.</span><span class="n">transform</span><span class="p">([[</span><span class="s1">&#39;Female&#39;</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Male&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="go">array([[0., 2.],</span>
<span class="go">       [1., 0.]])</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="go">array([[&#39;Male&#39;, 1],</span>
<span class="go">       [&#39;Female&#39;, 2]], dtype=object)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.OrdinalEncoder.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.OrdinalEncoder.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the OrdinalEncoder to X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data to determine the categories of each feature.</p></li>
<li><p><strong>y</strong> (<em>None</em>) – Ignored. This parameter exists only for compatibility with
<code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>self</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.OrdinalEncoder.inverse_transform">
<span class="sig-name descname"><span class="pre">inverse_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.OrdinalEncoder.inverse_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert the data back to the original representation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_encoded_features</em><em>)</em>) – The transformed data.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_tr</strong> – Inverse transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray of shape (n_samples, n_features)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.OrdinalEncoder.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.OrdinalEncoder.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform X to ordinal codes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data to encode.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_out</strong> – Transformed input.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray of shape (n_samples, n_features)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.preprocessing.PolynomialFeatures">
<em class="property"><span class="pre">class</span> </em><span class="sig-name descname"><span class="pre">PolynomialFeatures</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">degree</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interaction_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">order</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'C'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.PolynomialFeatures" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.TransformerMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.BaseEstimator</span></code></p>
<p>Generate polynomial and interaction features.</p>
<p>Generate a new feature matrix consisting of all polynomial combinations
of the features with degree less than or equal to the specified degree.
For example, if an input sample is two dimensional and of the form
[a, b], the degree-2 polynomial features are [1, a, b, a^2, ab, b^2].</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>degree</strong> (<em>int</em><em>, </em><em>default=2</em>) – The degree of the polynomial features.</p></li>
<li><p><strong>interaction_only</strong> (<em>bool</em><em>, </em><em>default=False</em>) – If true, only interaction features are produced: features that are
products of at most <code class="docutils literal notranslate"><span class="pre">degree</span></code> <em>distinct</em> input features (so not
<code class="docutils literal notranslate"><span class="pre">x[1]</span> <span class="pre">**</span> <span class="pre">2</span></code>, <code class="docutils literal notranslate"><span class="pre">x[0]</span> <span class="pre">*</span> <span class="pre">x[2]</span> <span class="pre">**</span> <span class="pre">3</span></code>, etc.).</p></li>
<li><p><strong>include_bias</strong> (<em>bool</em><em>, </em><em>default=True</em>) – If True (default), then include a bias column, the feature in which
all polynomial powers are zero (i.e. a column of ones - acts as an
intercept term in a linear model).</p></li>
<li><p><strong>order</strong> (<em>{'C'</em><em>, </em><em>'F'}</em><em>, </em><em>default='C'</em>) – <p>Order of output array in the dense case. ‘F’ order is faster to
compute, but may slow down subsequent estimators.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.21.</span></p>
</div>
</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span>
<span class="go">array([[0, 1],</span>
<span class="go">       [2, 3],</span>
<span class="go">       [4, 5]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">poly</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">poly</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([[ 1.,  0.,  1.,  0.,  0.,  1.],</span>
<span class="go">       [ 1.,  2.,  3.,  4.,  6.,  9.],</span>
<span class="go">       [ 1.,  4.,  5., 16., 20., 25.]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">poly</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">interaction_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">poly</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([[ 1.,  0.,  1.,  0.],</span>
<span class="go">       [ 1.,  2.,  3.,  6.],</span>
<span class="go">       [ 1.,  4.,  5., 20.]])</span>
</pre></div>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.PolynomialFeatures.powers_">
<span class="sig-name descname"><span class="pre">powers_</span></span><a class="headerlink" href="#sklearn.preprocessing.PolynomialFeatures.powers_" title="Permalink to this definition">¶</a></dt>
<dd><p>powers_[i, j] is the exponent of the jth input in the ith output.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray of shape (n_output_features, n_input_features)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.PolynomialFeatures.n_input_features_">
<span class="sig-name descname"><span class="pre">n_input_features_</span></span><a class="headerlink" href="#sklearn.preprocessing.PolynomialFeatures.n_input_features_" title="Permalink to this definition">¶</a></dt>
<dd><p>The total number of input features.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.PolynomialFeatures.n_output_features_">
<span class="sig-name descname"><span class="pre">n_output_features_</span></span><a class="headerlink" href="#sklearn.preprocessing.PolynomialFeatures.n_output_features_" title="Permalink to this definition">¶</a></dt>
<dd><p>The total number of polynomial output features. The number of output
features is computed by iterating over all suitably sized combinations
of input features.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.preprocessing.SplineTransformer" title="sklearn.preprocessing.SplineTransformer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SplineTransformer</span></code></a></dt><dd><p>Transformer that generates univariate B-spline bases for features</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>Be aware that the number of features in the output array scales
polynomially in the number of features of the input array, and
exponentially in the degree. High degrees can cause overfitting.</p>
<p>See <span class="xref std std-ref">examples/linear_model/plot_polynomial_interpolation.py</span></p>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.PolynomialFeatures.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.PolynomialFeatures.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute number of output features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data.</p></li>
<li><p><strong>y</strong> (<em>None</em>) – Ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – Fitted transformer.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.PolynomialFeatures.get_feature_names">
<span class="sig-name descname"><span class="pre">get_feature_names</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.PolynomialFeatures.get_feature_names" title="Permalink to this definition">¶</a></dt>
<dd><p>Return feature names for output features</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_features</strong> (<em>list of str of shape</em><em> (</em><em>n_features</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – String names for input features if available. By default,
“x0”, “x1”, … “xn_features” is used.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output_feature_names</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list of str of shape (n_output_features,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="id0">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">powers_</span></span><a class="headerlink" href="#id0" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.PolynomialFeatures.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.PolynomialFeatures.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform data to polynomial features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – <p>The data to transform, row by row.</p>
<p>Prefer CSR over CSC for sparse input (for speed), but CSC is
required if the degree is 4 or higher. If the degree is less than
4 and the input format is CSC, it will be converted to CSR, have
its polynomial features generated, then converted back to CSC.</p>
<p>If the degree is 2 or 3, the method described in “Leveraging
Sparsity to Speed Up Polynomial Feature Expansions of CSR Matrices
Using K-Simplex Numbers” by Andrew Nystrom and John Hughes is
used, which is much faster than the method used on CSC input. For
this reason, a CSC input will be converted to CSR, and the output
will be converted back to CSC prior to being returned, hence the
preference of CSR.</p>
</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>XP</strong> – The matrix of features, where NP is the number of polynomial
features generated from the combination of inputs. If a sparse
matrix is provided, it will be converted into a sparse
<code class="docutils literal notranslate"><span class="pre">csr_matrix</span></code>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>{ndarray, sparse matrix} of shape (n_samples, NP)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.preprocessing.PowerTransformer">
<em class="property"><span class="pre">class</span> </em><span class="sig-name descname"><span class="pre">PowerTransformer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'yeo-johnson'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">standardize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.PowerTransformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.TransformerMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.BaseEstimator</span></code></p>
<p>Apply a power transform featurewise to make data more Gaussian-like.</p>
<p>Power transforms are a family of parametric, monotonic transformations
that are applied to make data more Gaussian-like. This is useful for
modeling issues related to heteroscedasticity (non-constant variance),
or other situations where normality is desired.</p>
<p>Currently, PowerTransformer supports the Box-Cox transform and the
Yeo-Johnson transform. The optimal parameter for stabilizing variance and
minimizing skewness is estimated through maximum likelihood.</p>
<p>Box-Cox requires input data to be strictly positive, while Yeo-Johnson
supports both positive or negative data.</p>
<p>By default, zero-mean, unit-variance normalization is applied to the
transformed data.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.20.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>method</strong> (<em>{'yeo-johnson'</em><em>, </em><em>'box-cox'}</em><em>, </em><em>default='yeo-johnson'</em>) – <p>The power transform method. Available methods are:</p>
<ul>
<li><p>’yeo-johnson’ <a href="#id9"><span class="problematic" id="id1">[1]_</span></a>, works with positive and negative values</p></li>
<li><p>’box-cox’ <a href="#id10"><span class="problematic" id="id2">[2]_</span></a>, only works with strictly positive values</p></li>
</ul>
</p></li>
<li><p><strong>standardize</strong> (<em>bool</em><em>, </em><em>default=True</em>) – Set to True to apply zero-mean, unit-variance normalization to the
transformed output.</p></li>
<li><p><strong>copy</strong> (<em>bool</em><em>, </em><em>default=True</em>) – Set to False to perform inplace computation during transformation.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.PowerTransformer.lambdas_">
<span class="sig-name descname"><span class="pre">lambdas_</span></span><a class="headerlink" href="#sklearn.preprocessing.PowerTransformer.lambdas_" title="Permalink to this definition">¶</a></dt>
<dd><p>The parameters of the power transformation for the selected features.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray of float of shape (n_features,)</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PowerTransformer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pt</span> <span class="o">=</span> <span class="n">PowerTransformer</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
<span class="go">PowerTransformer()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">lambdas_</span><span class="p">)</span>
<span class="go">[ 1.386... -3.100...]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
<span class="go">[[-1.316... -0.707...]</span>
<span class="go"> [ 0.209... -0.707...]</span>
<span class="go"> [ 1.106...  1.414...]]</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.preprocessing.power_transform" title="sklearn.preprocessing.power_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">power_transform</span></code></a></dt><dd><p>Equivalent function without the estimator API.</p>
</dd>
<dt><a class="reference internal" href="#sklearn.preprocessing.QuantileTransformer" title="sklearn.preprocessing.QuantileTransformer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">QuantileTransformer</span></code></a></dt><dd><p>Maps data to a standard normal distribution with the parameter <cite>output_distribution=’normal’</cite>.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>NaNs are treated as missing values: disregarded in <code class="docutils literal notranslate"><span class="pre">fit</span></code>, and maintained
in <code class="docutils literal notranslate"><span class="pre">transform</span></code>.</p>
<p>For a comparison of the different scalers, transformers, and normalizers,
see <span class="xref std std-ref">examples/preprocessing/plot_all_scaling.py</span>.</p>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id3"><span class="brackets">1</span></dt>
<dd><p>I.K. Yeo and R.A. Johnson, “A new family of power transformations to
improve normality or symmetry.” Biometrika, 87(4), pp.954-959,
(2000).</p>
</dd>
<dt class="label" id="id4"><span class="brackets">2</span></dt>
<dd><p>G.E.P. Box and D.R. Cox, “An Analysis of Transformations”, Journal
of the Royal Statistical Society B, 26, 211-252 (1964).</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.PowerTransformer.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.PowerTransformer.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimate the optimal parameter lambda for each feature.</p>
<p>The optimal lambda parameter for minimizing skewness is estimated on
each feature independently using maximum likelihood.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data used to estimate the optimal transformation parameters.</p></li>
<li><p><strong>y</strong> (<em>None</em>) – Ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – Fitted transformer.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.PowerTransformer.fit_transform">
<span class="sig-name descname"><span class="pre">fit_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.PowerTransformer.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to <cite>X</cite> and <cite>y</cite> with optional parameters <cite>fit_params</cite>
and returns a transformed version of <cite>X</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Input samples.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or </em><em>(</em><em>n_samples</em><em>, </em><em>n_outputs</em><em>)</em><em>,                 </em><em>default=None</em>) – Target values (None for unsupervised transformations).</p></li>
<li><p><strong>**fit_params</strong> (<em>dict</em>) – Additional fit parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_new</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray array of shape (n_samples, n_features_new)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.PowerTransformer.inverse_transform">
<span class="sig-name descname"><span class="pre">inverse_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.PowerTransformer.inverse_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply the inverse power transformation using the fitted lambdas.</p>
<p>The inverse of the Box-Cox transformation is given by:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">lambda_</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">exp</span><span class="p">(</span><span class="n">X_trans</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">X</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_trans</span> <span class="o">*</span> <span class="n">lambda_</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">lambda_</span><span class="p">)</span>
</pre></div>
</div>
<p>The inverse of the Yeo-Johnson transformation is given by:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">X</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">lambda_</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">exp</span><span class="p">(</span><span class="n">X_trans</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
<span class="k">elif</span> <span class="n">X</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">lambda_</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">X</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_trans</span> <span class="o">*</span> <span class="n">lambda_</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">lambda_</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
<span class="k">elif</span> <span class="n">X</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">lambda_</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
    <span class="n">X</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="mi">2</span> <span class="o">-</span> <span class="n">lambda_</span><span class="p">)</span> <span class="o">*</span> <span class="n">X_trans</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">-</span> <span class="n">lambda_</span><span class="p">))</span>
<span class="k">elif</span> <span class="n">X</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">lambda_</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
    <span class="n">X</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">X_trans</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The transformed data.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X</strong> – The original data.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray of shape (n_samples, n_features)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.PowerTransformer.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.PowerTransformer.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply the power transform to each feature using the fitted lambdas.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data to be transformed using a power transformation.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_trans</strong> – The transformed data.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray of shape (n_samples, n_features)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.preprocessing.QuantileTransformer">
<em class="property"><span class="pre">class</span> </em><span class="sig-name descname"><span class="pre">QuantileTransformer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_quantiles</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_distribution</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'uniform'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_implicit_zeros</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.QuantileTransformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.TransformerMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.BaseEstimator</span></code></p>
<p>Transform features using quantiles information.</p>
<p>This method transforms the features to follow a uniform or a normal
distribution. Therefore, for a given feature, this transformation tends
to spread out the most frequent values. It also reduces the impact of
(marginal) outliers: this is therefore a robust preprocessing scheme.</p>
<p>The transformation is applied on each feature independently. First an
estimate of the cumulative distribution function of a feature is
used to map the original values to a uniform distribution. The obtained
values are then mapped to the desired output distribution using the
associated quantile function. Features values of new/unseen data that fall
below or above the fitted range will be mapped to the bounds of the output
distribution. Note that this transform is non-linear. It may distort linear
correlations between variables measured at the same scale but renders
variables measured at different scales more directly comparable.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.19.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_quantiles</strong> (<em>int</em><em>, </em><em>default=1000</em><em> or </em><em>n_samples</em>) – Number of quantiles to be computed. It corresponds to the number
of landmarks used to discretize the cumulative distribution function.
If n_quantiles is larger than the number of samples, n_quantiles is set
to the number of samples as a larger number of quantiles does not give
a better approximation of the cumulative distribution function
estimator.</p></li>
<li><p><strong>output_distribution</strong> (<em>{'uniform'</em><em>, </em><em>'normal'}</em><em>, </em><em>default='uniform'</em>) – Marginal distribution for the transformed data. The choices are
‘uniform’ (default) or ‘normal’.</p></li>
<li><p><strong>ignore_implicit_zeros</strong> (<em>bool</em><em>, </em><em>default=False</em>) – Only applies to sparse matrices. If True, the sparse entries of the
matrix are discarded to compute the quantile statistics. If False,
these entries are treated as zeros.</p></li>
<li><p><strong>subsample</strong> (<em>int</em><em>, </em><em>default=1e5</em>) – Maximum number of samples used to estimate the quantiles for
computational efficiency. Note that the subsampling procedure may
differ for value-identical sparse and dense matrices.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Determines random number generation for subsampling and smoothing
noise.
Please see <code class="docutils literal notranslate"><span class="pre">subsample</span></code> for more details.
Pass an int for reproducible results across multiple function calls.
See <span class="xref std std-term">Glossary</span></p></li>
<li><p><strong>copy</strong> (<em>bool</em><em>, </em><em>default=True</em>) – Set to False to perform inplace transformation and avoid a copy (if the
input is already a numpy array).</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.QuantileTransformer.n_quantiles_">
<span class="sig-name descname"><span class="pre">n_quantiles_</span></span><a class="headerlink" href="#sklearn.preprocessing.QuantileTransformer.n_quantiles_" title="Permalink to this definition">¶</a></dt>
<dd><p>The actual number of quantiles used to discretize the cumulative
distribution function.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.QuantileTransformer.quantiles_">
<span class="sig-name descname"><span class="pre">quantiles_</span></span><a class="headerlink" href="#sklearn.preprocessing.QuantileTransformer.quantiles_" title="Permalink to this definition">¶</a></dt>
<dd><p>The values corresponding the quantiles of reference.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray of shape (n_quantiles, n_features)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.QuantileTransformer.references_">
<span class="sig-name descname"><span class="pre">references_</span></span><a class="headerlink" href="#sklearn.preprocessing.QuantileTransformer.references_" title="Permalink to this definition">¶</a></dt>
<dd><p>Quantiles of references.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray of shape (n_quantiles, )</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">QuantileTransformer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qt</span> <span class="o">=</span> <span class="n">QuantileTransformer</span><span class="p">(</span><span class="n">n_quantiles</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qt</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([...])</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.preprocessing.quantile_transform" title="sklearn.preprocessing.quantile_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">quantile_transform</span></code></a></dt><dd><p>Equivalent function without the estimator API.</p>
</dd>
<dt><a class="reference internal" href="#sklearn.preprocessing.PowerTransformer" title="sklearn.preprocessing.PowerTransformer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PowerTransformer</span></code></a></dt><dd><p>Perform mapping to a normal distribution using a power transform.</p>
</dd>
<dt><a class="reference internal" href="#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler"><code class="xref py py-obj docutils literal notranslate"><span class="pre">StandardScaler</span></code></a></dt><dd><p>Perform standardization that is faster, but less robust to outliers.</p>
</dd>
<dt><a class="reference internal" href="#sklearn.preprocessing.RobustScaler" title="sklearn.preprocessing.RobustScaler"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RobustScaler</span></code></a></dt><dd><p>Perform robust standardization that removes the influence of outliers but does not put outliers and inliers on the same scale.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>NaNs are treated as missing values: disregarded in fit, and maintained in
transform.</p>
<p>For a comparison of the different scalers, transformers, and normalizers,
see <span class="xref std std-ref">examples/preprocessing/plot_all_scaling.py</span>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.QuantileTransformer.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.QuantileTransformer.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the quantiles used for transforming.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data used to scale along the features axis. If a sparse
matrix is provided, it will be converted into a sparse
<code class="docutils literal notranslate"><span class="pre">csc_matrix</span></code>. Additionally, the sparse matrix needs to be
nonnegative if <cite>ignore_implicit_zeros</cite> is False.</p></li>
<li><p><strong>y</strong> (<em>None</em>) – Ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – Fitted transformer.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.QuantileTransformer.inverse_transform">
<span class="sig-name descname"><span class="pre">inverse_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.QuantileTransformer.inverse_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Back-projection to the original space.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data used to scale along the features axis. If a sparse
matrix is provided, it will be converted into a sparse
<code class="docutils literal notranslate"><span class="pre">csc_matrix</span></code>. Additionally, the sparse matrix needs to be
nonnegative if <cite>ignore_implicit_zeros</cite> is False.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Xt</strong> – The projected data.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>{ndarray, sparse matrix} of (n_samples, n_features)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.QuantileTransformer.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.QuantileTransformer.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Feature-wise transformation of the data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data used to scale along the features axis. If a sparse
matrix is provided, it will be converted into a sparse
<code class="docutils literal notranslate"><span class="pre">csc_matrix</span></code>. Additionally, the sparse matrix needs to be
nonnegative if <cite>ignore_implicit_zeros</cite> is False.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Xt</strong> – The projected data.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>{ndarray, sparse matrix} of shape (n_samples, n_features)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.preprocessing.RobustScaler">
<em class="property"><span class="pre">class</span> </em><span class="sig-name descname"><span class="pre">RobustScaler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_centering</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_scaling</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quantile_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(25.0,</span> <span class="pre">75.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unit_variance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.RobustScaler" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.TransformerMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.BaseEstimator</span></code></p>
<p>Scale features using statistics that are robust to outliers.</p>
<p>This Scaler removes the median and scales the data according to
the quantile range (defaults to IQR: Interquartile Range).
The IQR is the range between the 1st quartile (25th quantile)
and the 3rd quartile (75th quantile).</p>
<p>Centering and scaling happen independently on each feature by
computing the relevant statistics on the samples in the training
set. Median and interquartile range are then stored to be used on
later data using the <code class="docutils literal notranslate"><span class="pre">transform</span></code> method.</p>
<p>Standardization of a dataset is a common requirement for many
machine learning estimators. Typically this is done by removing the mean
and scaling to unit variance. However, outliers can often influence the
sample mean / variance in a negative way. In such cases, the median and
the interquartile range often give better results.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.17.</span></p>
</div>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>with_centering</strong> (<em>bool</em><em>, </em><em>default=True</em>) – If True, center the data before scaling.
This will cause <code class="docutils literal notranslate"><span class="pre">transform</span></code> to raise an exception when attempted on
sparse matrices, because centering them entails building a dense
matrix which in common use cases is likely to be too large to fit in
memory.</p></li>
<li><p><strong>with_scaling</strong> (<em>bool</em><em>, </em><em>default=True</em>) – If True, scale the data to interquartile range.</p></li>
<li><p><strong>quantile_range</strong> (<em>tuple</em><em> (</em><em>q_min</em><em>, </em><em>q_max</em><em>)</em><em>, </em><em>0.0 &lt; q_min &lt; q_max &lt; 100.0</em><em>,         </em><em>default=</em><em>(</em><em>25.0</em><em>, </em><em>75.0</em><em>)</em><em>, </em><em>==</em><em> (</em><em>1st quantile</em><em>, </em><em>3rd quantile</em><em>)</em><em>, </em><em>== IQR</em>) – <p>Quantile range used to calculate <code class="docutils literal notranslate"><span class="pre">scale_</span></code>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.18.</span></p>
</div>
</p></li>
<li><p><strong>copy</strong> (<em>bool</em><em>, </em><em>default=True</em>) – If False, try to avoid a copy and do inplace scaling instead.
This is not guaranteed to always work inplace; e.g. if the data is
not a NumPy array or scipy.sparse CSR matrix, a copy may still be
returned.</p></li>
<li><p><strong>unit_variance</strong> (<em>bool</em><em>, </em><em>default=False</em>) – <p>If True, scale data so that normally distributed features have a
variance of 1. In general, if the difference between the x-values of
<code class="docutils literal notranslate"><span class="pre">q_max</span></code> and <code class="docutils literal notranslate"><span class="pre">q_min</span></code> for a standard normal distribution is greater
than 1, the dataset will be scaled down. If less than 1, the dataset
will be scaled up.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.RobustScaler.center_">
<span class="sig-name descname"><span class="pre">center_</span></span><a class="headerlink" href="#sklearn.preprocessing.RobustScaler.center_" title="Permalink to this definition">¶</a></dt>
<dd><p>The median value for each feature in the training set.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array of floats</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.RobustScaler.scale_">
<span class="sig-name descname"><span class="pre">scale_</span></span><a class="headerlink" href="#sklearn.preprocessing.RobustScaler.scale_" title="Permalink to this definition">¶</a></dt>
<dd><p>The (scaled) interquartile range for each feature in the training set.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.17: </span><em>scale_</em> attribute.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array of floats</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">RobustScaler</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
<span class="gp">... </span>     <span class="p">[</span> <span class="o">-</span><span class="mf">2.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">],</span>
<span class="gp">... </span>     <span class="p">[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transformer</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transformer</span>
<span class="go">RobustScaler()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transformer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([[ 0. , -2. ,  0. ],</span>
<span class="go">       [-1. ,  0. ,  0.4],</span>
<span class="go">       [ 1. ,  0. , -1.6]])</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.preprocessing.robust_scale" title="sklearn.preprocessing.robust_scale"><code class="xref py py-obj docutils literal notranslate"><span class="pre">robust_scale</span></code></a></dt><dd><p>Equivalent function without the estimator API.</p>
</dd>
<dt><code class="xref py py-class docutils literal notranslate"><span class="pre">PCA</span></code></dt><dd><p>Further removes the linear correlation across features with ‘whiten=True’.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>For a comparison of the different scalers, transformers, and normalizers,
see <span class="xref std std-ref">examples/preprocessing/plot_all_scaling.py</span>.</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Median">https://en.wikipedia.org/wiki/Median</a>
<a class="reference external" href="https://en.wikipedia.org/wiki/Interquartile_range">https://en.wikipedia.org/wiki/Interquartile_range</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.RobustScaler.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.RobustScaler.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the median and quantiles to be used for scaling.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data used to compute the median and quantiles
used for later scaling along the features axis.</p></li>
<li><p><strong>y</strong> (<em>None</em>) – Ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – Fitted scaler.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.RobustScaler.inverse_transform">
<span class="sig-name descname"><span class="pre">inverse_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.RobustScaler.inverse_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Scale back the data to the original representation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The rescaled data to be transformed back.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_tr</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>{ndarray, sparse matrix} of shape (n_samples, n_features)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.RobustScaler.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.RobustScaler.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Center and scale the data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data used to scale along the specified axis.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_tr</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>{ndarray, sparse matrix} of shape (n_samples, n_features)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.preprocessing.SplineTransformer">
<em class="property"><span class="pre">class</span> </em><span class="sig-name descname"><span class="pre">SplineTransformer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_knots</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">degree</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">knots</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'uniform'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">extrapolation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'constant'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">order</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'C'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.SplineTransformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.TransformerMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.BaseEstimator</span></code></p>
<p>Generate univariate B-spline bases for features.</p>
<p>Generate a new feature matrix consisting of
<cite>n_splines=n_knots + degree - 1</cite> (<cite>n_knots - 1</cite> for
<cite>extrapolation=”periodic”</cite>) spline basis functions
(B-splines) of polynomial order=`degree` for each feature.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_knots</strong> (<em>int</em><em>, </em><em>default=5</em>) – Number of knots of the splines if <cite>knots</cite> equals one of
{‘uniform’, ‘quantile’}. Must be larger or equal 2.</p></li>
<li><p><strong>degree</strong> (<em>int</em><em>, </em><em>default=3</em>) – The polynomial degree of the spline basis. Must be a non-negative
integer.</p></li>
<li><p><strong>knots</strong> (<em>{'uniform'</em><em>, </em><em>'quantile'}</em><em> or </em><em>array-like of shape</em><em>         (</em><em>n_knots</em><em>, </em><em>n_features</em><em>)</em><em>, </em><em>default='uniform'</em>) – <p>Set knot positions such that first knot &lt;= features &lt;= last knot.</p>
<ul>
<li><p>If ‘uniform’, <cite>n_knots</cite> number of knots are distributed uniformly
from min to max values of the features.</p></li>
<li><p>If ‘quantile’, they are distributed uniformly along the quantiles of
the features.</p></li>
<li><p>If an array-like is given, it directly specifies the sorted knot
positions including the boundary knots. Note that, internally,
<cite>degree</cite> number of knots are added before the first knot, the same
after the last knot.</p></li>
</ul>
</p></li>
<li><p><strong>extrapolation</strong> (<em>{'error'</em><em>, </em><em>'constant'</em><em>, </em><em>'linear'</em><em>, </em><em>'continue'</em><em>, </em><em>'periodic'}</em><em>,         </em><em>default='constant'</em>) – If ‘error’, values outside the min and max values of the training
features raises a <cite>ValueError</cite>. If ‘constant’, the value of the
splines at minimum and maximum value of the features is used as
constant extrapolation. If ‘linear’, a linear extrapolation is used.
If ‘continue’, the splines are extrapolated as is, i.e. option
<cite>extrapolate=True</cite> in <code class="xref py py-class docutils literal notranslate"><span class="pre">scipy.interpolate.BSpline</span></code>. If
‘periodic’, periodic splines with a periodicity equal to the distance
between the first and last knot are used. Periodic splines enforce
equal function values and derivatives at the first and last knot.
For example, this makes it possible to avoid introducing an arbitrary
jump between Dec 31st and Jan 1st in spline features derived from a
naturally periodic “day-of-year” input feature. In this case it is
recommended to manually set the knot values to control the period.</p></li>
<li><p><strong>include_bias</strong> (<em>bool</em><em>, </em><em>default=True</em>) – If True (default), then the last spline element inside the data range
of a feature is dropped. As B-splines sum to one over the spline basis
functions for each data point, they implicitly include a bias term,
i.e. a column of ones. It acts as an intercept term in a linear models.</p></li>
<li><p><strong>order</strong> (<em>{'C'</em><em>, </em><em>'F'}</em><em>, </em><em>default='C'</em>) – Order of output array. ‘F’ order is faster to compute, but may slow
down subsequent estimators.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.SplineTransformer.bsplines_">
<span class="sig-name descname"><span class="pre">bsplines_</span></span><a class="headerlink" href="#sklearn.preprocessing.SplineTransformer.bsplines_" title="Permalink to this definition">¶</a></dt>
<dd><p>List of BSplines objects, one for each feature.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>list of shape (n_features,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.SplineTransformer.n_features_in_">
<span class="sig-name descname"><span class="pre">n_features_in_</span></span><a class="headerlink" href="#sklearn.preprocessing.SplineTransformer.n_features_in_" title="Permalink to this definition">¶</a></dt>
<dd><p>The total number of input features.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.SplineTransformer.n_features_out_">
<span class="sig-name descname"><span class="pre">n_features_out_</span></span><a class="headerlink" href="#sklearn.preprocessing.SplineTransformer.n_features_out_" title="Permalink to this definition">¶</a></dt>
<dd><p>The total number of output features, which is computed as
<cite>n_features * n_splines</cite>, where <cite>n_splines</cite> is
the number of bases elements of the B-splines,
<cite>n_knots + degree - 1</cite> for non-periodic splines and
<cite>n_knots - 1</cite> for periodic ones.
If <cite>include_bias=False</cite>, then it is only
<cite>n_features * (n_splines - 1)</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.preprocessing.KBinsDiscretizer" title="sklearn.preprocessing.KBinsDiscretizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">KBinsDiscretizer</span></code></a></dt><dd><p>Transformer that bins continuous data into intervals.</p>
</dd>
<dt><a class="reference internal" href="#sklearn.preprocessing.PolynomialFeatures" title="sklearn.preprocessing.PolynomialFeatures"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PolynomialFeatures</span></code></a></dt><dd><p>Transformer that generates polynomial and interaction features.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>High degrees and a high number of knots can cause overfitting.</p>
<p>See <span class="xref std std-ref">examples/linear_model/plot_polynomial_interpolation.py</span>.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">SplineTransformer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spline</span> <span class="o">=</span> <span class="n">SplineTransformer</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_knots</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spline</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([[0.5 , 0.5 , 0.  , 0.  ],</span>
<span class="go">       [0.18, 0.74, 0.08, 0.  ],</span>
<span class="go">       [0.02, 0.66, 0.32, 0.  ],</span>
<span class="go">       [0.  , 0.32, 0.66, 0.02],</span>
<span class="go">       [0.  , 0.08, 0.74, 0.18],</span>
<span class="go">       [0.  , 0.  , 0.5 , 0.5 ]])</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.SplineTransformer.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.SplineTransformer.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute knot positions of splines.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data.</p></li>
<li><p><strong>y</strong> (<em>None</em>) – Ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – Fitted transformer.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.SplineTransformer.get_feature_names">
<span class="sig-name descname"><span class="pre">get_feature_names</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.SplineTransformer.get_feature_names" title="Permalink to this definition">¶</a></dt>
<dd><p>Return feature names for output features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_features</strong> (<em>list of str of shape</em><em> (</em><em>n_features</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – String names for input features if available. By default,
“x0”, “x1”, … “xn_features” is used.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>output_feature_names</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list of str of shape (n_output_features,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.SplineTransformer.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.SplineTransformer.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform each feature data to B-splines.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data to transform.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>XBS</strong> – The matrix of features, where n_splines is the number of bases
elements of the B-splines, n_knots + degree - 1.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray of shape (n_samples, n_features * n_splines)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sklearn.preprocessing.StandardScaler">
<em class="property"><span class="pre">class</span> </em><span class="sig-name descname"><span class="pre">StandardScaler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_mean</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.StandardScaler" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.TransformerMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.BaseEstimator</span></code></p>
<p>Standardize features by removing the mean and scaling to unit variance</p>
<p>The standard score of a sample <cite>x</cite> is calculated as:</p>
<blockquote>
<div><p>z = (x - u) / s</p>
</div></blockquote>
<p>where <cite>u</cite> is the mean of the training samples or zero if <cite>with_mean=False</cite>,
and <cite>s</cite> is the standard deviation of the training samples or one if
<cite>with_std=False</cite>.</p>
<p>Centering and scaling happen independently on each feature by computing
the relevant statistics on the samples in the training set. Mean and
standard deviation are then stored to be used on later data using
<a class="reference internal" href="#sklearn.preprocessing.StandardScaler.transform" title="sklearn.preprocessing.StandardScaler.transform"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transform()</span></code></a>.</p>
<p>Standardization of a dataset is a common requirement for many
machine learning estimators: they might behave badly if the
individual features do not more or less look like standard normally
distributed data (e.g. Gaussian with 0 mean and unit variance).</p>
<p>For instance many elements used in the objective function of
a learning algorithm (such as the RBF kernel of Support Vector
Machines or the L1 and L2 regularizers of linear models) assume that
all features are centered around 0 and have variance in the same
order. If a feature has a variance that is orders of magnitude larger
that others, it might dominate the objective function and make the
estimator unable to learn from other features correctly as expected.</p>
<p>This scaler can also be applied to sparse CSR or CSC matrices by passing
<cite>with_mean=False</cite> to avoid breaking the sparsity structure of the data.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>copy</strong> (<em>bool</em><em>, </em><em>default=True</em>) – If False, try to avoid a copy and do inplace scaling instead.
This is not guaranteed to always work inplace; e.g. if the data is
not a NumPy array or scipy.sparse CSR matrix, a copy may still be
returned.</p></li>
<li><p><strong>with_mean</strong> (<em>bool</em><em>, </em><em>default=True</em>) – If True, center the data before scaling.
This does not work (and will raise an exception) when attempted on
sparse matrices, because centering them entails building a dense
matrix which in common use cases is likely to be too large to fit in
memory.</p></li>
<li><p><strong>with_std</strong> (<em>bool</em><em>, </em><em>default=True</em>) – If True, scale the data to unit variance (or equivalently,
unit standard deviation).</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.StandardScaler.scale_">
<span class="sig-name descname"><span class="pre">scale_</span></span><a class="headerlink" href="#sklearn.preprocessing.StandardScaler.scale_" title="Permalink to this definition">¶</a></dt>
<dd><p>Per feature relative scaling of the data to achieve zero mean and unit
variance. Generally this is calculated using <cite>np.sqrt(var_)</cite>. If a
variance is zero, we can’t achieve unit variance, and the data is left
as-is, giving a scaling factor of 1. <cite>scale_</cite> is equal to <cite>None</cite>
when <cite>with_std=False</cite>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.17: </span><em>scale_</em></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray of shape (n_features,) or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.StandardScaler.mean_">
<span class="sig-name descname"><span class="pre">mean_</span></span><a class="headerlink" href="#sklearn.preprocessing.StandardScaler.mean_" title="Permalink to this definition">¶</a></dt>
<dd><p>The mean value for each feature in the training set.
Equal to <code class="docutils literal notranslate"><span class="pre">None</span></code> when <code class="docutils literal notranslate"><span class="pre">with_mean=False</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray of shape (n_features,) or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.StandardScaler.var_">
<span class="sig-name descname"><span class="pre">var_</span></span><a class="headerlink" href="#sklearn.preprocessing.StandardScaler.var_" title="Permalink to this definition">¶</a></dt>
<dd><p>The variance for each feature in the training set. Used to compute
<cite>scale_</cite>. Equal to <code class="docutils literal notranslate"><span class="pre">None</span></code> when <code class="docutils literal notranslate"><span class="pre">with_std=False</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray of shape (n_features,) or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sklearn.preprocessing.StandardScaler.n_samples_seen_">
<span class="sig-name descname"><span class="pre">n_samples_seen_</span></span><a class="headerlink" href="#sklearn.preprocessing.StandardScaler.n_samples_seen_" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of samples processed by the estimator for each feature.
If there are no missing samples, the <code class="docutils literal notranslate"><span class="pre">n_samples_seen</span></code> will be an
integer, otherwise it will be an array of dtype int. If
<cite>sample_weights</cite> are used it will be a float (if no missing data)
or an array of dtype float that sums the weights seen so far.
Will be reset on new calls to fit, but increments across
<code class="docutils literal notranslate"><span class="pre">partial_fit</span></code> calls.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int or ndarray of shape (n_features,)</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
<span class="go">StandardScaler()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">mean_</span><span class="p">)</span>
<span class="go">[0.5 0.5]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
<span class="go">[[-1. -1.]</span>
<span class="go"> [-1. -1.]</span>
<span class="go"> [ 1.  1.]</span>
<span class="go"> [ 1.  1.]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]))</span>
<span class="go">[[3. 3.]]</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.preprocessing.scale" title="sklearn.preprocessing.scale"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scale</span></code></a></dt><dd><p>Equivalent function without the estimator API.</p>
</dd>
<dt><code class="xref py py-class docutils literal notranslate"><span class="pre">PCA</span></code></dt><dd><p>Further removes the linear correlation across features with ‘whiten=True’.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>NaNs are treated as missing values: disregarded in fit, and maintained in
transform.</p>
<p>We use a biased estimator for the standard deviation, equivalent to
<cite>numpy.std(x, ddof=0)</cite>. Note that the choice of <cite>ddof</cite> is unlikely to
affect model performance.</p>
<p>For a comparison of the different scalers, transformers, and normalizers,
see <span class="xref std std-ref">examples/preprocessing/plot_all_scaling.py</span>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.StandardScaler.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.StandardScaler.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the mean and std to be used for later scaling.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data used to compute the mean and standard deviation
used for later scaling along the features axis.</p></li>
<li><p><strong>y</strong> (<em>None</em>) – Ignored.</p></li>
<li><p><strong>sample_weight</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – <p>Individual weights for each sample.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24: </span>parameter <em>sample_weight</em> support to StandardScaler.</p>
</div>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – Fitted scaler.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.StandardScaler.inverse_transform">
<span class="sig-name descname"><span class="pre">inverse_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.StandardScaler.inverse_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Scale back the data to the original representation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data used to scale along the features axis.</p></li>
<li><p><strong>copy</strong> (<em>bool</em><em>, </em><em>default=None</em>) – Copy the input X or not.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_tr</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>{ndarray, sparse matrix} of shape (n_samples, n_features)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.StandardScaler.partial_fit">
<span class="sig-name descname"><span class="pre">partial_fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.StandardScaler.partial_fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Online computation of mean and std on X for later scaling.</p>
<p>All of X is processed as a single batch. This is intended for cases
when <a class="reference internal" href="#sklearn.preprocessing.StandardScaler.fit" title="sklearn.preprocessing.StandardScaler.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> is not feasible due to very large number of
<cite>n_samples</cite> or because X is read from a continuous stream.</p>
<p>The algorithm for incremental mean and std is given in Equation 1.5a,b
in Chan, Tony F., Gene H. Golub, and Randall J. LeVeque. “Algorithms
for computing the sample variance: Analysis and recommendations.”
The American Statistician 37.3 (1983): 242-247:</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data used to compute the mean and standard deviation
used for later scaling along the features axis.</p></li>
<li><p><strong>y</strong> (<em>None</em>) – Ignored.</p></li>
<li><p><strong>sample_weight</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – <p>Individual weights for each sample.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24: </span>parameter <em>sample_weight</em> support to StandardScaler.</p>
</div>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – Fitted scaler.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.preprocessing.StandardScaler.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.StandardScaler.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform standardization by centering and scaling</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data used to scale along the features axis.</p></li>
<li><p><strong>copy</strong> (<em>bool</em><em>, </em><em>default=None</em>) – Copy the input X or not.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_tr</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>{ndarray, sparse matrix} of shape (n_samples, n_features)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sklearn.preprocessing.add_dummy_feature">
<span class="sig-name descname"><span class="pre">add_dummy_feature</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.add_dummy_feature" title="Permalink to this definition">¶</a></dt>
<dd><p>Augment dataset with an additional dummy feature.</p>
<p>This is useful for fitting an intercept term with implementations which
cannot otherwise fit it directly.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Data.</p></li>
<li><p><strong>value</strong> (<em>float</em>) – Value to use for the dummy feature.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X</strong> – Same data with dummy feature added as first column.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>{ndarray, sparse matrix} of shape (n_samples, n_features + 1)</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">add_dummy_feature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">add_dummy_feature</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="go">array([[1., 0., 1.],</span>
<span class="go">       [1., 1., 0.]])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sklearn.preprocessing.binarize">
<span class="sig-name descname"><span class="pre">binarize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.binarize" title="Permalink to this definition">¶</a></dt>
<dd><p>Boolean thresholding of array-like or scipy.sparse matrix.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data to binarize, element by element.
scipy.sparse matrices should be in CSR or CSC format to avoid an
un-necessary copy.</p></li>
<li><p><strong>threshold</strong> (<em>float</em><em>, </em><em>default=0.0</em>) – Feature values below or equal to this are replaced by 0, above it by 1.
Threshold may not be less than 0 for operations on sparse matrices.</p></li>
<li><p><strong>copy</strong> (<em>bool</em><em>, </em><em>default=True</em>) – set to False to perform inplace binarization and avoid a copy
(if the input is already a numpy array or a scipy.sparse CSR / CSC
matrix and if axis is 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_tr</strong> – The transformed data.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>{ndarray, sparse matrix} of shape (n_samples, n_features)</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.preprocessing.Binarizer" title="sklearn.preprocessing.Binarizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Binarizer</span></code></a></dt><dd><p>Performs binarization using the Transformer API (e.g. as part of a preprocessing <code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code>).</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sklearn.preprocessing.label_binarize">
<span class="sig-name descname"><span class="pre">label_binarize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neg_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pos_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse_output</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.label_binarize" title="Permalink to this definition">¶</a></dt>
<dd><p>Binarize labels in a one-vs-all fashion.</p>
<p>Several regression and binary classification algorithms are
available in scikit-learn. A simple way to extend these algorithms
to the multi-class classification case is to use the so-called
one-vs-all scheme.</p>
<p>This function makes it possible to compute this transformation for a
fixed set of class labels known ahead of time.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<em>array-like</em>) – Sequence of integer labels or multilabel data to encode.</p></li>
<li><p><strong>classes</strong> (<em>array-like of shape</em><em> (</em><em>n_classes</em><em>,</em><em>)</em>) – Uniquely holds the label for each class.</p></li>
<li><p><strong>neg_label</strong> (<em>int</em><em>, </em><em>default=0</em>) – Value with which negative labels must be encoded.</p></li>
<li><p><strong>pos_label</strong> (<em>int</em><em>, </em><em>default=1</em>) – Value with which positive labels must be encoded.</p></li>
<li><p><strong>sparse_output</strong> (<em>bool</em><em>, </em><em>default=False</em><em>,</em>) – Set to true if output binary array is desired in CSR sparse format.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Y</strong> – Shape will be (n_samples, 1) for binary problems. Sparse matrix will
be of CSR format.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>{ndarray, sparse matrix} of shape (n_samples, n_classes)</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">label_binarize</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label_binarize</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="go">array([[1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1]])</span>
</pre></div>
</div>
<p>The class ordering is preserved:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">label_binarize</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="go">array([[1, 0, 0, 0],</span>
<span class="go">       [0, 1, 0, 0]])</span>
</pre></div>
</div>
<p>Binary targets transform to a column vector</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">label_binarize</span><span class="p">([</span><span class="s1">&#39;yes&#39;</span><span class="p">,</span> <span class="s1">&#39;no&#39;</span><span class="p">,</span> <span class="s1">&#39;no&#39;</span><span class="p">,</span> <span class="s1">&#39;yes&#39;</span><span class="p">],</span> <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;no&#39;</span><span class="p">,</span> <span class="s1">&#39;yes&#39;</span><span class="p">])</span>
<span class="go">array([[1],</span>
<span class="go">       [0],</span>
<span class="go">       [0],</span>
<span class="go">       [1]])</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.preprocessing.LabelBinarizer" title="sklearn.preprocessing.LabelBinarizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LabelBinarizer</span></code></a></dt><dd><p>Class used to wrap the functionality of label_binarize and allow for fitting to classes independently of the transform operation.</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sklearn.preprocessing.maxabs_scale">
<span class="sig-name descname"><span class="pre">maxabs_scale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.maxabs_scale" title="Permalink to this definition">¶</a></dt>
<dd><p>Scale each feature to the [-1, 1] range without breaking the sparsity.</p>
<p>This estimator scales each feature individually such
that the maximal absolute value of each feature in the
training set will be 1.0.</p>
<p>This scaler can also be applied to sparse CSR or CSC matrices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data.</p></li>
<li><p><strong>axis</strong> (<em>int</em><em>, </em><em>default=0</em>) – axis used to scale along. If 0, independently scale each feature,
otherwise (if 1) scale each sample.</p></li>
<li><p><strong>copy</strong> (<em>bool</em><em>, </em><em>default=True</em>) – Set to False to perform inplace scaling and avoid a copy (if the input
is already a numpy array).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>X_tr</strong> (<em>{ndarray, sparse matrix} of shape (n_samples, n_features)</em>) – The transformed data.</p></li>
<li><p><em>.. warning:: Risk of data leak</em> – Do not use <a class="reference internal" href="#sklearn.preprocessing.maxabs_scale" title="sklearn.preprocessing.maxabs_scale"><code class="xref py py-func docutils literal notranslate"><span class="pre">maxabs_scale()</span></code></a> unless you know what
you are doing. A common mistake is to apply it to the entire data
<em>before</em> splitting into training and test sets. This will bias the
model evaluation because information would have leaked from the test
set to the training set.
In general, we recommend using
<a class="reference internal" href="#sklearn.preprocessing.MaxAbsScaler" title="sklearn.preprocessing.MaxAbsScaler"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaxAbsScaler</span></code></a> within a
<span class="xref std std-ref">Pipeline</span> in order to prevent most risks of data
leaking: <cite>pipe = make_pipeline(MaxAbsScaler(), LogisticRegression())</cite>.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.preprocessing.MaxAbsScaler" title="sklearn.preprocessing.MaxAbsScaler"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MaxAbsScaler</span></code></a></dt><dd><p>Performs scaling to the [-1, 1] range using the Transformer API (e.g. as part of a preprocessing <code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code>).</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>NaNs are treated as missing values: disregarded to compute the statistics,
and maintained during the data transformation.</p>
<p>For a comparison of the different scalers, transformers, and normalizers,
see <span class="xref std std-ref">examples/preprocessing/plot_all_scaling.py</span>.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sklearn.preprocessing.minmax_scale">
<span class="sig-name descname"><span class="pre">minmax_scale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0,</span> <span class="pre">1)</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.minmax_scale" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform features by scaling each feature to a given range.</p>
<p>This estimator scales and translates each feature individually such
that it is in the given range on the training set, i.e. between
zero and one.</p>
<p>The transformation is given by (when <code class="docutils literal notranslate"><span class="pre">axis=0</span></code>):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X_std</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">X</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="n">X</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="n">X_scaled</span> <span class="o">=</span> <span class="n">X_std</span> <span class="o">*</span> <span class="p">(</span><span class="nb">max</span> <span class="o">-</span> <span class="nb">min</span><span class="p">)</span> <span class="o">+</span> <span class="nb">min</span>
</pre></div>
</div>
<p>where min, max = feature_range.</p>
<p>The transformation is calculated as (when <code class="docutils literal notranslate"><span class="pre">axis=0</span></code>):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X_scaled</span> <span class="o">=</span> <span class="n">scale</span> <span class="o">*</span> <span class="n">X</span> <span class="o">+</span> <span class="nb">min</span> <span class="o">-</span> <span class="n">X</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="n">scale</span>
<span class="n">where</span> <span class="n">scale</span> <span class="o">=</span> <span class="p">(</span><span class="nb">max</span> <span class="o">-</span> <span class="nb">min</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="n">X</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
<p>This transformation is often used as an alternative to zero mean,
unit variance scaling.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.17: </span><em>minmax_scale</em> function interface
to <a class="reference internal" href="#sklearn.preprocessing.MinMaxScaler" title="sklearn.preprocessing.MinMaxScaler"><code class="xref py py-class docutils literal notranslate"><span class="pre">MinMaxScaler</span></code></a>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data.</p></li>
<li><p><strong>feature_range</strong> (<em>tuple</em><em> (</em><em>min</em><em>, </em><em>max</em><em>)</em><em>, </em><em>default=</em><em>(</em><em>0</em><em>, </em><em>1</em><em>)</em>) – Desired range of transformed data.</p></li>
<li><p><strong>axis</strong> (<em>int</em><em>, </em><em>default=0</em>) – Axis used to scale along. If 0, independently scale each feature,
otherwise (if 1) scale each sample.</p></li>
<li><p><strong>copy</strong> (<em>bool</em><em>, </em><em>default=True</em>) – Set to False to perform inplace scaling and avoid a copy (if the input
is already a numpy array).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>X_tr</strong> (<em>ndarray of shape (n_samples, n_features)</em>) – The transformed data.</p></li>
<li><p><em>.. warning:: Risk of data leak</em> – Do not use <a class="reference internal" href="#sklearn.preprocessing.minmax_scale" title="sklearn.preprocessing.minmax_scale"><code class="xref py py-func docutils literal notranslate"><span class="pre">minmax_scale()</span></code></a> unless you know
what you are doing. A common mistake is to apply it to the entire data
<em>before</em> splitting into training and test sets. This will bias the
model evaluation because information would have leaked from the test
set to the training set.
In general, we recommend using
<a class="reference internal" href="#sklearn.preprocessing.MinMaxScaler" title="sklearn.preprocessing.MinMaxScaler"><code class="xref py py-class docutils literal notranslate"><span class="pre">MinMaxScaler</span></code></a> within a
<span class="xref std std-ref">Pipeline</span> in order to prevent most risks of data
leaking: <cite>pipe = make_pipeline(MinMaxScaler(), LogisticRegression())</cite>.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.preprocessing.MinMaxScaler" title="sklearn.preprocessing.MinMaxScaler"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MinMaxScaler</span></code></a></dt><dd><p>Performs scaling to a given range using the Transformer API (e.g. as part of a preprocessing <code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code>).</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>For a comparison of the different scalers, transformers, and normalizers,
see <span class="xref std std-ref">examples/preprocessing/plot_all_scaling.py</span>.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sklearn.preprocessing.normalize">
<span class="sig-name descname"><span class="pre">normalize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'l2'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.normalize" title="Permalink to this definition">¶</a></dt>
<dd><p>Scale input vectors individually to unit norm (vector length).</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data to normalize, element by element.
scipy.sparse matrices should be in CSR format to avoid an
un-necessary copy.</p></li>
<li><p><strong>norm</strong> (<em>{'l1'</em><em>, </em><em>'l2'</em><em>, </em><em>'max'}</em><em>, </em><em>default='l2'</em>) – The norm to use to normalize each non zero sample (or each non-zero
feature if axis is 0).</p></li>
<li><p><strong>axis</strong> (<em>{0</em><em>, </em><em>1}</em><em>, </em><em>default=1</em>) – axis used to normalize the data along. If 1, independently normalize
each sample, otherwise (if 0) normalize each feature.</p></li>
<li><p><strong>copy</strong> (<em>bool</em><em>, </em><em>default=True</em>) – set to False to perform inplace row normalization and avoid a
copy (if the input is already a numpy array or a scipy.sparse
CSR matrix and if axis is 1).</p></li>
<li><p><strong>return_norm</strong> (<em>bool</em><em>, </em><em>default=False</em>) – whether to return the computed norms</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>X</strong> (<em>{ndarray, sparse matrix} of shape (n_samples, n_features)</em>) – Normalized input X.</p></li>
<li><p><strong>norms</strong> (<em>ndarray of shape (n_samples, ) if axis=1 else (n_features, )</em>) – An array of norms along given axis for X.
When X is sparse, a NotImplementedError will be raised
for norm ‘l1’ or ‘l2’.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.preprocessing.Normalizer" title="sklearn.preprocessing.Normalizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Normalizer</span></code></a></dt><dd><p>Performs normalization using the Transformer API (e.g. as part of a preprocessing <code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code>).</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>For a comparison of the different scalers, transformers, and normalizers,
see <span class="xref std std-ref">examples/preprocessing/plot_all_scaling.py</span>.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sklearn.preprocessing.power_transform">
<span class="sig-name descname"><span class="pre">power_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'yeo-johnson'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">standardize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.power_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Power transforms are a family of parametric, monotonic transformations
that are applied to make data more Gaussian-like. This is useful for
modeling issues related to heteroscedasticity (non-constant variance),
or other situations where normality is desired.</p>
<p>Currently, power_transform supports the Box-Cox transform and the
Yeo-Johnson transform. The optimal parameter for stabilizing variance and
minimizing skewness is estimated through maximum likelihood.</p>
<p>Box-Cox requires input data to be strictly positive, while Yeo-Johnson
supports both positive or negative data.</p>
<p>By default, zero-mean, unit-variance normalization is applied to the
transformed data.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data to be transformed using a power transformation.</p></li>
<li><p><strong>method</strong> (<em>{'yeo-johnson'</em><em>, </em><em>'box-cox'}</em><em>, </em><em>default='yeo-johnson'</em>) – <p>The power transform method. Available methods are:</p>
<ul>
<li><p>’yeo-johnson’ <a href="#id11"><span class="problematic" id="id5">[1]_</span></a>, works with positive and negative values</p></li>
<li><p>’box-cox’ <a href="#id12"><span class="problematic" id="id6">[2]_</span></a>, only works with strictly positive values</p></li>
</ul>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.23: </span>The default value of the <cite>method</cite> parameter changed from
‘box-cox’ to ‘yeo-johnson’ in 0.23.</p>
</div>
</p></li>
<li><p><strong>standardize</strong> (<em>bool</em><em>, </em><em>default=True</em>) – Set to True to apply zero-mean, unit-variance normalization to the
transformed output.</p></li>
<li><p><strong>copy</strong> (<em>bool</em><em>, </em><em>default=True</em>) – Set to False to perform inplace computation during transformation.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_trans</strong> – The transformed data.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray of shape (n_samples, n_features)</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">power_transform</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">power_transform</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;box-cox&#39;</span><span class="p">))</span>
<span class="go">[[-1.332... -0.707...]</span>
<span class="go"> [ 0.256... -0.707...]</span>
<span class="go"> [ 1.076...  1.414...]]</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Risk of data leak.
Do not use <a class="reference internal" href="#sklearn.preprocessing.power_transform" title="sklearn.preprocessing.power_transform"><code class="xref py py-func docutils literal notranslate"><span class="pre">power_transform()</span></code></a> unless you
know what you are doing. A common mistake is to apply it to the entire
data <em>before</em> splitting into training and test sets. This will bias the
model evaluation because information would have leaked from the test
set to the training set.
In general, we recommend using
<a class="reference internal" href="#sklearn.preprocessing.PowerTransformer" title="sklearn.preprocessing.PowerTransformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">PowerTransformer</span></code></a> within a
<span class="xref std std-ref">Pipeline</span> in order to prevent most risks of data
leaking, e.g.: <cite>pipe = make_pipeline(PowerTransformer(),
LogisticRegression())</cite>.</p>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.preprocessing.PowerTransformer" title="sklearn.preprocessing.PowerTransformer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PowerTransformer</span></code></a></dt><dd><p>Equivalent transformation with the Transformer API (e.g. as part of a preprocessing <code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code>).</p>
</dd>
<dt><a class="reference internal" href="#sklearn.preprocessing.quantile_transform" title="sklearn.preprocessing.quantile_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">quantile_transform</span></code></a></dt><dd><p>Maps data to a standard normal distribution with the parameter <cite>output_distribution=’normal’</cite>.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>NaNs are treated as missing values: disregarded in <code class="docutils literal notranslate"><span class="pre">fit</span></code>, and maintained
in <code class="docutils literal notranslate"><span class="pre">transform</span></code>.</p>
<p>For a comparison of the different scalers, transformers, and normalizers,
see <span class="xref std std-ref">examples/preprocessing/plot_all_scaling.py</span>.</p>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id7"><span class="brackets">1</span></dt>
<dd><p>I.K. Yeo and R.A. Johnson, “A new family of power transformations to
improve normality or symmetry.” Biometrika, 87(4), pp.954-959,
(2000).</p>
</dd>
<dt class="label" id="id8"><span class="brackets">2</span></dt>
<dd><p>G.E.P. Box and D.R. Cox, “An Analysis of Transformations”, Journal
of the Royal Statistical Society B, 26, 211-252 (1964).</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sklearn.preprocessing.quantile_transform">
<span class="sig-name descname"><span class="pre">quantile_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_quantiles</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_distribution</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'uniform'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_implicit_zeros</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.quantile_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform features using quantiles information.</p>
<p>This method transforms the features to follow a uniform or a normal
distribution. Therefore, for a given feature, this transformation tends
to spread out the most frequent values. It also reduces the impact of
(marginal) outliers: this is therefore a robust preprocessing scheme.</p>
<p>The transformation is applied on each feature independently. First an
estimate of the cumulative distribution function of a feature is
used to map the original values to a uniform distribution. The obtained
values are then mapped to the desired output distribution using the
associated quantile function. Features values of new/unseen data that fall
below or above the fitted range will be mapped to the bounds of the output
distribution. Note that this transform is non-linear. It may distort linear
correlations between variables measured at the same scale but renders
variables measured at different scales more directly comparable.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data to transform.</p></li>
<li><p><strong>axis</strong> (<em>int</em><em>, </em><em>default=0</em>) – Axis used to compute the means and standard deviations along. If 0,
transform each feature, otherwise (if 1) transform each sample.</p></li>
<li><p><strong>n_quantiles</strong> (<em>int</em><em>, </em><em>default=1000</em><em> or </em><em>n_samples</em>) – Number of quantiles to be computed. It corresponds to the number
of landmarks used to discretize the cumulative distribution function.
If n_quantiles is larger than the number of samples, n_quantiles is set
to the number of samples as a larger number of quantiles does not give
a better approximation of the cumulative distribution function
estimator.</p></li>
<li><p><strong>output_distribution</strong> (<em>{'uniform'</em><em>, </em><em>'normal'}</em><em>, </em><em>default='uniform'</em>) – Marginal distribution for the transformed data. The choices are
‘uniform’ (default) or ‘normal’.</p></li>
<li><p><strong>ignore_implicit_zeros</strong> (<em>bool</em><em>, </em><em>default=False</em>) – Only applies to sparse matrices. If True, the sparse entries of the
matrix are discarded to compute the quantile statistics. If False,
these entries are treated as zeros.</p></li>
<li><p><strong>subsample</strong> (<em>int</em><em>, </em><em>default=1e5</em>) – Maximum number of samples used to estimate the quantiles for
computational efficiency. Note that the subsampling procedure may
differ for value-identical sparse and dense matrices.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Determines random number generation for subsampling and smoothing
noise.
Please see <code class="docutils literal notranslate"><span class="pre">subsample</span></code> for more details.
Pass an int for reproducible results across multiple function calls.
See <span class="xref std std-term">Glossary</span></p></li>
<li><p><strong>copy</strong> (<em>bool</em><em>, </em><em>default=True</em>) – <p>Set to False to perform inplace transformation and avoid a copy (if the
input is already a numpy array). If True, a copy of <cite>X</cite> is transformed,
leaving the original <cite>X</cite> unchanged</p>
<dl class="simple">
<dt>..versionchanged:: 0.23</dt><dd><p>The default value of <cite>copy</cite> changed from False to True in 0.23.</p>
</dd>
</dl>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Xt</strong> – The transformed data.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>{ndarray, sparse matrix} of shape (n_samples, n_features)</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">quantile_transform</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">quantile_transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n_quantiles</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">array([...])</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.preprocessing.QuantileTransformer" title="sklearn.preprocessing.QuantileTransformer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">QuantileTransformer</span></code></a></dt><dd><p>Performs quantile-based scaling using the Transformer API (e.g. as part of a preprocessing <code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code>).</p>
</dd>
<dt><a class="reference internal" href="#sklearn.preprocessing.power_transform" title="sklearn.preprocessing.power_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">power_transform</span></code></a></dt><dd><p>Maps data to a normal distribution using a power transformation.</p>
</dd>
<dt><a class="reference internal" href="#sklearn.preprocessing.scale" title="sklearn.preprocessing.scale"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scale</span></code></a></dt><dd><p>Performs standardization that is faster, but less robust to outliers.</p>
</dd>
<dt><a class="reference internal" href="#sklearn.preprocessing.robust_scale" title="sklearn.preprocessing.robust_scale"><code class="xref py py-obj docutils literal notranslate"><span class="pre">robust_scale</span></code></a></dt><dd><p>Performs robust standardization that removes the influence of outliers but does not put outliers and inliers on the same scale.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>NaNs are treated as missing values: disregarded in fit, and maintained in
transform.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Risk of data leak</p>
<p>Do not use <a class="reference internal" href="#sklearn.preprocessing.quantile_transform" title="sklearn.preprocessing.quantile_transform"><code class="xref py py-func docutils literal notranslate"><span class="pre">quantile_transform()</span></code></a> unless
you know what you are doing. A common mistake is to apply it
to the entire data <em>before</em> splitting into training and
test sets. This will bias the model evaluation because
information would have leaked from the test set to the
training set.
In general, we recommend using
<a class="reference internal" href="#sklearn.preprocessing.QuantileTransformer" title="sklearn.preprocessing.QuantileTransformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantileTransformer</span></code></a> within a
<span class="xref std std-ref">Pipeline</span> in order to prevent most risks of data
leaking:<cite>pipe = make_pipeline(QuantileTransformer(),
LogisticRegression())</cite>.</p>
</div>
<p>For a comparison of the different scalers, transformers, and normalizers,
see <span class="xref std std-ref">examples/preprocessing/plot_all_scaling.py</span>.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sklearn.preprocessing.robust_scale">
<span class="sig-name descname"><span class="pre">robust_scale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_centering</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_scaling</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quantile_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(25.0,</span> <span class="pre">75.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unit_variance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.robust_scale" title="Permalink to this definition">¶</a></dt>
<dd><p>Standardize a dataset along any axis</p>
<p>Center to the median and component wise scale
according to the interquartile range.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_sample</em><em>, </em><em>n_features</em><em>)</em>) – The data to center and scale.</p></li>
<li><p><strong>axis</strong> (<em>int</em><em>, </em><em>default=0</em>) – axis used to compute the medians and IQR along. If 0,
independently scale each feature, otherwise (if 1) scale
each sample.</p></li>
<li><p><strong>with_centering</strong> (<em>bool</em><em>, </em><em>default=True</em>) – If True, center the data before scaling.</p></li>
<li><p><strong>with_scaling</strong> (<em>bool</em><em>, </em><em>default=True</em>) – If True, scale the data to unit variance (or equivalently,
unit standard deviation).</p></li>
<li><p><strong>quantile_range</strong> (<em>tuple</em><em> (</em><em>q_min</em><em>, </em><em>q_max</em><em>)</em><em>, </em><em>0.0 &lt; q_min &lt; q_max &lt; 100.0</em>) – <p>default=(25.0, 75.0), == (1st quantile, 3rd quantile), == IQR
Quantile range used to calculate <code class="docutils literal notranslate"><span class="pre">scale_</span></code>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.18.</span></p>
</div>
</p></li>
<li><p><strong>copy</strong> (<em>bool</em><em>, </em><em>default=True</em>) – set to False to perform inplace row normalization and avoid a
copy (if the input is already a numpy array or a scipy.sparse
CSR matrix and if axis is 1).</p></li>
<li><p><strong>unit_variance</strong> (<em>bool</em><em>, </em><em>default=False</em>) – <p>If True, scale data so that normally distributed features have a
variance of 1. In general, if the difference between the x-values of
<code class="docutils literal notranslate"><span class="pre">q_max</span></code> and <code class="docutils literal notranslate"><span class="pre">q_min</span></code> for a standard normal distribution is greater
than 1, the dataset will be scaled down. If less than 1, the dataset
will be scaled up.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_tr</strong> – The transformed data.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>{ndarray, sparse matrix} of shape (n_samples, n_features)</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This implementation will refuse to center scipy.sparse matrices
since it would make them non-sparse and would potentially crash the
program with memory exhaustion problems.</p>
<p>Instead the caller is expected to either set explicitly
<cite>with_centering=False</cite> (in that case, only variance scaling will be
performed on the features of the CSR matrix) or to call <cite>X.toarray()</cite>
if he/she expects the materialized dense array to fit in memory.</p>
<p>To avoid memory copy the caller should pass a CSR matrix.</p>
<p>For a comparison of the different scalers, transformers, and normalizers,
see <span class="xref std std-ref">examples/preprocessing/plot_all_scaling.py</span>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Risk of data leak</p>
<p>Do not use <a class="reference internal" href="#sklearn.preprocessing.robust_scale" title="sklearn.preprocessing.robust_scale"><code class="xref py py-func docutils literal notranslate"><span class="pre">robust_scale()</span></code></a> unless you know
what you are doing. A common mistake is to apply it to the entire data
<em>before</em> splitting into training and test sets. This will bias the
model evaluation because information would have leaked from the test
set to the training set.
In general, we recommend using
<a class="reference internal" href="#sklearn.preprocessing.RobustScaler" title="sklearn.preprocessing.RobustScaler"><code class="xref py py-class docutils literal notranslate"><span class="pre">RobustScaler</span></code></a> within a
<span class="xref std std-ref">Pipeline</span> in order to prevent most risks of data
leaking: <cite>pipe = make_pipeline(RobustScaler(), LogisticRegression())</cite>.</p>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.preprocessing.RobustScaler" title="sklearn.preprocessing.RobustScaler"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RobustScaler</span></code></a></dt><dd><p>Performs centering and scaling using the Transformer API (e.g. as part of a preprocessing <code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code>).</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sklearn.preprocessing.scale">
<span class="sig-name descname"><span class="pre">scale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_mean</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.preprocessing.scale" title="Permalink to this definition">¶</a></dt>
<dd><p>Standardize a dataset along any axis.</p>
<p>Center to the mean and component wise scale to unit variance.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data to center and scale.</p></li>
<li><p><strong>axis</strong> (<em>int</em><em>, </em><em>default=0</em>) – axis used to compute the means and standard deviations along. If 0,
independently standardize each feature, otherwise (if 1) standardize
each sample.</p></li>
<li><p><strong>with_mean</strong> (<em>bool</em><em>, </em><em>default=True</em>) – If True, center the data before scaling.</p></li>
<li><p><strong>with_std</strong> (<em>bool</em><em>, </em><em>default=True</em>) – If True, scale the data to unit variance (or equivalently,
unit standard deviation).</p></li>
<li><p><strong>copy</strong> (<em>bool</em><em>, </em><em>default=True</em>) – set to False to perform inplace row normalization and avoid a
copy (if the input is already a numpy array or a scipy.sparse
CSC matrix and if axis is 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_tr</strong> – The transformed data.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>{ndarray, sparse matrix} of shape (n_samples, n_features)</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This implementation will refuse to center scipy.sparse matrices
since it would make them non-sparse and would potentially crash the
program with memory exhaustion problems.</p>
<p>Instead the caller is expected to either set explicitly
<cite>with_mean=False</cite> (in that case, only variance scaling will be
performed on the features of the CSC matrix) or to call <cite>X.toarray()</cite>
if he/she expects the materialized dense array to fit in memory.</p>
<p>To avoid memory copy the caller should pass a CSC matrix.</p>
<p>NaNs are treated as missing values: disregarded to compute the statistics,
and maintained during the data transformation.</p>
<p>We use a biased estimator for the standard deviation, equivalent to
<cite>numpy.std(x, ddof=0)</cite>. Note that the choice of <cite>ddof</cite> is unlikely to
affect model performance.</p>
<p>For a comparison of the different scalers, transformers, and normalizers,
see <span class="xref std std-ref">examples/preprocessing/plot_all_scaling.py</span>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Risk of data leak</p>
<p>Do not use <a class="reference internal" href="#sklearn.preprocessing.scale" title="sklearn.preprocessing.scale"><code class="xref py py-func docutils literal notranslate"><span class="pre">scale()</span></code></a> unless you know
what you are doing. A common mistake is to apply it to the entire data
<em>before</em> splitting into training and test sets. This will bias the
model evaluation because information would have leaked from the test
set to the training set.
In general, we recommend using
<a class="reference internal" href="#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler"><code class="xref py py-class docutils literal notranslate"><span class="pre">StandardScaler</span></code></a> within a
<span class="xref std std-ref">Pipeline</span> in order to prevent most risks of data
leaking: <cite>pipe = make_pipeline(StandardScaler(), LogisticRegression())</cite>.</p>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler"><code class="xref py py-obj docutils literal notranslate"><span class="pre">StandardScaler</span></code></a></dt><dd><p>Performs scaling to unit variance using the Transformer API (e.g. as part of a preprocessing <code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code>).</p>
</dd>
</dl>
</div>
</dd></dl>

</section>
</section>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, Tommaso Fioravanti

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>